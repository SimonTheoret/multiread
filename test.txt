logo
core
1.89.0
(29483883e 2025-08-04)
Module x86_64
Module Items

    Structs
    Constants
    Functions
    Type Aliases

In core::arch
Modules

    aarch64
    arm
    loongarch64
    mips
    mips64
    nvptx
    powerpc
    powerpc64
    riscv32
    riscv64
    s390x
    wasm
    wasm32
    wasm64
    x86
    x86_64

Macros

    asm
    global_asm
    naked_asm

Functions

    breakpoint

core::arch
Module x86_64
1.27.0 · Source
Settings
Help
Available on x86-64 only.

Platform-specific intrinsics for the x86_64 platform.

See the module documentation for more details.
Structs

CpuidResultx86 or x86-64
    Result of the cpuid instruction.
__m128x86 or x86-64
    128-bit wide set of four f32 types, x86-specific
__m256x86 or x86-64
    256-bit wide set of eight f32 types, x86-specific
__m512x86 or x86-64
    512-bit wide set of sixteen f32 types, x86-specific
__m128bhx86 or x86-64
    128-bit wide set of eight u16 types, x86-specific
__m128dx86 or x86-64
    128-bit wide set of two f64 types, x86-specific
__m128ix86 or x86-64
    128-bit wide integer vector type, x86-specific
__m256bhx86 or x86-64
    256-bit wide set of 16 u16 types, x86-specific
__m256dx86 or x86-64
    256-bit wide set of four f64 types, x86-specific
__m256ix86 or x86-64
    256-bit wide integer vector type, x86-specific
__m512bhx86 or x86-64
    512-bit wide set of 32 u16 types, x86-specific
__m512dx86 or x86-64
    512-bit wide set of eight f64 types, x86-specific
__m512ix86 or x86-64
    512-bit wide integer vector type, x86-specific
__m128hExperimentalx86 or x86-64
    128-bit wide set of 8 f16 types, x86-specific
__m256hExperimentalx86 or x86-64
    256-bit wide set of 16 f16 types, x86-specific
__m512hExperimentalx86 or x86-64
    512-bit wide set of 32 f16 types, x86-specific
bf16Experimentalx86 or x86-64
    The BFloat16 type used in AVX-512 intrinsics.

Constants

_CMP_EQ_OQx86 or x86-64
    Equal (ordered, non-signaling)
_CMP_EQ_OSx86 or x86-64
    Equal (ordered, signaling)
_CMP_EQ_UQx86 or x86-64
    Equal (unordered, non-signaling)
_CMP_EQ_USx86 or x86-64
    Equal (unordered, signaling)
_CMP_FALSE_OQx86 or x86-64
    False (ordered, non-signaling)
_CMP_FALSE_OSx86 or x86-64
    False (ordered, signaling)
_CMP_GE_OQx86 or x86-64
    Greater-than-or-equal (ordered, non-signaling)
_CMP_GE_OSx86 or x86-64
    Greater-than-or-equal (ordered, signaling)
_CMP_GT_OQx86 or x86-64
    Greater-than (ordered, non-signaling)
_CMP_GT_OSx86 or x86-64
    Greater-than (ordered, signaling)
_CMP_LE_OQx86 or x86-64
    Less-than-or-equal (ordered, non-signaling)
_CMP_LE_OSx86 or x86-64
    Less-than-or-equal (ordered, signaling)
_CMP_LT_OQx86 or x86-64
    Less-than (ordered, non-signaling)
_CMP_LT_OSx86 or x86-64
    Less-than (ordered, signaling)
_CMP_NEQ_OQx86 or x86-64
    Not-equal (ordered, non-signaling)
_CMP_NEQ_OSx86 or x86-64
    Not-equal (ordered, signaling)
_CMP_NEQ_UQx86 or x86-64
    Not-equal (unordered, non-signaling)
_CMP_NEQ_USx86 or x86-64
    Not-equal (unordered, signaling)
_CMP_NGE_UQx86 or x86-64
    Not-greater-than-or-equal (unordered, non-signaling)
_CMP_NGE_USx86 or x86-64
    Not-greater-than-or-equal (unordered, signaling)
_CMP_NGT_UQx86 or x86-64
    Not-greater-than (unordered, non-signaling)
_CMP_NGT_USx86 or x86-64
    Not-greater-than (unordered, signaling)
_CMP_NLE_UQx86 or x86-64
    Not-less-than-or-equal (unordered, non-signaling)
_CMP_NLE_USx86 or x86-64
    Not-less-than-or-equal (unordered, signaling)
_CMP_NLT_UQx86 or x86-64
    Not-less-than (unordered, non-signaling)
_CMP_NLT_USx86 or x86-64
    Not-less-than (unordered, signaling)
_CMP_ORD_Qx86 or x86-64
    Ordered (non-signaling)
_CMP_ORD_Sx86 or x86-64
    Ordered (signaling)
_CMP_TRUE_UQx86 or x86-64
    True (unordered, non-signaling)
_CMP_TRUE_USx86 or x86-64
    True (unordered, signaling)
_CMP_UNORD_Qx86 or x86-64
    Unordered (non-signaling)
_CMP_UNORD_Sx86 or x86-64
    Unordered (signaling)
_MM_CMPINT_EQx86 or x86-64
    Equal
_MM_CMPINT_FALSEx86 or x86-64
    False
_MM_CMPINT_LEx86 or x86-64
    Less-than-or-equal
_MM_CMPINT_LTx86 or x86-64
    Less-than
_MM_CMPINT_NEx86 or x86-64
    Not-equal
_MM_CMPINT_NLEx86 or x86-64
    Not less-than-or-equal
_MM_CMPINT_NLTx86 or x86-64
    Not less-than
_MM_CMPINT_TRUEx86 or x86-64
    True
_MM_EXCEPT_DENORMx86 or x86-64
    See _mm_setcsr
_MM_EXCEPT_DIV_ZEROx86 or x86-64
    See _mm_setcsr
_MM_EXCEPT_INEXACTx86 or x86-64
    See _mm_setcsr
_MM_EXCEPT_INVALIDx86 or x86-64
    See _mm_setcsr
_MM_EXCEPT_MASKx86 or x86-64
    See _MM_GET_EXCEPTION_STATE
_MM_EXCEPT_OVERFLOWx86 or x86-64
    See _mm_setcsr
_MM_EXCEPT_UNDERFLOWx86 or x86-64
    See _mm_setcsr
_MM_FLUSH_ZERO_MASKx86 or x86-64
    See _MM_GET_FLUSH_ZERO_MODE
_MM_FLUSH_ZERO_OFFx86 or x86-64
    See _mm_setcsr
_MM_FLUSH_ZERO_ONx86 or x86-64
    See _mm_setcsr
_MM_FROUND_CEILx86 or x86-64
    round up and do not suppress exceptions
_MM_FROUND_CUR_DIRECTIONx86 or x86-64
    use MXCSR.RC; see vendor::_MM_SET_ROUNDING_MODE
_MM_FROUND_FLOORx86 or x86-64
    round down and do not suppress exceptions
_MM_FROUND_NEARBYINTx86 or x86-64
    use MXCSR.RC and suppress exceptions; see vendor::_MM_SET_ROUNDING_MODE
_MM_FROUND_NINTx86 or x86-64
    round to nearest and do not suppress exceptions
_MM_FROUND_NO_EXCx86 or x86-64
    suppress exceptions
_MM_FROUND_RAISE_EXCx86 or x86-64
    do not suppress exceptions
_MM_FROUND_RINTx86 or x86-64
    use MXCSR.RC and do not suppress exceptions; see vendor::_MM_SET_ROUNDING_MODE
_MM_FROUND_TO_NEAREST_INTx86 or x86-64
    round to nearest
_MM_FROUND_TO_NEG_INFx86 or x86-64
    round down
_MM_FROUND_TO_POS_INFx86 or x86-64
    round up
_MM_FROUND_TO_ZEROx86 or x86-64
    truncate
_MM_FROUND_TRUNCx86 or x86-64
    truncate and do not suppress exceptions
_MM_HINT_ET0x86 or x86-64
    See _mm_prefetch.
_MM_HINT_ET1x86 or x86-64
    See _mm_prefetch.
_MM_HINT_NTAx86 or x86-64
    See _mm_prefetch.
_MM_HINT_T0x86 or x86-64
    See _mm_prefetch.
_MM_HINT_T1x86 or x86-64
    See _mm_prefetch.
_MM_HINT_T2x86 or x86-64
    See _mm_prefetch.
_MM_MANT_NORM_1_2x86 or x86-64
    interval [1, 2)
_MM_MANT_NORM_P5_1x86 or x86-64
    interval [0.5, 1)
_MM_MANT_NORM_P5_2x86 or x86-64
    interval [0.5, 2)
_MM_MANT_NORM_P75_1P5x86 or x86-64
    interval [0.75, 1.5)
_MM_MANT_SIGN_NANx86 or x86-64
    DEST = NaN if sign(SRC) = 1
_MM_MANT_SIGN_SRCx86 or x86-64
    sign = sign(SRC)
_MM_MANT_SIGN_ZEROx86 or x86-64
    sign = 0
_MM_MASK_DENORMx86 or x86-64
    See _mm_setcsr
_MM_MASK_DIV_ZEROx86 or x86-64
    See _mm_setcsr
_MM_MASK_INEXACTx86 or x86-64
    See _mm_setcsr
_MM_MASK_INVALIDx86 or x86-64
    See _mm_setcsr
_MM_MASK_MASKx86 or x86-64
    See _MM_GET_EXCEPTION_MASK
_MM_MASK_OVERFLOWx86 or x86-64
    See _mm_setcsr
_MM_MASK_UNDERFLOWx86 or x86-64
    See _mm_setcsr
_MM_PERM_AAAAx86 or x86-64
_MM_PERM_AAABx86 or x86-64
_MM_PERM_AAACx86 or x86-64
_MM_PERM_AAADx86 or x86-64
_MM_PERM_AABAx86 or x86-64
_MM_PERM_AABBx86 or x86-64
_MM_PERM_AABCx86 or x86-64
_MM_PERM_AABDx86 or x86-64
_MM_PERM_AACAx86 or x86-64
_MM_PERM_AACBx86 or x86-64
_MM_PERM_AACCx86 or x86-64
_MM_PERM_AACDx86 or x86-64
_MM_PERM_AADAx86 or x86-64
_MM_PERM_AADBx86 or x86-64
_MM_PERM_AADCx86 or x86-64
_MM_PERM_AADDx86 or x86-64
_MM_PERM_ABAAx86 or x86-64
_MM_PERM_ABABx86 or x86-64
_MM_PERM_ABACx86 or x86-64
_MM_PERM_ABADx86 or x86-64
_MM_PERM_ABBAx86 or x86-64
_MM_PERM_ABBBx86 or x86-64
_MM_PERM_ABBCx86 or x86-64
_MM_PERM_ABBDx86 or x86-64
_MM_PERM_ABCAx86 or x86-64
_MM_PERM_ABCBx86 or x86-64
_MM_PERM_ABCCx86 or x86-64
_MM_PERM_ABCDx86 or x86-64
_MM_PERM_ABDAx86 or x86-64
_MM_PERM_ABDBx86 or x86-64
_MM_PERM_ABDCx86 or x86-64
_MM_PERM_ABDDx86 or x86-64
_MM_PERM_ACAAx86 or x86-64
_MM_PERM_ACABx86 or x86-64
_MM_PERM_ACACx86 or x86-64
_MM_PERM_ACADx86 or x86-64
_MM_PERM_ACBAx86 or x86-64
_MM_PERM_ACBBx86 or x86-64
_MM_PERM_ACBCx86 or x86-64
_MM_PERM_ACBDx86 or x86-64
_MM_PERM_ACCAx86 or x86-64
_MM_PERM_ACCBx86 or x86-64
_MM_PERM_ACCCx86 or x86-64
_MM_PERM_ACCDx86 or x86-64
_MM_PERM_ACDAx86 or x86-64
_MM_PERM_ACDBx86 or x86-64
_MM_PERM_ACDCx86 or x86-64
_MM_PERM_ACDDx86 or x86-64
_MM_PERM_ADAAx86 or x86-64
_MM_PERM_ADABx86 or x86-64
_MM_PERM_ADACx86 or x86-64
_MM_PERM_ADADx86 or x86-64
_MM_PERM_ADBAx86 or x86-64
_MM_PERM_ADBBx86 or x86-64
_MM_PERM_ADBCx86 or x86-64
_MM_PERM_ADBDx86 or x86-64
_MM_PERM_ADCAx86 or x86-64
_MM_PERM_ADCBx86 or x86-64
_MM_PERM_ADCCx86 or x86-64
_MM_PERM_ADCDx86 or x86-64
_MM_PERM_ADDAx86 or x86-64
_MM_PERM_ADDBx86 or x86-64
_MM_PERM_ADDCx86 or x86-64
_MM_PERM_ADDDx86 or x86-64
_MM_PERM_BAAAx86 or x86-64
_MM_PERM_BAABx86 or x86-64
_MM_PERM_BAACx86 or x86-64
_MM_PERM_BAADx86 or x86-64
_MM_PERM_BABAx86 or x86-64
_MM_PERM_BABBx86 or x86-64
_MM_PERM_BABCx86 or x86-64
_MM_PERM_BABDx86 or x86-64
_MM_PERM_BACAx86 or x86-64
_MM_PERM_BACBx86 or x86-64
_MM_PERM_BACCx86 or x86-64
_MM_PERM_BACDx86 or x86-64
_MM_PERM_BADAx86 or x86-64
_MM_PERM_BADBx86 or x86-64
_MM_PERM_BADCx86 or x86-64
_MM_PERM_BADDx86 or x86-64
_MM_PERM_BBAAx86 or x86-64
_MM_PERM_BBABx86 or x86-64
_MM_PERM_BBACx86 or x86-64
_MM_PERM_BBADx86 or x86-64
_MM_PERM_BBBAx86 or x86-64
_MM_PERM_BBBBx86 or x86-64
_MM_PERM_BBBCx86 or x86-64
_MM_PERM_BBBDx86 or x86-64
_MM_PERM_BBCAx86 or x86-64
_MM_PERM_BBCBx86 or x86-64
_MM_PERM_BBCCx86 or x86-64
_MM_PERM_BBCDx86 or x86-64
_MM_PERM_BBDAx86 or x86-64
_MM_PERM_BBDBx86 or x86-64
_MM_PERM_BBDCx86 or x86-64
_MM_PERM_BBDDx86 or x86-64
_MM_PERM_BCAAx86 or x86-64
_MM_PERM_BCABx86 or x86-64
_MM_PERM_BCACx86 or x86-64
_MM_PERM_BCADx86 or x86-64
_MM_PERM_BCBAx86 or x86-64
_MM_PERM_BCBBx86 or x86-64
_MM_PERM_BCBCx86 or x86-64
_MM_PERM_BCBDx86 or x86-64
_MM_PERM_BCCAx86 or x86-64
_MM_PERM_BCCBx86 or x86-64
_MM_PERM_BCCCx86 or x86-64
_MM_PERM_BCCDx86 or x86-64
_MM_PERM_BCDAx86 or x86-64
_MM_PERM_BCDBx86 or x86-64
_MM_PERM_BCDCx86 or x86-64
_MM_PERM_BCDDx86 or x86-64
_MM_PERM_BDAAx86 or x86-64
_MM_PERM_BDABx86 or x86-64
_MM_PERM_BDACx86 or x86-64
_MM_PERM_BDADx86 or x86-64
_MM_PERM_BDBAx86 or x86-64
_MM_PERM_BDBBx86 or x86-64
_MM_PERM_BDBCx86 or x86-64
_MM_PERM_BDBDx86 or x86-64
_MM_PERM_BDCAx86 or x86-64
_MM_PERM_BDCBx86 or x86-64
_MM_PERM_BDCCx86 or x86-64
_MM_PERM_BDCDx86 or x86-64
_MM_PERM_BDDAx86 or x86-64
_MM_PERM_BDDBx86 or x86-64
_MM_PERM_BDDCx86 or x86-64
_MM_PERM_BDDDx86 or x86-64
_MM_PERM_CAAAx86 or x86-64
_MM_PERM_CAABx86 or x86-64
_MM_PERM_CAACx86 or x86-64
_MM_PERM_CAADx86 or x86-64
_MM_PERM_CABAx86 or x86-64
_MM_PERM_CABBx86 or x86-64
_MM_PERM_CABCx86 or x86-64
_MM_PERM_CABDx86 or x86-64
_MM_PERM_CACAx86 or x86-64
_MM_PERM_CACBx86 or x86-64
_MM_PERM_CACCx86 or x86-64
_MM_PERM_CACDx86 or x86-64
_MM_PERM_CADAx86 or x86-64
_MM_PERM_CADBx86 or x86-64
_MM_PERM_CADCx86 or x86-64
_MM_PERM_CADDx86 or x86-64
_MM_PERM_CBAAx86 or x86-64
_MM_PERM_CBABx86 or x86-64
_MM_PERM_CBACx86 or x86-64
_MM_PERM_CBADx86 or x86-64
_MM_PERM_CBBAx86 or x86-64
_MM_PERM_CBBBx86 or x86-64
_MM_PERM_CBBCx86 or x86-64
_MM_PERM_CBBDx86 or x86-64
_MM_PERM_CBCAx86 or x86-64
_MM_PERM_CBCBx86 or x86-64
_MM_PERM_CBCCx86 or x86-64
_MM_PERM_CBCDx86 or x86-64
_MM_PERM_CBDAx86 or x86-64
_MM_PERM_CBDBx86 or x86-64
_MM_PERM_CBDCx86 or x86-64
_MM_PERM_CBDDx86 or x86-64
_MM_PERM_CCAAx86 or x86-64
_MM_PERM_CCABx86 or x86-64
_MM_PERM_CCACx86 or x86-64
_MM_PERM_CCADx86 or x86-64
_MM_PERM_CCBAx86 or x86-64
_MM_PERM_CCBBx86 or x86-64
_MM_PERM_CCBCx86 or x86-64
_MM_PERM_CCBDx86 or x86-64
_MM_PERM_CCCAx86 or x86-64
_MM_PERM_CCCBx86 or x86-64
_MM_PERM_CCCCx86 or x86-64
_MM_PERM_CCCDx86 or x86-64
_MM_PERM_CCDAx86 or x86-64
_MM_PERM_CCDBx86 or x86-64
_MM_PERM_CCDCx86 or x86-64
_MM_PERM_CCDDx86 or x86-64
_MM_PERM_CDAAx86 or x86-64
_MM_PERM_CDABx86 or x86-64
_MM_PERM_CDACx86 or x86-64
_MM_PERM_CDADx86 or x86-64
_MM_PERM_CDBAx86 or x86-64
_MM_PERM_CDBBx86 or x86-64
_MM_PERM_CDBCx86 or x86-64
_MM_PERM_CDBDx86 or x86-64
_MM_PERM_CDCAx86 or x86-64
_MM_PERM_CDCBx86 or x86-64
_MM_PERM_CDCCx86 or x86-64
_MM_PERM_CDCDx86 or x86-64
_MM_PERM_CDDAx86 or x86-64
_MM_PERM_CDDBx86 or x86-64
_MM_PERM_CDDCx86 or x86-64
_MM_PERM_CDDDx86 or x86-64
_MM_PERM_DAAAx86 or x86-64
_MM_PERM_DAABx86 or x86-64
_MM_PERM_DAACx86 or x86-64
_MM_PERM_DAADx86 or x86-64
_MM_PERM_DABAx86 or x86-64
_MM_PERM_DABBx86 or x86-64
_MM_PERM_DABCx86 or x86-64
_MM_PERM_DABDx86 or x86-64
_MM_PERM_DACAx86 or x86-64
_MM_PERM_DACBx86 or x86-64
_MM_PERM_DACCx86 or x86-64
_MM_PERM_DACDx86 or x86-64
_MM_PERM_DADAx86 or x86-64
_MM_PERM_DADBx86 or x86-64
_MM_PERM_DADCx86 or x86-64
_MM_PERM_DADDx86 or x86-64
_MM_PERM_DBAAx86 or x86-64
_MM_PERM_DBABx86 or x86-64
_MM_PERM_DBACx86 or x86-64
_MM_PERM_DBADx86 or x86-64
_MM_PERM_DBBAx86 or x86-64
_MM_PERM_DBBBx86 or x86-64
_MM_PERM_DBBCx86 or x86-64
_MM_PERM_DBBDx86 or x86-64
_MM_PERM_DBCAx86 or x86-64
_MM_PERM_DBCBx86 or x86-64
_MM_PERM_DBCCx86 or x86-64
_MM_PERM_DBCDx86 or x86-64
_MM_PERM_DBDAx86 or x86-64
_MM_PERM_DBDBx86 or x86-64
_MM_PERM_DBDCx86 or x86-64
_MM_PERM_DBDDx86 or x86-64
_MM_PERM_DCAAx86 or x86-64
_MM_PERM_DCABx86 or x86-64
_MM_PERM_DCACx86 or x86-64
_MM_PERM_DCADx86 or x86-64
_MM_PERM_DCBAx86 or x86-64
_MM_PERM_DCBBx86 or x86-64
_MM_PERM_DCBCx86 or x86-64
_MM_PERM_DCBDx86 or x86-64
_MM_PERM_DCCAx86 or x86-64
_MM_PERM_DCCBx86 or x86-64
_MM_PERM_DCCCx86 or x86-64
_MM_PERM_DCCDx86 or x86-64
_MM_PERM_DCDAx86 or x86-64
_MM_PERM_DCDBx86 or x86-64
_MM_PERM_DCDCx86 or x86-64
_MM_PERM_DCDDx86 or x86-64
_MM_PERM_DDAAx86 or x86-64
_MM_PERM_DDABx86 or x86-64
_MM_PERM_DDACx86 or x86-64
_MM_PERM_DDADx86 or x86-64
_MM_PERM_DDBAx86 or x86-64
_MM_PERM_DDBBx86 or x86-64
_MM_PERM_DDBCx86 or x86-64
_MM_PERM_DDBDx86 or x86-64
_MM_PERM_DDCAx86 or x86-64
_MM_PERM_DDCBx86 or x86-64
_MM_PERM_DDCCx86 or x86-64
_MM_PERM_DDCDx86 or x86-64
_MM_PERM_DDDAx86 or x86-64
_MM_PERM_DDDBx86 or x86-64
_MM_PERM_DDDCx86 or x86-64
_MM_PERM_DDDDx86 or x86-64
_MM_ROUND_DOWNx86 or x86-64
    See _mm_setcsr
_MM_ROUND_MASKx86 or x86-64
    See _MM_GET_ROUNDING_MODE
_MM_ROUND_NEARESTx86 or x86-64
    See _mm_setcsr
_MM_ROUND_TOWARD_ZEROx86 or x86-64
    See _mm_setcsr
_MM_ROUND_UPx86 or x86-64
    See _mm_setcsr
_SIDD_BIT_MASKx86 or x86-64
    Mask only: return the bit mask
_SIDD_CMP_EQUAL_ANYx86 or x86-64
    For each character in a, find if it is in b (Default)
_SIDD_CMP_EQUAL_EACHx86 or x86-64
    The strings defined by a and b are equal
_SIDD_CMP_EQUAL_ORDEREDx86 or x86-64
    Search for the defined substring in the target
_SIDD_CMP_RANGESx86 or x86-64
    For each character in a, determine if b[0] <= c <= b[1] or b[1] <= c <= b[2]...
_SIDD_LEAST_SIGNIFICANTx86 or x86-64
    Index only: return the least significant bit (Default)
_SIDD_MASKED_NEGATIVE_POLARITYx86 or x86-64
    Negates results only before the end of the string
_SIDD_MASKED_POSITIVE_POLARITYx86 or x86-64
    Do not negate results before the end of the string
_SIDD_MOST_SIGNIFICANTx86 or x86-64
    Index only: return the most significant bit
_SIDD_NEGATIVE_POLARITYx86 or x86-64
    Negates results
_SIDD_POSITIVE_POLARITYx86 or x86-64
    Do not negate results (Default)
_SIDD_SBYTE_OPSx86 or x86-64
    String contains signed 8-bit characters
_SIDD_SWORD_OPSx86 or x86-64
    String contains unsigned 16-bit characters
_SIDD_UBYTE_OPSx86 or x86-64
    String contains unsigned 8-bit characters (Default)
_SIDD_UNIT_MASKx86 or x86-64
    Mask only: return the byte mask
_SIDD_UWORD_OPSx86 or x86-64
    String contains unsigned 16-bit characters
_XCR_XFEATURE_ENABLED_MASKx86 or x86-64
    XFEATURE_ENABLED_MASK for XCR
_XABORT_CAPACITYExperimentalx86 or x86-64
    Transaction abort due to the transaction using too much memory.
_XABORT_CONFLICTExperimentalx86 or x86-64
    Transaction abort due to a memory conflict with another thread.
_XABORT_DEBUGExperimentalx86 or x86-64
    Transaction abort due to a debug trap.
_XABORT_EXPLICITExperimentalx86 or x86-64
    Transaction explicitly aborted with xabort. The parameter passed to xabort is available with _xabort_code(status).
_XABORT_NESTEDExperimentalx86 or x86-64
    Transaction abort in a inner nested transaction.
_XABORT_RETRYExperimentalx86 or x86-64
    Transaction retry is possible.
_XBEGIN_STARTEDExperimentalx86 or x86-64
    Transaction successfully started.

Functions

_MM_GET_EXCEPTION_MASK⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_GET_EXCEPTION_STATE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_GET_FLUSH_ZERO_MODE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_GET_ROUNDING_MODE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_SET_EXCEPTION_MASK⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_SET_EXCEPTION_STATE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_SET_FLUSH_ZERO_MODE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_SET_ROUNDING_MODE⚠Deprecated(x86 or x86-64) and sse
    See _mm_setcsr
_MM_TRANSPOSE4_PS⚠(x86 or x86-64) and sse
    Transpose the 4x4 matrix formed by 4 rows of __m128 in place.
__cpuid⚠x86 or x86-64
    See __cpuid_count.
__cpuid_count⚠x86 or x86-64
    Returns the result of the cpuid instruction for a given leaf (EAX) and sub_leaf (ECX).
__get_cpuid_max⚠x86 or x86-64
    Returns the highest-supported leaf (EAX) and sub-leaf (ECX) cpuid values.
__rdtscp⚠x86 or x86-64
    Reads the current value of the processor’s time-stamp counter and the IA32_TSC_AUX MSR.
_addcarry_u32⚠x86 or x86-64
    Adds unsigned 32-bit integers a and b with unsigned 8-bit carry-in c_in (carry or overflow flag), and store the unsigned 32-bit result in out, and the carry-out is returned (carry or overflow flag).
_addcarry_u64⚠
    Adds unsigned 64-bit integers a and b with unsigned 8-bit carry-in c_in (carry or overflow flag), and store the unsigned 64-bit result in out, and the carry-out is returned (carry or overflow flag).
_addcarryx_u32⚠(x86 or x86-64) and adx
    Adds unsigned 32-bit integers a and b with unsigned 8-bit carry-in c_in (carry or overflow flag), and store the unsigned 32-bit result in out, and the carry-out is returned (carry or overflow flag).
_addcarryx_u64⚠adx
    Adds unsigned 64-bit integers a and b with unsigned 8-bit carry-in c_in (carry or overflow flag), and store the unsigned 64-bit result in out, and the carry-out is returned (carry or overflow flag).
_andn_u32⚠(x86 or x86-64) and bmi1
    Bitwise logical AND of inverted a with b.
_andn_u64⚠bmi1
    Bitwise logical AND of inverted a with b.
_bextr2_u32⚠(x86 or x86-64) and bmi1
    Extracts bits of a specified by control into the least significant bits of the result.
_bextr2_u64⚠bmi1
    Extracts bits of a specified by control into the least significant bits of the result.
_bextr_u32⚠(x86 or x86-64) and bmi1
    Extracts bits in range [start, start + length) from a into the least significant bits of the result.
_bextr_u64⚠bmi1
    Extracts bits in range [start, start + length) from a into the least significant bits of the result.
_bextri_u32⚠(x86 or x86-64) and tbm
    Extracts bits of a specified by control into the least significant bits of the result.
_bextri_u64⚠tbm
    Extracts bits of a specified by control into the least significant bits of the result.
_bittest⚠x86 or x86-64
    Returns the bit in position b of the memory addressed by p.
_bittest64⚠
    Returns the bit in position b of the memory addressed by p.
_bittestandcomplement⚠x86 or x86-64
    Returns the bit in position b of the memory addressed by p, then inverts that bit.
_bittestandcomplement64⚠
    Returns the bit in position b of the memory addressed by p, then inverts that bit.
_bittestandreset⚠x86 or x86-64
    Returns the bit in position b of the memory addressed by p, then resets that bit to 0.
_bittestandreset64⚠
    Returns the bit in position b of the memory addressed by p, then resets that bit to 0.
_bittestandset⚠x86 or x86-64
    Returns the bit in position b of the memory addressed by p, then sets the bit to 1.
_bittestandset64⚠
    Returns the bit in position b of the memory addressed by p, then sets the bit to 1.
_blcfill_u32⚠(x86 or x86-64) and tbm
    Clears all bits below the least significant zero bit of x.
_blcfill_u64⚠tbm
    Clears all bits below the least significant zero bit of x.
_blci_u32⚠(x86 or x86-64) and tbm
    Sets all bits of x to 1 except for the least significant zero bit.
_blci_u64⚠tbm
    Sets all bits of x to 1 except for the least significant zero bit.
_blcic_u32⚠(x86 or x86-64) and tbm
    Sets the least significant zero bit of x and clears all other bits.
_blcic_u64⚠tbm
    Sets the least significant zero bit of x and clears all other bits.
_blcmsk_u32⚠(x86 or x86-64) and tbm
    Sets the least significant zero bit of x and clears all bits above that bit.
_blcmsk_u64⚠tbm
    Sets the least significant zero bit of x and clears all bits above that bit.
_blcs_u32⚠(x86 or x86-64) and tbm
    Sets the least significant zero bit of x.
_blcs_u64⚠tbm
    Sets the least significant zero bit of x.
_blsfill_u32⚠(x86 or x86-64) and tbm
    Sets all bits of x below the least significant one.
_blsfill_u64⚠tbm
    Sets all bits of x below the least significant one.
_blsi_u32⚠(x86 or x86-64) and bmi1
    Extracts lowest set isolated bit.
_blsi_u64⚠bmi1
    Extracts lowest set isolated bit.
_blsic_u32⚠(x86 or x86-64) and tbm
    Clears least significant bit and sets all other bits.
_blsic_u64⚠tbm
    Clears least significant bit and sets all other bits.
_blsmsk_u32⚠(x86 or x86-64) and bmi1
    Gets mask up to lowest set bit.
_blsmsk_u64⚠bmi1
    Gets mask up to lowest set bit.
_blsr_u32⚠(x86 or x86-64) and bmi1
    Resets the lowest set bit of x.
_blsr_u64⚠bmi1
    Resets the lowest set bit of x.
_bswap⚠x86 or x86-64
    Returns an integer with the reversed byte order of x
_bswap64⚠
    Returns an integer with the reversed byte order of x
_bzhi_u32⚠(x86 or x86-64) and bmi2
    Zeroes higher bits of a >= index.
_bzhi_u64⚠bmi2
    Zeroes higher bits of a >= index.
_cvtmask8_u32⚠(x86 or x86-64) and avx512dq
    Convert 8-bit mask a to a 32-bit integer value and store the result in dst.
_cvtmask16_u32⚠(x86 or x86-64) and avx512f
    Convert 16-bit mask a into an integer value, and store the result in dst.
_cvtmask32_u32⚠(x86 or x86-64) and avx512bw
    Convert 32-bit mask a into an integer value, and store the result in dst.
_cvtmask64_u64⚠avx512bw
    Convert 64-bit mask a into an integer value, and store the result in dst.
_cvtu32_mask8⚠(x86 or x86-64) and avx512dq
    Convert 32-bit integer value a to an 8-bit mask and store the result in dst.
_cvtu32_mask16⚠(x86 or x86-64) and avx512f
    Convert 32-bit integer value a to an 16-bit mask and store the result in dst.
_cvtu32_mask32⚠(x86 or x86-64) and avx512bw
    Convert integer value a into an 32-bit mask, and store the result in k.
_cvtu64_mask64⚠avx512bw
    Convert integer value a into an 64-bit mask, and store the result in k.
_fxrstor⚠(x86 or x86-64) and fxsr
    Restores the XMM, MMX, MXCSR, and x87 FPU registers from the 512-byte-long 16-byte-aligned memory region mem_addr.
_fxrstor64⚠fxsr
    Restores the XMM, MMX, MXCSR, and x87 FPU registers from the 512-byte-long 16-byte-aligned memory region mem_addr.
_fxsave⚠(x86 or x86-64) and fxsr
    Saves the x87 FPU, MMX technology, XMM, and MXCSR registers to the 512-byte-long 16-byte-aligned memory region mem_addr.
_fxsave64⚠fxsr
    Saves the x87 FPU, MMX technology, XMM, and MXCSR registers to the 512-byte-long 16-byte-aligned memory region mem_addr.
_kadd_mask8⚠(x86 or x86-64) and avx512dq
    Add 8-bit masks a and b, and store the result in dst.
_kadd_mask16⚠(x86 or x86-64) and avx512dq
    Add 16-bit masks a and b, and store the result in dst.
_kadd_mask32⚠(x86 or x86-64) and avx512bw
    Add 32-bit masks in a and b, and store the result in k.
_kadd_mask64⚠(x86 or x86-64) and avx512bw
    Add 64-bit masks in a and b, and store the result in k.
_kand_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise AND of 8-bit masks a and b, and store the result in dst.
_kand_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of 16-bit masks a and b, and store the result in k.
_kand_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 32-bit masks a and b, and store the result in k.
_kand_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 64-bit masks a and b, and store the result in k.
_kandn_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise AND NOT of 8-bit masks a and b, and store the result in dst.
_kandn_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 16-bit masks a and then AND with b, and store the result in k.
_kandn_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 32-bit masks a and then AND with b, and store the result in k.
_kandn_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 64-bit masks a and then AND with b, and store the result in k.
_knot_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise NOT of 8-bit mask a, and store the result in dst.
_knot_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 16-bit mask a, and store the result in k.
_knot_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 32-bit mask a, and store the result in k.
_knot_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 64-bit mask a, and store the result in k.
_kor_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise OR of 8-bit masks a and b, and store the result in dst.
_kor_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 16-bit masks a and b, and store the result in k.
_kor_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 32-bit masks a and b, and store the result in k.
_kor_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 64-bit masks a and b, and store the result in k.
_kortest_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of 8-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst. If the result is all ones, store 1 in all_ones, otherwise store 0 in all_ones.
_kortest_mask16_u8⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 16-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst. If the result is all ones, store 1 in all_ones, otherwise store 0 in all_ones.
_kortest_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 32-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst. If the result is all ones, store 1 in all_ones, otherwise store 0 in all_ones.
_kortest_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 64-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst. If the result is all ones, store 1 in all_ones, otherwise store 0 in all_ones.
_kortestc_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of 8-bit masks a and b. If the result is all ones, store 1 in dst, otherwise store 0 in dst.
_kortestc_mask16_u8⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 16-bit masks a and b. If the result is all ones, store 1 in dst, otherwise store 0 in dst.
_kortestc_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 32-bit masks a and b. If the result is all ones, store 1 in dst, otherwise store 0 in dst.
_kortestc_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 64-bit masks a and b. If the result is all ones, store 1 in dst, otherwise store 0 in dst.
_kortestz_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of 8-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_kortestz_mask16_u8⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 16-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_kortestz_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 32-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_kortestz_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise OR of 64-bit masks a and b. If the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_kshiftli_mask8⚠(x86 or x86-64) and avx512dq
    Shift 8-bit mask a left by count bits while shifting in zeros, and store the result in dst.
_kshiftli_mask16⚠(x86 or x86-64) and avx512f
    Shift 16-bit mask a left by count bits while shifting in zeros, and store the result in dst.
_kshiftli_mask32⚠(x86 or x86-64) and avx512bw
    Shift the bits of 32-bit mask a left by count while shifting in zeros, and store the least significant 32 bits of the result in k.
_kshiftli_mask64⚠(x86 or x86-64) and avx512bw
    Shift the bits of 64-bit mask a left by count while shifting in zeros, and store the least significant 32 bits of the result in k.
_kshiftri_mask8⚠(x86 or x86-64) and avx512dq
    Shift 8-bit mask a right by count bits while shifting in zeros, and store the result in dst.
_kshiftri_mask16⚠(x86 or x86-64) and avx512f
    Shift 16-bit mask a right by count bits while shifting in zeros, and store the result in dst.
_kshiftri_mask32⚠(x86 or x86-64) and avx512bw
    Shift the bits of 32-bit mask a right by count while shifting in zeros, and store the least significant 32 bits of the result in k.
_kshiftri_mask64⚠(x86 or x86-64) and avx512bw
    Shift the bits of 64-bit mask a right by count while shifting in zeros, and store the least significant 32 bits of the result in k.
_ktest_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of 8-bit masks a and b, and if the result is all zeros, store 1 in dst, otherwise store 0 in dst. Compute the bitwise NOT of a and then AND with b, if the result is all zeros, store 1 in and_not, otherwise store 0 in and_not.
_ktest_mask16_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of 16-bit masks a and b, and if the result is all zeros, store 1 in dst, otherwise store 0 in dst. Compute the bitwise NOT of a and then AND with b, if the result is all zeros, store 1 in and_not, otherwise store 0 in and_not.
_ktest_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 32-bit masks a and b, and if the result is all zeros, store 1 in dst, otherwise store 0 in dst. Compute the bitwise NOT of a and then AND with b, if the result is all zeros, store 1 in and_not, otherwise store 0 in and_not.
_ktest_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 64-bit masks a and b, and if the result is all zeros, store 1 in dst, otherwise store 0 in dst. Compute the bitwise NOT of a and then AND with b, if the result is all zeros, store 1 in and_not, otherwise store 0 in and_not.
_ktestc_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of 8-bit mask a and then AND with 8-bit mask b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestc_mask16_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of 16-bit mask a and then AND with 16-bit mask b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestc_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 32-bit mask a and then AND with 16-bit mask b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestc_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NOT of 64-bit mask a and then AND with 8-bit mask b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestz_mask8_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of 8-bit masks a and b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestz_mask16_u8⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of 16-bit masks a and b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestz_mask32_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 32-bit masks a and b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_ktestz_mask64_u8⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of 64-bit masks a and b, if the result is all zeros, store 1 in dst, otherwise store 0 in dst.
_kxnor_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise XNOR of 8-bit masks a and b, and store the result in dst.
_kxnor_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise XNOR of 16-bit masks a and b, and store the result in k.
_kxnor_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise XNOR of 32-bit masks a and b, and store the result in k.
_kxnor_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise XNOR of 64-bit masks a and b, and store the result in k.
_kxor_mask8⚠(x86 or x86-64) and avx512dq
    Bitwise XOR of 8-bit masks a and b, and store the result in dst.
_kxor_mask16⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of 16-bit masks a and b, and store the result in k.
_kxor_mask32⚠(x86 or x86-64) and avx512bw
    Compute the bitwise XOR of 32-bit masks a and b, and store the result in k.
_kxor_mask64⚠(x86 or x86-64) and avx512bw
    Compute the bitwise XOR of 64-bit masks a and b, and store the result in k.
_load_mask8⚠(x86 or x86-64) and avx512dq
    Load 8-bit mask from memory
_load_mask16⚠(x86 or x86-64) and avx512f
    Load 16-bit mask from memory
_load_mask32⚠(x86 or x86-64) and avx512bw
    Load 32-bit mask from memory into k.
_load_mask64⚠(x86 or x86-64) and avx512bw
    Load 64-bit mask from memory into k.
_lzcnt_u32⚠(x86 or x86-64) and lzcnt
    Counts the leading most significant zero bits.
_lzcnt_u64⚠lzcnt
    Counts the leading most significant zero bits.
_mm256_abs_epi8⚠(x86 or x86-64) and avx2
    Computes the absolute values of packed 8-bit integers in a.
_mm256_abs_epi16⚠(x86 or x86-64) and avx2
    Computes the absolute values of packed 16-bit integers in a.
_mm256_abs_epi32⚠(x86 or x86-64) and avx2
    Computes the absolute values of packed 32-bit integers in a.
_mm256_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst.
_mm256_add_epi8⚠(x86 or x86-64) and avx2
    Adds packed 8-bit integers in a and b.
_mm256_add_epi16⚠(x86 or x86-64) and avx2
    Adds packed 16-bit integers in a and b.
_mm256_add_epi32⚠(x86 or x86-64) and avx2
    Adds packed 32-bit integers in a and b.
_mm256_add_epi64⚠(x86 or x86-64) and avx2
    Adds packed 64-bit integers in a and b.
_mm256_add_pd⚠(x86 or x86-64) and avx
    Adds packed double-precision (64-bit) floating-point elements in a and b.
_mm256_add_ps⚠(x86 or x86-64) and avx
    Adds packed single-precision (32-bit) floating-point elements in a and b.
_mm256_adds_epi8⚠(x86 or x86-64) and avx2
    Adds packed 8-bit integers in a and b using saturation.
_mm256_adds_epi16⚠(x86 or x86-64) and avx2
    Adds packed 16-bit integers in a and b using saturation.
_mm256_adds_epu8⚠(x86 or x86-64) and avx2
    Adds packed unsigned 8-bit integers in a and b using saturation.
_mm256_adds_epu16⚠(x86 or x86-64) and avx2
    Adds packed unsigned 16-bit integers in a and b using saturation.
_mm256_addsub_pd⚠(x86 or x86-64) and avx
    Alternatively adds and subtracts packed double-precision (64-bit) floating-point elements in a to/from packed elements in b.
_mm256_addsub_ps⚠(x86 or x86-64) and avx
    Alternatively adds and subtracts packed single-precision (32-bit) floating-point elements in a to/from packed elements in b.
_mm256_aesdec_epi128⚠(x86 or x86-64) and vaes
    Performs one round of an AES decryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm256_aesdeclast_epi128⚠(x86 or x86-64) and vaes
    Performs the last round of an AES decryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm256_aesenc_epi128⚠(x86 or x86-64) and vaes
    Performs one round of an AES encryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm256_aesenclast_epi128⚠(x86 or x86-64) and vaes
    Performs the last round of an AES encryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm256_alignr_epi8⚠(x86 or x86-64) and avx2
    Concatenates pairs of 16-byte blocks in a and b into a 32-byte temporary result, shifts the result right by n bytes, and returns the low 16 bytes.
_mm256_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 32 bytes (8 elements) in dst.
_mm256_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 32 bytes (4 elements) in dst.
_mm256_and_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of a packed double-precision (64-bit) floating-point elements in a and b.
_mm256_and_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of packed single-precision (32-bit) floating-point elements in a and b.
_mm256_and_si256⚠(x86 or x86-64) and avx2
    Computes the bitwise AND of 256 bits (representing integer data) in a and b.
_mm256_andnot_pd⚠(x86 or x86-64) and avx
    Computes the bitwise NOT of packed double-precision (64-bit) floating-point elements in a, and then AND with b.
_mm256_andnot_ps⚠(x86 or x86-64) and avx
    Computes the bitwise NOT of packed single-precision (32-bit) floating-point elements in a and then AND with b.
_mm256_andnot_si256⚠(x86 or x86-64) and avx2
    Computes the bitwise NOT of 256 bits (representing integer data) in a and then AND with b.
_mm256_avg_epu8⚠(x86 or x86-64) and avx2
    Averages packed unsigned 8-bit integers in a and b.
_mm256_avg_epu16⚠(x86 or x86-64) and avx2
    Averages packed unsigned 16-bit integers in a and b.
_mm256_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg,avx512vl
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm256_blend_epi16⚠(x86 or x86-64) and avx2
    Blends packed 16-bit integers from a and b using control mask IMM8.
_mm256_blend_epi32⚠(x86 or x86-64) and avx2
    Blends packed 32-bit integers from a and b using control mask IMM8.
_mm256_blend_pd⚠(x86 or x86-64) and avx
    Blends packed double-precision (64-bit) floating-point elements from a and b using control mask imm8.
_mm256_blend_ps⚠(x86 or x86-64) and avx
    Blends packed single-precision (32-bit) floating-point elements from a and b using control mask imm8.
_mm256_blendv_epi8⚠(x86 or x86-64) and avx2
    Blends packed 8-bit integers from a and b using mask.
_mm256_blendv_pd⚠(x86 or x86-64) and avx
    Blends packed double-precision (64-bit) floating-point elements from a and b using c as a mask.
_mm256_blendv_ps⚠(x86 or x86-64) and avx
    Blends packed single-precision (32-bit) floating-point elements from a and b using c as a mask.
_mm256_broadcast_f32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst.
_mm256_broadcast_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst.
_mm256_broadcast_f64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst.
_mm256_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst.
_mm256_broadcast_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed 32-bit integers from a to all elements of dst.
_mm256_broadcast_i64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst.
_mm256_broadcast_pd⚠(x86 or x86-64) and avx
    Broadcasts 128 bits from memory (composed of 2 packed double-precision (64-bit) floating-point elements) to all elements of the returned vector.
_mm256_broadcast_ps⚠(x86 or x86-64) and avx
    Broadcasts 128 bits from memory (composed of 4 packed single-precision (32-bit) floating-point elements) to all elements of the returned vector.
_mm256_broadcast_sd⚠(x86 or x86-64) and avx
    Broadcasts a double-precision (64-bit) floating-point element from memory to all elements of the returned vector.
_mm256_broadcast_ss⚠(x86 or x86-64) and avx
    Broadcasts a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.
_mm256_broadcastb_epi8⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 8-bit integer from a to all elements of the 256-bit returned value.
_mm256_broadcastd_epi32⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 32-bit integer from a to all elements of the 256-bit returned value.
_mm256_broadcastmb_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Broadcast the low 8-bits from input mask k to all 64-bit elements of dst.
_mm256_broadcastmw_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Broadcast the low 16-bits from input mask k to all 32-bit elements of dst.
_mm256_broadcastq_epi64⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 64-bit integer from a to all elements of the 256-bit returned value.
_mm256_broadcastsd_pd⚠(x86 or x86-64) and avx2
    Broadcasts the low double-precision (64-bit) floating-point element from a to all elements of the 256-bit returned value.
_mm256_broadcastsi128_si256⚠(x86 or x86-64) and avx2
    Broadcasts 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.
_mm256_broadcastss_ps⚠(x86 or x86-64) and avx2
    Broadcasts the low single-precision (32-bit) floating-point element from a to all elements of the 256-bit returned value.
_mm256_broadcastw_epi16⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 16-bit integer from a to all elements of the 256-bit returned value
_mm256_bslli_epi128⚠(x86 or x86-64) and avx2
    Shifts 128-bit lanes in a left by imm8 bytes while shifting in zeros.
_mm256_bsrli_epi128⚠(x86 or x86-64) and avx2
    Shifts 128-bit lanes in a right by imm8 bytes while shifting in zeros.
_mm256_castpd128_pd256⚠(x86 or x86-64) and avx
    Casts vector of type __m128d to type __m256d; the upper 128 bits of the result are undefined.
_mm256_castpd256_pd128⚠(x86 or x86-64) and avx
    Casts vector of type __m256d to type __m128d.
_mm256_castpd_ps⚠(x86 or x86-64) and avx
    Cast vector of type __m256d to type __m256.
_mm256_castpd_si256⚠(x86 or x86-64) and avx
    Casts vector of type __m256d to type __m256i.
_mm256_castps128_ps256⚠(x86 or x86-64) and avx
    Casts vector of type __m128 to type __m256; the upper 128 bits of the result are undefined.
_mm256_castps256_ps128⚠(x86 or x86-64) and avx
    Casts vector of type __m256 to type __m128.
_mm256_castps_pd⚠(x86 or x86-64) and avx
    Cast vector of type __m256 to type __m256d.
_mm256_castps_si256⚠(x86 or x86-64) and avx
    Casts vector of type __m256 to type __m256i.
_mm256_castsi128_si256⚠(x86 or x86-64) and avx
    Casts vector of type __m128i to type __m256i; the upper 128 bits of the result are undefined.
_mm256_castsi256_pd⚠(x86 or x86-64) and avx
    Casts vector of type __m256i to type __m256d.
_mm256_castsi256_ps⚠(x86 or x86-64) and avx
    Casts vector of type __m256i to type __m256.
_mm256_castsi256_si128⚠(x86 or x86-64) and avx
    Casts vector of type __m256i to type __m128i.
_mm256_ceil_pd⚠(x86 or x86-64) and avx
    Rounds packed double-precision (64-bit) floating point elements in a toward positive infinity.
_mm256_ceil_ps⚠(x86 or x86-64) and avx
    Rounds packed single-precision (32-bit) floating point elements in a toward positive infinity.
_mm256_clmulepi64_epi128⚠(x86 or x86-64) and vpclmulqdq
    Performs a carry-less multiplication of two 64-bit polynomials over the finite field GF(2) - in each of the 2 128-bit lanes.
_mm256_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_pd⚠(x86 or x86-64) and avx
    Compares packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by IMM5.
_mm256_cmp_pd_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmp_ps⚠(x86 or x86-64) and avx
    Compares packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by IMM5.
_mm256_cmp_ps_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmpeq_epi8⚠(x86 or x86-64) and avx2
    Compares packed 8-bit integers in a and b for equality.
_mm256_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epi16⚠(x86 or x86-64) and avx2
    Compares packed 16-bit integers in a and b for equality.
_mm256_cmpeq_epi32⚠(x86 or x86-64) and avx2
    Compares packed 32-bit integers in a and b for equality.
_mm256_cmpeq_epi64⚠(x86 or x86-64) and avx2
    Compares packed 64-bit integers in a and b for equality.
_mm256_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm256_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm256_cmpgt_epi8⚠(x86 or x86-64) and avx2
    Compares packed 8-bit integers in a and b for greater-than.
_mm256_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epi16⚠(x86 or x86-64) and avx2
    Compares packed 16-bit integers in a and b for greater-than.
_mm256_cmpgt_epi32⚠(x86 or x86-64) and avx2
    Compares packed 32-bit integers in a and b for greater-than.
_mm256_cmpgt_epi64⚠(x86 or x86-64) and avx2
    Compares packed 64-bit integers in a and b for greater-than.
_mm256_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm256_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmple_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm256_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm256_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm256_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm256_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm256_cvtepi8_epi16⚠(x86 or x86-64) and avx2
    Sign-extend 8-bit integers to 16-bit integers.
_mm256_cvtepi8_epi32⚠(x86 or x86-64) and avx2
    Sign-extend 8-bit integers to 32-bit integers.
_mm256_cvtepi8_epi64⚠(x86 or x86-64) and avx2
    Sign-extend 8-bit integers to 64-bit integers.
_mm256_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm256_cvtepi16_epi32⚠(x86 or x86-64) and avx2
    Sign-extend 16-bit integers to 32-bit integers.
_mm256_cvtepi16_epi64⚠(x86 or x86-64) and avx2
    Sign-extend 16-bit integers to 64-bit integers.
_mm256_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm256_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm256_cvtepi32_epi64⚠(x86 or x86-64) and avx2
    Sign-extend 32-bit integers to 64-bit integers.
_mm256_cvtepi32_pd⚠(x86 or x86-64) and avx
    Converts packed 32-bit integers in a to packed double-precision (64-bit) floating-point elements.
_mm256_cvtepi32_ps⚠(x86 or x86-64) and avx
    Converts packed 32-bit integers in a to packed single-precision (32-bit) floating-point elements.
_mm256_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm256_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm256_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst.
_mm256_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm256_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtepu8_epi16⚠(x86 or x86-64) and avx2
    Zero-extend unsigned 8-bit integers in a to 16-bit integers.
_mm256_cvtepu8_epi32⚠(x86 or x86-64) and avx2
    Zero-extend the lower eight unsigned 8-bit integers in a to 32-bit integers. The upper eight elements of a are unused.
_mm256_cvtepu8_epi64⚠(x86 or x86-64) and avx2
    Zero-extend the lower four unsigned 8-bit integers in a to 64-bit integers. The upper twelve elements of a are unused.
_mm256_cvtepu16_epi32⚠(x86 or x86-64) and avx2
    Zeroes extend packed unsigned 16-bit integers in a to packed 32-bit integers, and stores the results in dst.
_mm256_cvtepu16_epi64⚠(x86 or x86-64) and avx2
    Zero-extend the lower four unsigned 16-bit integers in a to 64-bit integers. The upper four elements of a are unused.
_mm256_cvtepu32_epi64⚠(x86 or x86-64) and avx2
    Zero-extend unsigned 32-bit integers in a to 64-bit integers.
_mm256_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm256_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm256_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two 256-bit vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in a 256-bit wide vector. Intel’s documentation
_mm256_cvtneebf16_ps⚠(x86 or x86-64) and avxneconvert
    Convert packed BF16 (16-bit) floating-point even-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtneobf16_ps⚠(x86 or x86-64) and avxneconvert
    Convert packed BF16 (16-bit) floating-point odd-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtneps_avx_pbh⚠(x86 or x86-64) and avxneconvert
    Convert packed single precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst.
_mm256_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst. Intel’s documentation
_mm256_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtpd_epi32⚠(x86 or x86-64) and avx
    Converts packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers.
_mm256_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm256_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm256_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm256_cvtpd_ps⚠(x86 or x86-64) and avx
    Converts packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements.
_mm256_cvtph_ps⚠(x86 or x86-64) and f16c
    Converts the 8 x 16-bit half-precision float values in the 128-bit vector a into 8 x 32-bit float values stored in a 256-bit wide vector.
_mm256_cvtps_epi32⚠(x86 or x86-64) and avx
    Converts packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers.
_mm256_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm256_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm256_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm256_cvtps_pd⚠(x86 or x86-64) and avx
    Converts packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements.
_mm256_cvtps_ph⚠(x86 or x86-64) and f16c
    Converts the 8 x 32-bit float values in the 256-bit vector a into 8 x 16-bit half-precision float values stored in a 128-bit wide vector.
_mm256_cvtsd_f64⚠(x86 or x86-64) and avx
    Returns the first element of the input vector of [4 x double].
_mm256_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst.
_mm256_cvtsi256_si32⚠(x86 or x86-64) and avx
    Returns the first element of the input vector of [8 x i32].
_mm256_cvtss_f32⚠(x86 or x86-64) and avx
    Returns the first element of the input vector of [8 x float].
_mm256_cvttpd_epi32⚠(x86 or x86-64) and avx
    Converts packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation.
_mm256_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm256_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm256_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm256_cvttps_epi32⚠(x86 or x86-64) and avx
    Converts packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation.
_mm256_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm256_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm256_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm256_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm256_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm256_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm256_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm256_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm256_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst.
_mm256_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst. Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm256_div_pd⚠(x86 or x86-64) and avx
    Computes the division of each of the 4 packed 64-bit floating-point elements in a by the corresponding packed elements in b.
_mm256_div_ps⚠(x86 or x86-64) and avx
    Computes the division of each of the 8 packed 32-bit floating-point elements in a by the corresponding packed elements in b.
_mm256_dp_ps⚠(x86 or x86-64) and avx
    Conditionally multiplies the packed single-precision (32-bit) floating-point elements in a and b using the high 4 bits in imm8, sum the four products, and conditionally return the sum using the low 4 bits of imm8.
_mm256_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst. Intel’s documentation
_mm256_dpbssd_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpbssds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_dpbsud_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpbsuds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_dpbusd_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpbusds_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm256_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm256_dpbuud_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpbuuds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_dpwssd_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpwssds_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm256_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm256_dpwsud_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpwsuds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_dpwusd_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding signed 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpwusds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding signed 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_dpwuud_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm256_dpwuuds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm256_extract_epi8⚠(x86 or x86-64) and avx2
    Extracts an 8-bit integer from a, selected with INDEX. Returns a 32-bit integer containing the zero-extended integer data.
_mm256_extract_epi16⚠(x86 or x86-64) and avx2
    Extracts a 16-bit integer from a, selected with INDEX. Returns a 32-bit integer containing the zero-extended integer data.
_mm256_extract_epi32⚠(x86 or x86-64) and avx
    Extracts a 32-bit integer from a, selected with INDEX.
_mm256_extract_epi64⚠avx
    Extracts a 64-bit integer from a, selected with INDEX.
_mm256_extractf32x4_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the result in dst.
_mm256_extractf64x2_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst.
_mm256_extractf128_pd⚠(x86 or x86-64) and avx
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with imm8.
_mm256_extractf128_ps⚠(x86 or x86-64) and avx
    Extracts 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8.
_mm256_extractf128_si256⚠(x86 or x86-64) and avx
    Extracts 128 bits (composed of integer data) from a, selected with imm8.
_mm256_extracti32x4_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM1, and store the result in dst.
_mm256_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst.
_mm256_extracti128_si256⚠(x86 or x86-64) and avx2
    Extracts 128 bits (of integer data) from a selected with IMM1.
_mm256_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm256_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm256_floor_pd⚠(x86 or x86-64) and avx
    Rounds packed double-precision (64-bit) floating point elements in a toward negative infinity.
_mm256_floor_ps⚠(x86 or x86-64) and avx
    Rounds packed single-precision (32-bit) floating point elements in a toward negative infinity.
_mm256_fmadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to packed elements in c.
_mm256_fmadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to packed elements in c.
_mm256_fmaddsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and alternatively add and subtract packed elements in c to/from the intermediate result.
_mm256_fmaddsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and alternatively add and subtract packed elements in c to/from the intermediate result.
_mm256_fmsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result.
_mm256_fmsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result.
_mm256_fmsubadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and alternatively subtract and add packed elements in c from/to the intermediate result.
_mm256_fmsubadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and alternatively subtract and add packed elements in c from/to the intermediate result.
_mm256_fnmadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to packed elements in c.
_mm256_fnmadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to packed elements in c.
_mm256_fnmsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result.
_mm256_fnmsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result.
_mm256_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm256_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm256_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign. The mantissa is normalized to the interval specified by interv, which can take the following values: _MM_MANT_NORM_1_2 // interval [1, 2) _MM_MANT_NORM_p5_2 // interval [0.5, 2) _MM_MANT_NORM_p5_1 // interval [0.5, 1) _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5) The sign is determined by sc which can take the following values: _MM_MANT_SIGN_src // sign = sign(src) _MM_MANT_SIGN_zero // sign = 0 _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm256_hadd_epi16⚠(x86 or x86-64) and avx2
    Horizontally adds adjacent pairs of 16-bit integers in a and b.
_mm256_hadd_epi32⚠(x86 or x86-64) and avx2
    Horizontally adds adjacent pairs of 32-bit integers in a and b.
_mm256_hadd_pd⚠(x86 or x86-64) and avx
    Horizontal addition of adjacent pairs in the two packed vectors of 4 64-bit floating points a and b. In the result, sums of elements from a are returned in even locations, while sums of elements from b are returned in odd locations.
_mm256_hadd_ps⚠(x86 or x86-64) and avx
    Horizontal addition of adjacent pairs in the two packed vectors of 8 32-bit floating points a and b. In the result, sums of elements from a are returned in locations of indices 0, 1, 4, 5; while sums of elements from b are locations 2, 3, 6, 7.
_mm256_hadds_epi16⚠(x86 or x86-64) and avx2
    Horizontally adds adjacent pairs of 16-bit integers in a and b using saturation.
_mm256_hsub_epi16⚠(x86 or x86-64) and avx2
    Horizontally subtract adjacent pairs of 16-bit integers in a and b.
_mm256_hsub_epi32⚠(x86 or x86-64) and avx2
    Horizontally subtract adjacent pairs of 32-bit integers in a and b.
_mm256_hsub_pd⚠(x86 or x86-64) and avx
    Horizontal subtraction of adjacent pairs in the two packed vectors of 4 64-bit floating points a and b. In the result, sums of elements from a are returned in even locations, while sums of elements from b are returned in odd locations.
_mm256_hsub_ps⚠(x86 or x86-64) and avx
    Horizontal subtraction of adjacent pairs in the two packed vectors of 8 32-bit floating points a and b. In the result, sums of elements from a are returned in locations of indices 0, 1, 4, 5; while sums of elements from b are locations 2, 3, 6, 7.
_mm256_hsubs_epi16⚠(x86 or x86-64) and avx2
    Horizontally subtract adjacent pairs of 16-bit integers in a and b using saturation.
_mm256_i32gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i32gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i32gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i32gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i32scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 8 32-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm256_i32scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Scatter 64-bit integers from a into memory using 32-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm256_i32scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm256_i32scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 8 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm256_i64gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i64gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i64gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i64gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm256_i64scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 32-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm256_i64scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 64-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm256_i64scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm256_i64scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm256_insert_epi8⚠(x86 or x86-64) and avx
    Copies a to result, and inserts the 8-bit integer i into result at the location specified by index.
_mm256_insert_epi16⚠(x86 or x86-64) and avx
    Copies a to result, and inserts the 16-bit integer i into result at the location specified by index.
_mm256_insert_epi32⚠(x86 or x86-64) and avx
    Copies a to result, and inserts the 32-bit integer i into result at the location specified by index.
_mm256_insert_epi64⚠avx
    Copies a to result, and insert the 64-bit integer i into result at the location specified by index.
_mm256_insertf32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to dst, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into dst at the location specified by imm8.
_mm256_insertf64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to dst, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into dst at the location specified by IMM8.
_mm256_insertf128_pd⚠(x86 or x86-64) and avx
    Copies a to result, then inserts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into result at the location specified by imm8.
_mm256_insertf128_ps⚠(x86 or x86-64) and avx
    Copies a to result, then inserts 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into result at the location specified by imm8.
_mm256_insertf128_si256⚠(x86 or x86-64) and avx
    Copies a to result, then inserts 128 bits from b into result at the location specified by imm8.
_mm256_inserti32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to dst, then insert 128 bits (composed of 4 packed 32-bit integers) from b into dst at the location specified by imm8.
_mm256_inserti64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to dst, then insert 128 bits (composed of 2 packed 64-bit integers) from b into dst at the location specified by IMM8.
_mm256_inserti128_si256⚠(x86 or x86-64) and avx2
    Copies a to dst, then insert 128 bits (of integer data) from b at the location specified by IMM1.
_mm256_lddqu_si256⚠(x86 or x86-64) and avx
    Loads 256-bits of integer data from unaligned memory into result. This intrinsic may perform better than _mm256_loadu_si256 when the data crosses a cache line boundary.
_mm256_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load 256-bits (composed of 8 packed 32-bit integers) from memory into dst. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load 256-bits (composed of 4 packed 64-bit integers) from memory into dst. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_load_pd⚠(x86 or x86-64) and avx
    Loads 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_load_ps⚠(x86 or x86-64) and avx
    Loads 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_load_si256⚠(x86 or x86-64) and avx
    Loads 256-bits of integer data from memory into result. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_loadu2_m128⚠(x86 or x86-64) and avx
    Loads two 128-bit values (composed of 4 packed single-precision (32-bit) floating-point elements) from memory, and combine them into a 256-bit value. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_loadu2_m128d⚠(x86 or x86-64) and avx
    Loads two 128-bit values (composed of 2 packed double-precision (64-bit) floating-point elements) from memory, and combine them into a 256-bit value. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_loadu2_m128i⚠(x86 or x86-64) and avx
    Loads two 128-bit values (composed of integer data) from memory, and combine them into a 256-bit value. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load 256-bits (composed of 32 packed 8-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load 256-bits (composed of 16 packed 16-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load 256-bits (composed of 8 packed 32-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load 256-bits (composed of 4 packed 64-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_pd⚠(x86 or x86-64) and avx
    Loads 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from memory into result. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_ps⚠(x86 or x86-64) and avx
    Loads 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from memory into result. mem_addr does not need to be aligned on any particular boundary.
_mm256_loadu_si256⚠(x86 or x86-64) and avx
    Loads 256-bits of integer data from memory into result. mem_addr does not need to be aligned on any particular boundary.
_mm256_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst.
_mm256_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst.
_mm256_madd52hi_avx_epu64⚠(x86 or x86-64) and avxifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm256_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm256_madd52lo_avx_epu64⚠(x86 or x86-64) and avxifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm256_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm256_madd_epi16⚠(x86 or x86-64) and avx2
    Multiplies packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers.
_mm256_maddubs_epi16⚠(x86 or x86-64) and avx2
    Vertically multiplies each unsigned 8-bit integer from a with the corresponding signed 8-bit integer from b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers
_mm256_mask2_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask2_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm256_mask2_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm256_mask2_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm256_mask2_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set)
_mm256_mask2_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm256_mask3_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm256_mask_abs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_abs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_abs_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 32-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_add_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_adds_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_adds_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_adds_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_adds_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_alignr_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 32 bytes (8 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 32 bytes (4 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_and_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Performs element-by-element bitwise AND between packed 32-bit integer elements of a and b, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_and_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_and_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_and_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_andnot_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_andnot_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_andnot_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_andnot_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_avg_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_avg_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg,avx512vl
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm256_mask_blend_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Blend packed 8-bit integers from a and b using control mask k, and store the results in dst.
_mm256_mask_blend_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Blend packed 16-bit integers from a and b using control mask k, and store the results in dst.
_mm256_mask_blend_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed 32-bit integers from a and b using control mask k, and store the results in dst.
_mm256_mask_blend_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed 64-bit integers from a and b using control mask k, and store the results in dst.
_mm256_mask_blend_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed double-precision (64-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm256_mask_blend_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed single-precision (32-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm256_mask_broadcast_f32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_broadcast_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcast_f64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_broadcast_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcast_i64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_broadcastb_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 8-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcastd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 32-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcastq_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 64-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcastsd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low double-precision (64-bit) floating-point element from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcastss_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_broadcastw_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_pd_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmp_ps_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmple_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_compress_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compress_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compress_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compress_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compress_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compress_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm256_mask_compressstoreu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_compressstoreu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_compressstoreu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_compressstoreu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_compressstoreu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_compressstoreu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm256_mask_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm256_mask_cvt_roundps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:
_mm256_mask_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 8 bytes of a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements and store the results in single vector dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm256_mask_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm256_mask_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtpd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_mask_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtsepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtsepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtsepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtsepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvttpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvttps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtusepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtusepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtusepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_cvtusepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 32-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm256_mask_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm256_mask_div_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_div_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm256_mask_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expand_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_expandloadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_extractf32x4_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_extractf64x2_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_extracti32x4_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM1, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm256_mask_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm256_mask_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm256_mask_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm256_mask_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_mask_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_mask_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_mask_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_mask_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_mask_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_mask_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm256_mask_i32gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i32gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i32gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i32gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i32scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 8 32-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i32scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 64-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i32scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i32scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 8 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i64gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i64gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i64gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i64gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm256_mask_i64scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 32-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i64scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 64-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i64scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_i64scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm256_mask_insertf32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_insertf64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_inserti32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 4 packed 32-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_inserti64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 2 packed 64-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_load_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_load_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 8-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 16-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_loadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_loadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm256_mask_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm256_mask_madd_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_maddubs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_max_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_min_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 8-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 16-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 32-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 64-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed double-precision (64-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mov_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed single-precision (32-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_movedup_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_movehdup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_moveldup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mul_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mul_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mul_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mul_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mulhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mulhi_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mulhrs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mullo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mullo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_or_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_or_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_packs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_packs_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_packus_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_packus_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permute_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permute_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutevar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutevar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_permutex_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutex_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_permutexvar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm256_mask_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm256_mask_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm256_mask_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm256_mask_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_mask_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_mask_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_mask_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_mask_reduce_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm256_mask_reduce_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm256_mask_reduce_and_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise AND using mask k. Returns the bitwise AND of all active elements in a.
_mm256_mask_reduce_and_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise AND using mask k. Returns the bitwise AND of all active elements in a.
_mm256_mask_reduce_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm256_mask_reduce_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm256_mask_reduce_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm256_mask_reduce_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm256_mask_reduce_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm256_mask_reduce_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm256_mask_reduce_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm256_mask_reduce_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm256_mask_reduce_mul_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm256_mask_reduce_mul_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm256_mask_reduce_or_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm256_mask_reduce_or_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm256_mask_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm256_mask_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm256_mask_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_mask_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_mask_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_mask_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_mask_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_set1_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 8-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_set1_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 16-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_set1_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 32-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_set1_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 64-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using writemask k (elements are copied from src“ when the corresponding mask bit is not set).
_mm256_mask_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm256_mask_shuffle_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 8-bit integers in a within 128-bit lanes using the control in the corresponding 8-bit element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_f64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_i64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shuffle_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shufflehi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_shufflelo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sll_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sll_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sll_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_slli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_slli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_slli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sllv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sllv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sqrt_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sqrt_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sra_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sra_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srai_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srai_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srav_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srl_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srl_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srl_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srlv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_srlv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_store_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 32-bit integers from a into memory using writemask k. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_store_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 64-bit integers from a into memory using writemask k. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_store_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_store_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_mask_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Store packed 8-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_storeu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Store packed 16-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 32-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_storeu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 64-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_storeu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_storeu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm256_mask_sub_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_subs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_subs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_subs_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_subs_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 32-bit granularity (32-bit elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 64-bit granularity (64-bit elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_test_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm256_mask_test_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm256_mask_test_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm256_mask_test_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm256_mask_testn_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm256_mask_testn_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm256_mask_testn_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm256_mask_testn_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm256_mask_unpackhi_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpackhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpackhi_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpackhi_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpackhi_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpackhi_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_unpacklo_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_xor_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_mask_xor_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm256_maskload_epi32⚠(x86 or x86-64) and avx2
    Loads packed 32-bit integers from memory pointed by mem_addr using mask (elements are zeroed out when the highest bit is not set in the corresponding element).
_mm256_maskload_epi64⚠(x86 or x86-64) and avx2
    Loads packed 64-bit integers from memory pointed by mem_addr using mask (elements are zeroed out when the highest bit is not set in the corresponding element).
_mm256_maskload_pd⚠(x86 or x86-64) and avx
    Loads packed double-precision (64-bit) floating-point elements from memory into result using mask (elements are zeroed out when the high bit of the corresponding element is not set).
_mm256_maskload_ps⚠(x86 or x86-64) and avx
    Loads packed single-precision (32-bit) floating-point elements from memory into result using mask (elements are zeroed out when the high bit of the corresponding element is not set).
_mm256_maskstore_epi32⚠(x86 or x86-64) and avx2
    Stores packed 32-bit integers from a into memory pointed by mem_addr using mask (elements are not stored when the highest bit is not set in the corresponding element).
_mm256_maskstore_epi64⚠(x86 or x86-64) and avx2
    Stores packed 64-bit integers from a into memory pointed by mem_addr using mask (elements are not stored when the highest bit is not set in the corresponding element).
_mm256_maskstore_pd⚠(x86 or x86-64) and avx
    Stores packed double-precision (64-bit) floating-point elements from a into memory using mask.
_mm256_maskstore_ps⚠(x86 or x86-64) and avx
    Stores packed single-precision (32-bit) floating-point elements from a into memory using mask.
_mm256_maskz_abs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_abs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_abs_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 32-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_add_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_adds_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_adds_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_adds_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_adds_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_alignr_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 32 bytes (8 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 64-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 32 bytes (4 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_and_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_and_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_and_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_and_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_andnot_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_andnot_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_andnot_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_andnot_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_avg_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_avg_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcast_f32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_broadcast_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcast_f64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_broadcast_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the 4 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcast_i64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_broadcastb_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 8-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcastd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 32-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcastq_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 64-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcastsd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low double-precision (64-bit) floating-point element from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcastss_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_broadcastw_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_compress_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_compress_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_compress_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_compress_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_compress_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_compress_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm256_maskz_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm256_maskz_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm256_maskz_cvt_roundps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_maskz_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 8 bytes of a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in single vector dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm256_maskz_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm256_maskz_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtpd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_maskz_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm256_maskz_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvttps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm256_maskz_div_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_div_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm256_maskz_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expand_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_expandloadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_extractf32x4_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_extractf64x2_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_extracti32x4_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM1, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm256_maskz_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm256_maskz_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_maskz_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_maskz_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_maskz_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm256_maskz_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_maskz_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm256_maskz_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm256_maskz_insertf32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_insertf64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_inserti32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 4 packed 32-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_inserti64x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Copy a to tmp, then insert 128 bits (composed of 2 packed 64-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_maskz_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_maskz_load_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_maskz_load_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_maskz_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 8-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 16-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_loadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_loadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm256_maskz_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_madd_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_maddubs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_max_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_min_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 8-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 16-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 32-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 64-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed double-precision (64-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mov_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed single-precision (32-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_movedup_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_movehdup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_moveldup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mul_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mul_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mul_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mul_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mulhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mulhi_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mulhrs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mullo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mullo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_or_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_or_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_packs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_packs_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_packus_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_packus_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permute_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permute_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutevar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutevar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutex_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_permutexvar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm256_maskz_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm256_maskz_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm256_maskz_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm256_maskz_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_maskz_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_maskz_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_maskz_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_maskz_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm256_maskz_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm256_maskz_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_maskz_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_maskz_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_maskz_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm256_maskz_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_set1_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 8-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_set1_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_set1_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 32-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_set1_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 64-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle packed 8-bit integers in a according to shuffle control mask in the corresponding 8-bit element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_f64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_i64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shuffle_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shufflehi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_shufflelo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_maskz_sll_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sll_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sll_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_slli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_slli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_slli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sllv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sllv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sqrt_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sqrt_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sra_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sra_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srai_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srai_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srav_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srl_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srl_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srl_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srlv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_srlv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_subs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_subs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_subs_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_subs_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 32-bit granularity (32-bit elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 64-bit granularity (64-bit elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpackhi_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_unpacklo_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_xor_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_maskz_xor_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm256_max_epi8⚠(x86 or x86-64) and avx2
    Compares packed 8-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epi16⚠(x86 or x86-64) and avx2
    Compares packed 16-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epi32⚠(x86 or x86-64) and avx2
    Compares packed 32-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst.
_mm256_max_epu8⚠(x86 or x86-64) and avx2
    Compares packed unsigned 8-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epu16⚠(x86 or x86-64) and avx2
    Compares packed unsigned 16-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epu32⚠(x86 or x86-64) and avx2
    Compares packed unsigned 32-bit integers in a and b, and returns the packed maximum values.
_mm256_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst.
_mm256_max_pd⚠(x86 or x86-64) and avx
    Compares packed double-precision (64-bit) floating-point elements in a and b, and returns packed maximum values
_mm256_max_ps⚠(x86 or x86-64) and avx
    Compares packed single-precision (32-bit) floating-point elements in a and b, and returns packed maximum values
_mm256_min_epi8⚠(x86 or x86-64) and avx2
    Compares packed 8-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epi16⚠(x86 or x86-64) and avx2
    Compares packed 16-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epi32⚠(x86 or x86-64) and avx2
    Compares packed 32-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst.
_mm256_min_epu8⚠(x86 or x86-64) and avx2
    Compares packed unsigned 8-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epu16⚠(x86 or x86-64) and avx2
    Compares packed unsigned 16-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epu32⚠(x86 or x86-64) and avx2
    Compares packed unsigned 32-bit integers in a and b, and returns the packed minimum values.
_mm256_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst.
_mm256_min_pd⚠(x86 or x86-64) and avx
    Compares packed double-precision (64-bit) floating-point elements in a and b, and returns packed minimum values
_mm256_min_ps⚠(x86 or x86-64) and avx
    Compares packed single-precision (32-bit) floating-point elements in a and b, and returns packed minimum values
_mm256_mmask_i32gather_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 8 32-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i32gather_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 64-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i32gather_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i32gather_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 8 single-precision (32-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i64gather_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 32-bit integer elements from memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i64gather_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 64-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i64gather_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mmask_i64gather_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 single-precision (32-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_movedup_pd⚠(x86 or x86-64) and avx
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and returns the results.
_mm256_movehdup_ps⚠(x86 or x86-64) and avx
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and returns the results.
_mm256_moveldup_ps⚠(x86 or x86-64) and avx
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and returns the results.
_mm256_movemask_epi8⚠(x86 or x86-64) and avx2
    Creates mask from the most significant bit of each 8-bit element in a, return the result.
_mm256_movemask_pd⚠(x86 or x86-64) and avx
    Sets each bit of the returned mask based on the most significant bit of the corresponding packed double-precision (64-bit) floating-point element in a.
_mm256_movemask_ps⚠(x86 or x86-64) and avx
    Sets each bit of the returned mask based on the most significant bit of the corresponding packed single-precision (32-bit) floating-point element in a.
_mm256_movepi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 8-bit integer in a.
_mm256_movepi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 16-bit integer in a.
_mm256_movepi32_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 32-bit integer in a.
_mm256_movepi64_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 64-bit integer in a.
_mm256_movm_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each packed 8-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm256_movm_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each packed 16-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm256_movm_epi32⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each packed 32-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm256_movm_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each packed 64-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm256_mpsadbw_epu8⚠(x86 or x86-64) and avx2
    Computes the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and stores the 16-bit results in dst. Eight SADs are performed for each 128-bit lane using one quadruplet from b and eight quadruplets from a. One quadruplet is selected from b starting at on the offset specified in imm8. Eight quadruplets are formed from sequential 8-bit integers selected from a starting at the offset specified in imm8.
_mm256_mul_epi32⚠(x86 or x86-64) and avx2
    Multiplies the low 32-bit integers from each packed 64-bit element in a and b
_mm256_mul_epu32⚠(x86 or x86-64) and avx2
    Multiplies the low unsigned 32-bit integers from each packed 64-bit element in a and b
_mm256_mul_pd⚠(x86 or x86-64) and avx
    Multiplies packed double-precision (64-bit) floating-point elements in a and b.
_mm256_mul_ps⚠(x86 or x86-64) and avx
    Multiplies packed single-precision (32-bit) floating-point elements in a and b.
_mm256_mulhi_epi16⚠(x86 or x86-64) and avx2
    Multiplies the packed 16-bit integers in a and b, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.
_mm256_mulhi_epu16⚠(x86 or x86-64) and avx2
    Multiplies the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers and returning the high 16 bits of the intermediate integers.
_mm256_mulhrs_epi16⚠(x86 or x86-64) and avx2
    Multiplies packed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and return bits [16:1].
_mm256_mullo_epi16⚠(x86 or x86-64) and avx2
    Multiplies the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and returns the low 16 bits of the intermediate integers
_mm256_mullo_epi32⚠(x86 or x86-64) and avx2
    Multiplies the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and returns the low 32 bits of the intermediate integers
_mm256_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst.
_mm256_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst.
_mm256_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst.
_mm256_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the resut in dst.
_mm256_or_pd⚠(x86 or x86-64) and avx
    Computes the bitwise OR packed double-precision (64-bit) floating-point elements in a and b.
_mm256_or_ps⚠(x86 or x86-64) and avx
    Computes the bitwise OR packed single-precision (32-bit) floating-point elements in a and b.
_mm256_or_si256⚠(x86 or x86-64) and avx2
    Computes the bitwise OR of 256 bits (representing integer data) in a and b
_mm256_packs_epi16⚠(x86 or x86-64) and avx2
    Converts packed 16-bit integers from a and b to packed 8-bit integers using signed saturation
_mm256_packs_epi32⚠(x86 or x86-64) and avx2
    Converts packed 32-bit integers from a and b to packed 16-bit integers using signed saturation
_mm256_packus_epi16⚠(x86 or x86-64) and avx2
    Converts packed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation
_mm256_packus_epi32⚠(x86 or x86-64) and avx2
    Converts packed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation
_mm256_permute2f128_pd⚠(x86 or x86-64) and avx
    Shuffles 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) selected by imm8 from a and b.
_mm256_permute2f128_ps⚠(x86 or x86-64) and avx
    Shuffles 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) selected by imm8 from a and b.
_mm256_permute2f128_si256⚠(x86 or x86-64) and avx
    Shuffles 128-bits (composed of integer data) selected by imm8 from a and b.
_mm256_permute2x128_si256⚠(x86 or x86-64) and avx2
    Shuffles 128-bits of integer data selected by imm8 from a and b.
_mm256_permute4x64_epi64⚠(x86 or x86-64) and avx2
    Permutes 64-bit integers from a using control mask imm8.
_mm256_permute4x64_pd⚠(x86 or x86-64) and avx2
    Shuffles 64-bit floating-point elements in a across lanes using the control in imm8.
_mm256_permute_pd⚠(x86 or x86-64) and avx
    Shuffles double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8.
_mm256_permute_ps⚠(x86 or x86-64) and avx
    Shuffles single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8.
_mm256_permutevar8x32_epi32⚠(x86 or x86-64) and avx2
    Permutes packed 32-bit integers from a according to the content of b.
_mm256_permutevar8x32_ps⚠(x86 or x86-64) and avx2
    Shuffles eight 32-bit floating-point elements in a across lanes using the corresponding 32-bit integer index in idx.
_mm256_permutevar_pd⚠(x86 or x86-64) and avx
    Shuffles double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in b.
_mm256_permutevar_ps⚠(x86 or x86-64) and avx
    Shuffles single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b.
_mm256_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutex_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst.
_mm256_permutex_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst.
_mm256_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm256_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm256_permutexvar_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm256_permutexvar_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm256_permutexvar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst.
_mm256_permutexvar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx.
_mm256_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm256_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm256_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm256_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm256_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm256_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm256_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm256_rcp_ps⚠(x86 or x86-64) and avx
    Computes the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and returns the results. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_reduce_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by addition. Returns the sum of all elements in a.
_mm256_reduce_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by addition. Returns the sum of all elements in a.
_mm256_reduce_and_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm256_reduce_and_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm256_reduce_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm256_reduce_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm256_reduce_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm256_reduce_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm256_reduce_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm256_reduce_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm256_reduce_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm256_reduce_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm256_reduce_mul_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by multiplication. Returns the product of all elements in a.
_mm256_reduce_mul_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by multiplication. Returns the product of all elements in a.
_mm256_reduce_or_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm256_reduce_or_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm256_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm256_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm256_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm256_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm256_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm256_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm256_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm256_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm256_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm256_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm256_round_pd⚠(x86 or x86-64) and avx
    Rounds packed double-precision (64-bit) floating point elements in a according to the flag ROUNDING. The value of ROUNDING may be as follows:
_mm256_round_ps⚠(x86 or x86-64) and avx
    Rounds packed single-precision (32-bit) floating point elements in a according to the flag ROUNDING. The value of ROUNDING may be as follows:
_mm256_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm256_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm256_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm256_rsqrt_ps⚠(x86 or x86-64) and avx
    Computes the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and returns the results. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_sad_epu8⚠(x86 or x86-64) and avx2
    Computes the absolute differences of packed unsigned 8-bit integers in a and b, then horizontally sum each consecutive 8 differences to produce four unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of the 64-bit return value
_mm256_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst.
_mm256_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst.
_mm256_set1_epi8⚠(x86 or x86-64) and avx
    Broadcasts 8-bit integer a to all elements of returned vector. This intrinsic may generate the vpbroadcastb.
_mm256_set1_epi16⚠(x86 or x86-64) and avx
    Broadcasts 16-bit integer a to all elements of returned vector. This intrinsic may generate the vpbroadcastw.
_mm256_set1_epi32⚠(x86 or x86-64) and avx
    Broadcasts 32-bit integer a to all elements of returned vector. This intrinsic may generate the vpbroadcastd.
_mm256_set1_epi64x⚠(x86 or x86-64) and avx
    Broadcasts 64-bit integer a to all elements of returned vector. This intrinsic may generate the vpbroadcastq.
_mm256_set1_pd⚠(x86 or x86-64) and avx
    Broadcasts double-precision (64-bit) floating-point value a to all elements of returned vector.
_mm256_set1_ps⚠(x86 or x86-64) and avx
    Broadcasts single-precision (32-bit) floating-point value a to all elements of returned vector.
_mm256_set_epi8⚠(x86 or x86-64) and avx
    Sets packed 8-bit integers in returned vector with the supplied values.
_mm256_set_epi16⚠(x86 or x86-64) and avx
    Sets packed 16-bit integers in returned vector with the supplied values.
_mm256_set_epi32⚠(x86 or x86-64) and avx
    Sets packed 32-bit integers in returned vector with the supplied values.
_mm256_set_epi64x⚠(x86 or x86-64) and avx
    Sets packed 64-bit integers in returned vector with the supplied values.
_mm256_set_m128⚠(x86 or x86-64) and avx
    Sets packed __m256 returned vector with the supplied values.
_mm256_set_m128d⚠(x86 or x86-64) and avx
    Sets packed __m256d returned vector with the supplied values.
_mm256_set_m128i⚠(x86 or x86-64) and avx
    Sets packed __m256i returned vector with the supplied values.
_mm256_set_pd⚠(x86 or x86-64) and avx
    Sets packed double-precision (64-bit) floating-point elements in returned vector with the supplied values.
_mm256_set_ps⚠(x86 or x86-64) and avx
    Sets packed single-precision (32-bit) floating-point elements in returned vector with the supplied values.
_mm256_setr_epi8⚠(x86 or x86-64) and avx
    Sets packed 8-bit integers in returned vector with the supplied values in reverse order.
_mm256_setr_epi16⚠(x86 or x86-64) and avx
    Sets packed 16-bit integers in returned vector with the supplied values in reverse order.
_mm256_setr_epi32⚠(x86 or x86-64) and avx
    Sets packed 32-bit integers in returned vector with the supplied values in reverse order.
_mm256_setr_epi64x⚠(x86 or x86-64) and avx
    Sets packed 64-bit integers in returned vector with the supplied values in reverse order.
_mm256_setr_m128⚠(x86 or x86-64) and avx
    Sets packed __m256 returned vector with the supplied values.
_mm256_setr_m128d⚠(x86 or x86-64) and avx
    Sets packed __m256d returned vector with the supplied values.
_mm256_setr_m128i⚠(x86 or x86-64) and avx
    Sets packed __m256i returned vector with the supplied values.
_mm256_setr_pd⚠(x86 or x86-64) and avx
    Sets packed double-precision (64-bit) floating-point elements in returned vector with the supplied values in reverse order.
_mm256_setr_ps⚠(x86 or x86-64) and avx
    Sets packed single-precision (32-bit) floating-point elements in returned vector with the supplied values in reverse order.
_mm256_setzero_pd⚠(x86 or x86-64) and avx
    Returns vector of type __m256d with all elements set to zero.
_mm256_setzero_ps⚠(x86 or x86-64) and avx
    Returns vector of type __m256 with all elements set to zero.
_mm256_setzero_si256⚠(x86 or x86-64) and avx
    Returns vector of type __m256i with all elements set to zero.
_mm256_sha512msg1_epi64⚠(x86 or x86-64) and sha512,avx
    This intrinsic is one of the two SHA512 message scheduling instructions. The intrinsic performs an intermediate calculation for the next four SHA512 message qwords. The calculated results are stored in dst.
_mm256_sha512msg2_epi64⚠(x86 or x86-64) and sha512,avx
    This intrinsic is one of the two SHA512 message scheduling instructions. The intrinsic performs the final calculation for the next four SHA512 message qwords. The calculated results are stored in dst.
_mm256_sha512rnds2_epi64⚠(x86 or x86-64) and sha512,avx
    This intrinsic performs two rounds of SHA512 operation using initial SHA512 state (C,D,G,H) from a, an initial SHA512 state (A,B,E,F) from b, and a pre-computed sum of the next two round message qwords and the corresponding round constants from c (only the two lower qwords of the third operand). The updated SHA512 state (A,B,E,F) is written to dst, and dst can be used as the updated state (C,D,G,H) in later rounds.
_mm256_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst).
_mm256_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst.
_mm256_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst).
_mm256_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst.
_mm256_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst.
_mm256_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst.
_mm256_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst.
_mm256_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst.
_mm256_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst.
_mm256_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst.
_mm256_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst.
_mm256_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst.
_mm256_shuffle_epi8⚠(x86 or x86-64) and avx2
    Shuffles bytes from a according to the content of b.
_mm256_shuffle_epi32⚠(x86 or x86-64) and avx2
    Shuffles 32-bit integers in 128-bit lanes of a using the control in imm8.
_mm256_shuffle_f32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst.
_mm256_shuffle_f64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst.
_mm256_shuffle_i32x4⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst.
_mm256_shuffle_i64x2⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst.
_mm256_shuffle_pd⚠(x86 or x86-64) and avx
    Shuffles double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8.
_mm256_shuffle_ps⚠(x86 or x86-64) and avx
    Shuffles single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8.
_mm256_shufflehi_epi16⚠(x86 or x86-64) and avx2
    Shuffles 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. The low 64 bits of 128-bit lanes of a are copied to the output.
_mm256_shufflelo_epi16⚠(x86 or x86-64) and avx2
    Shuffles 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. The high 64 bits of 128-bit lanes of a are copied to the output.
_mm256_sign_epi8⚠(x86 or x86-64) and avx2
    Negates packed 8-bit integers in a when the corresponding signed 8-bit integer in b is negative, and returns the results. Results are zeroed out when the corresponding element in b is zero.
_mm256_sign_epi16⚠(x86 or x86-64) and avx2
    Negates packed 16-bit integers in a when the corresponding signed 16-bit integer in b is negative, and returns the results. Results are zeroed out when the corresponding element in b is zero.
_mm256_sign_epi32⚠(x86 or x86-64) and avx2
    Negates packed 32-bit integers in a when the corresponding signed 32-bit integer in b is negative, and returns the results. Results are zeroed out when the corresponding element in b is zero.
_mm256_sll_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a left by count while shifting in zeros, and returns the result
_mm256_sll_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a left by count while shifting in zeros, and returns the result
_mm256_sll_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a left by count while shifting in zeros, and returns the result
_mm256_slli_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a left by IMM8 while shifting in zeros, return the results;
_mm256_slli_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a left by IMM8 while shifting in zeros, return the results;
_mm256_slli_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a left by IMM8 while shifting in zeros, return the results;
_mm256_slli_si256⚠(x86 or x86-64) and avx2
    Shifts 128-bit lanes in a left by imm8 bytes while shifting in zeros.
_mm256_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm256_sllv_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and returns the result.
_mm256_sllv_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and returns the result.
_mm256_sm4key4_epi32⚠(x86 or x86-64) and sm4,avx
    This intrinsic performs four rounds of SM4 key expansion. The intrinsic operates on independent 128-bit lanes. The calculated results are stored in dst.
_mm256_sm4rnds4_epi32⚠(x86 or x86-64) and sm4,avx
    This intrinsic performs four rounds of SM4 encryption. The intrinsic operates on independent 128-bit lanes. The calculated results are stored in dst.
_mm256_sqrt_pd⚠(x86 or x86-64) and avx
    Returns the square root of packed double-precision (64-bit) floating point elements in a.
_mm256_sqrt_ps⚠(x86 or x86-64) and avx
    Returns the square root of packed single-precision (32-bit) floating point elements in a.
_mm256_sra_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a right by count while shifting in sign bits.
_mm256_sra_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by count while shifting in sign bits.
_mm256_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst.
_mm256_srai_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a right by IMM8 while shifting in sign bits.
_mm256_srai_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by IMM8 while shifting in sign bits.
_mm256_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst.
_mm256_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm256_srav_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits.
_mm256_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm256_srl_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a right by count while shifting in zeros.
_mm256_srl_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by count while shifting in zeros.
_mm256_srl_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a right by count while shifting in zeros.
_mm256_srli_epi16⚠(x86 or x86-64) and avx2
    Shifts packed 16-bit integers in a right by IMM8 while shifting in zeros
_mm256_srli_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by IMM8 while shifting in zeros
_mm256_srli_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a right by IMM8 while shifting in zeros
_mm256_srli_si256⚠(x86 or x86-64) and avx2
    Shifts 128-bit lanes in a right by imm8 bytes while shifting in zeros.
_mm256_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm256_srlv_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros,
_mm256_srlv_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros,
_mm256_store_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store 256-bits (composed of 8 packed 32-bit integers) from a into memory. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_store_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store 256-bits (composed of 4 packed 64-bit integers) from a into memory. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_store_pd⚠(x86 or x86-64) and avx
    Stores 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_store_ps⚠(x86 or x86-64) and avx
    Stores 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from a into memory. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_store_si256⚠(x86 or x86-64) and avx
    Stores 256-bits of integer data from a into memory. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated.
_mm256_storeu2_m128⚠(x86 or x86-64) and avx
    Stores the high and low 128-bit halves (each composed of 4 packed single-precision (32-bit) floating-point elements) from a into memory two different 128-bit locations. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_storeu2_m128d⚠(x86 or x86-64) and avx
    Stores the high and low 128-bit halves (each composed of 2 packed double-precision (64-bit) floating-point elements) from a into memory two different 128-bit locations. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_storeu2_m128i⚠(x86 or x86-64) and avx
    Stores the high and low 128-bit halves (each composed of integer data) from a into memory two different 128-bit locations. hiaddr and loaddr do not need to be aligned on any particular boundary.
_mm256_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Store 256-bits (composed of 32 packed 8-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Store 256-bits (composed of 16 packed 16-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store 256-bits (composed of 8 packed 32-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store 256-bits (composed of 4 packed 64-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_pd⚠(x86 or x86-64) and avx
    Stores 256-bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_ps⚠(x86 or x86-64) and avx
    Stores 256-bits (composed of 8 packed single-precision (32-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_storeu_si256⚠(x86 or x86-64) and avx
    Stores 256-bits of integer data from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm256_stream_load_si256⚠(x86 or x86-64) and avx2
    Load 256-bits of integer data from memory into dst using a non-temporal memory hint. mem_addr must be aligned on a 32-byte boundary or a general-protection exception may be generated. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)
_mm256_stream_pd⚠(x86 or x86-64) and avx
    Moves double-precision values from a 256-bit vector of [4 x double] to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm256_stream_ps⚠(x86 or x86-64) and avx
    Moves single-precision floating point values from a 256-bit vector of [8 x float] to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm256_stream_si256⚠(x86 or x86-64) and avx
    Moves integer data from a 256-bit integer vector to a 32-byte aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)
_mm256_sub_epi8⚠(x86 or x86-64) and avx2
    Subtract packed 8-bit integers in b from packed 8-bit integers in a
_mm256_sub_epi16⚠(x86 or x86-64) and avx2
    Subtract packed 16-bit integers in b from packed 16-bit integers in a
_mm256_sub_epi32⚠(x86 or x86-64) and avx2
    Subtract packed 32-bit integers in b from packed 32-bit integers in a
_mm256_sub_epi64⚠(x86 or x86-64) and avx2
    Subtract packed 64-bit integers in b from packed 64-bit integers in a
_mm256_sub_pd⚠(x86 or x86-64) and avx
    Subtracts packed double-precision (64-bit) floating-point elements in b from packed elements in a.
_mm256_sub_ps⚠(x86 or x86-64) and avx
    Subtracts packed single-precision (32-bit) floating-point elements in b from packed elements in a.
_mm256_subs_epi8⚠(x86 or x86-64) and avx2
    Subtract packed 8-bit integers in b from packed 8-bit integers in a using saturation.
_mm256_subs_epi16⚠(x86 or x86-64) and avx2
    Subtract packed 16-bit integers in b from packed 16-bit integers in a using saturation.
_mm256_subs_epu8⚠(x86 or x86-64) and avx2
    Subtract packed unsigned 8-bit integers in b from packed 8-bit integers in a using saturation.
_mm256_subs_epu16⚠(x86 or x86-64) and avx2
    Subtract packed unsigned 16-bit integers in b from packed 16-bit integers in a using saturation.
_mm256_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm256_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm256_test_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm256_test_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm256_test_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm256_test_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm256_testc_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return the CF value.
_mm256_testc_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return the CF value.
_mm256_testc_si256⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing integer data) in a and b, and set ZF to 1 if the result is zero, otherwise set ZF to 0. Computes the bitwise NOT of a and then AND with b, and set CF to 1 if the result is zero, otherwise set CF to 0. Return the CF value.
_mm256_testn_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm256_testn_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm256_testn_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm256_testn_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm256_testnzc_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return 1 if both the ZF and CF values are zero, otherwise return 0.
_mm256_testnzc_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return 1 if both the ZF and CF values are zero, otherwise return 0.
_mm256_testnzc_si256⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing integer data) in a and b, and set ZF to 1 if the result is zero, otherwise set ZF to 0. Computes the bitwise NOT of a and then AND with b, and set CF to 1 if the result is zero, otherwise set CF to 0. Return 1 if both the ZF and CF values are zero, otherwise return 0.
_mm256_testz_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return the ZF value.
_mm256_testz_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 256-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return the ZF value.
_mm256_testz_si256⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 256 bits (representing integer data) in a and b, and set ZF to 1 if the result is zero, otherwise set ZF to 0. Computes the bitwise NOT of a and then AND with b, and set CF to 1 if the result is zero, otherwise set CF to 0. Return the ZF value.
_mm256_undefined_pd⚠(x86 or x86-64) and avx
    Returns vector of type __m256d with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm256_undefined_ps⚠(x86 or x86-64) and avx
    Returns vector of type __m256 with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm256_undefined_si256⚠(x86 or x86-64) and avx
    Returns vector of type __m256i with with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm256_unpackhi_epi8⚠(x86 or x86-64) and avx2
    Unpacks and interleave 8-bit integers from the high half of each 128-bit lane in a and b.
_mm256_unpackhi_epi16⚠(x86 or x86-64) and avx2
    Unpacks and interleave 16-bit integers from the high half of each 128-bit lane of a and b.
_mm256_unpackhi_epi32⚠(x86 or x86-64) and avx2
    Unpacks and interleave 32-bit integers from the high half of each 128-bit lane of a and b.
_mm256_unpackhi_epi64⚠(x86 or x86-64) and avx2
    Unpacks and interleave 64-bit integers from the high half of each 128-bit lane of a and b.
_mm256_unpackhi_pd⚠(x86 or x86-64) and avx
    Unpacks and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b.
_mm256_unpackhi_ps⚠(x86 or x86-64) and avx
    Unpacks and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b.
_mm256_unpacklo_epi8⚠(x86 or x86-64) and avx2
    Unpacks and interleave 8-bit integers from the low half of each 128-bit lane of a and b.
_mm256_unpacklo_epi16⚠(x86 or x86-64) and avx2
    Unpacks and interleave 16-bit integers from the low half of each 128-bit lane of a and b.
_mm256_unpacklo_epi32⚠(x86 or x86-64) and avx2
    Unpacks and interleave 32-bit integers from the low half of each 128-bit lane of a and b.
_mm256_unpacklo_epi64⚠(x86 or x86-64) and avx2
    Unpacks and interleave 64-bit integers from the low half of each 128-bit lane of a and b.
_mm256_unpacklo_pd⚠(x86 or x86-64) and avx
    Unpacks and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b.
_mm256_unpacklo_ps⚠(x86 or x86-64) and avx
    Unpacks and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b.
_mm256_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst.
_mm256_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst.
_mm256_xor_pd⚠(x86 or x86-64) and avx
    Computes the bitwise XOR of packed double-precision (64-bit) floating-point elements in a and b.
_mm256_xor_ps⚠(x86 or x86-64) and avx
    Computes the bitwise XOR of packed single-precision (32-bit) floating-point elements in a and b.
_mm256_xor_si256⚠(x86 or x86-64) and avx2
    Computes the bitwise XOR of 256 bits (representing integer data) in a and b
_mm256_zeroall⚠(x86 or x86-64) and avx
    Zeroes the contents of all XMM or YMM registers.
_mm256_zeroupper⚠(x86 or x86-64) and avx
    Zeroes the upper 128 bits of all YMM registers; the lower 128-bits of the registers are unmodified.
_mm256_zextpd128_pd256⚠(x86 or x86-64) and avx
    Constructs a 256-bit floating-point vector of [4 x double] from a 128-bit floating-point vector of [2 x double]. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.
_mm256_zextps128_ps256⚠(x86 or x86-64) and avx
    Constructs a 256-bit floating-point vector of [8 x float] from a 128-bit floating-point vector of [4 x float]. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.
_mm256_zextsi128_si256⚠(x86 or x86-64) and avx
    Constructs a 256-bit integer vector from a 128-bit integer vector. The lower 128 bits contain the value of the source vector. The upper 128 bits are set to zero.
_mm512_abs_epi8⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst.
_mm512_abs_epi16⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst.
_mm512_abs_epi32⚠(x86 or x86-64) and avx512f
    Computes the absolute values of packed 32-bit integers in a.
_mm512_abs_epi64⚠(x86 or x86-64) and avx512f
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst.
_mm512_abs_pd⚠(x86 or x86-64) and avx512f
    Finds the absolute value of each packed double-precision (64-bit) floating-point element in v2, storing the results in dst.
_mm512_abs_ps⚠(x86 or x86-64) and avx512f
    Finds the absolute value of each packed single-precision (32-bit) floating-point element in v2, storing the results in dst.
_mm512_add_epi8⚠(x86 or x86-64) and avx512bw
    Add packed 8-bit integers in a and b, and store the results in dst.
_mm512_add_epi16⚠(x86 or x86-64) and avx512bw
    Add packed 16-bit integers in a and b, and store the results in dst.
_mm512_add_epi32⚠(x86 or x86-64) and avx512f
    Add packed 32-bit integers in a and b, and store the results in dst.
_mm512_add_epi64⚠(x86 or x86-64) and avx512f
    Add packed 64-bit integers in a and b, and store the results in dst.
_mm512_add_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst.
_mm512_add_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst.
_mm512_add_round_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst.\
_mm512_add_round_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst.\
_mm512_adds_epi8⚠(x86 or x86-64) and avx512bw
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst.
_mm512_adds_epi16⚠(x86 or x86-64) and avx512bw
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst.
_mm512_adds_epu8⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst.
_mm512_adds_epu16⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst.
_mm512_aesdec_epi128⚠(x86 or x86-64) and vaes,avx512f
    Performs one round of an AES decryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm512_aesdeclast_epi128⚠(x86 or x86-64) and vaes,avx512f
    Performs the last round of an AES decryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm512_aesenc_epi128⚠(x86 or x86-64) and vaes,avx512f
    Performs one round of an AES encryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm512_aesenclast_epi128⚠(x86 or x86-64) and vaes,avx512f
    Performs the last round of an AES encryption flow on each 128-bit word (state) in a using the corresponding 128-bit word (key) in round_key.
_mm512_alignr_epi8⚠(x86 or x86-64) and avx512bw
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst. Unlike _mm_alignr_epi8, _mm256_alignr_epi8 functions, where the entire input vectors are concatenated to the temporary result, this concatenation happens in 4 steps, where each step builds 32-byte temporary result.
_mm512_alignr_epi32⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 64 bytes (16 elements) in dst.
_mm512_alignr_epi64⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 64 bytes (8 elements) in dst.
_mm512_and_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 32-bit integers in a and b, and store the results in dst.
_mm512_and_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of 512 bits (composed of packed 64-bit integers) in a and b, and store the results in dst.
_mm512_and_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst.
_mm512_and_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst.
_mm512_and_si512⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of 512 bits (representing integer data) in a and b, and store the result in dst.
_mm512_andnot_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst.
_mm512_andnot_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 512 bits (composed of packed 64-bit integers) in a and then AND with b, and store the results in dst.
_mm512_andnot_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst.
_mm512_andnot_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst.
_mm512_andnot_si512⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 512 bits (representing integer data) in a and then AND with b, and store the result in dst.
_mm512_avg_epu8⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 8-bit integers in a and b, and store the results in dst.
_mm512_avg_epu16⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 16-bit integers in a and b, and store the results in dst.
_mm512_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm512_broadcast_f32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst.
_mm512_broadcast_f32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst.
_mm512_broadcast_f32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed single-precision (32-bit) floating-point elements from a to all elements of dst.
_mm512_broadcast_f64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst.
_mm512_broadcast_f64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed double-precision (64-bit) floating-point elements from a to all elements of dst.
_mm512_broadcast_i32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst.
_mm512_broadcast_i32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 32-bit integers from a to all elements of dst.
_mm512_broadcast_i32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed 32-bit integers from a to all elements of dst.
_mm512_broadcast_i64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst.
_mm512_broadcast_i64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 64-bit integers from a to all elements of dst.
_mm512_broadcastb_epi8⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 8-bit integer from a to all elements of dst.
_mm512_broadcastd_epi32⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 32-bit integer from a to all elements of dst.
_mm512_broadcastmb_epi64⚠(x86 or x86-64) and avx512cd
    Broadcast the low 8-bits from input mask k to all 64-bit elements of dst.
_mm512_broadcastmw_epi32⚠(x86 or x86-64) and avx512cd
    Broadcast the low 16-bits from input mask k to all 32-bit elements of dst.
_mm512_broadcastq_epi64⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 64-bit integer from a to all elements of dst.
_mm512_broadcastsd_pd⚠(x86 or x86-64) and avx512f
    Broadcast the low double-precision (64-bit) floating-point element from a to all elements of dst.
_mm512_broadcastss_ps⚠(x86 or x86-64) and avx512f
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst.
_mm512_broadcastw_epi16⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 16-bit integer from a to all elements of dst.
_mm512_bslli_epi128⚠(x86 or x86-64) and avx512bw
    Shift 128-bit lanes in a left by imm8 bytes while shifting in zeros, and store the results in dst.
_mm512_bsrli_epi128⚠(x86 or x86-64) and avx512bw
    Shift 128-bit lanes in a right by imm8 bytes while shifting in zeros, and store the results in dst.
_mm512_castpd128_pd512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128d to type __m512d; the upper 384 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castpd256_pd512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256d to type __m512d; the upper 256 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castpd512_pd128⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512d to type __m128d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castpd512_pd256⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512d to type __m256d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castpd_ps⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512d to type __m512. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castpd_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512d to type __m512i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps128_ps512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128 to type __m512; the upper 384 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps256_ps512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256 to type __m512; the upper 256 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps512_ps128⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512 to type __m128. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps512_ps256⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512 to type __m256. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps_pd⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512 to type __m512d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512 to type __m512i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi128_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128i to type __m512i; the upper 384 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi256_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256i to type __m512i; the upper 256 bits of the result are undefined. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi512_pd⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512i to type __m512d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi512_ps⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512i to type __m512. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi512_si128⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512i to type __m128i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi512_si256⚠(x86 or x86-64) and avx512f
    Cast vector of type __m512i to type __m256i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_clmulepi64_epi128⚠(x86 or x86-64) and vpclmulqdq,avx512f
    Performs a carry-less multiplication of two 64-bit polynomials over the finite field GF(2) - in each of the 4 128-bit lanes.
_mm512_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by IMM8, and store the results in mask vector k.
_mm512_cmp_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_round_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cmp_round_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for equality, and store the results in mask vector k.
_mm512_cmpeq_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for equality, and store the results in mask vector k.
_mm512_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm512_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm512_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmple_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for less-than-or-equal, and store the results in mask vector k.
_mm512_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for less-than, and store the results in mask vector k.
_mm512_cmplt_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for less-than, and store the results in mask vector k.
_mm512_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpneq_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-equal, and store the results in mask vector k.
_mm512_cmpnle_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-less-than-or-equal, and store the results in mask vector k.
_mm512_cmpnle_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-less-than-or-equal, and store the results in mask vector k.
_mm512_cmpnlt_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-less-than, and store the results in mask vector k.
_mm512_cmpnlt_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-less-than, and store the results in mask vector k.
_mm512_cmpord_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b to see if neither is NaN, and store the results in mask vector k.
_mm512_cmpord_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b to see if neither is NaN, and store the results in mask vector k.
_mm512_cmpunord_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b to see if either is NaN, and store the results in mask vector k.
_mm512_cmpunord_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b to see if either is NaN, and store the results in mask vector k.
_mm512_conflict_epi32⚠(x86 or x86-64) and avx512cd
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm512_conflict_epi64⚠(x86 or x86-64) and avx512cd
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm512_cvt_roundepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.\
_mm512_cvt_roundepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.\
_mm512_cvt_roundepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.\
_mm512_cvt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.\
_mm512_cvt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.\
_mm512_cvt_roundph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm512_cvt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.\
_mm512_cvt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst. Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_cvt_roundps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvt_roundps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst.
_mm512_cvtepi8_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtepi8_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm512_cvtepi16_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtepi16_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm512_cvtepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm512_cvtepi32_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepi32_pd⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi32lo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of packed 32-bit integer elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst.
_mm512_cvtepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm512_cvtepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm512_cvtepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst.
_mm512_cvtepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst.
_mm512_cvtepu8_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtepu8_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in the low 8 byte sof a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepu16_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtepu16_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepu32_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst.
_mm512_cvtepu32_pd⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu32lo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of packed 32-bit unsigned integer elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst.
_mm512_cvtepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in two 512-bit vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in a 512-bit wide vector. Intel’s documentation
_mm512_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst. Intel’s documentation
_mm512_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm512_cvtpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm512_cvtpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm512_cvtpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtpd_pslo⚠(x86 or x86-64) and avx512f
    Performs an element-by-element conversion of packed double-precision (64-bit) floating-point elements in v2 to single-precision (32-bit) floating-point elements and stores them in dst. The elements are stored in the lower half of the results vector, while the remaining upper half locations are set to 0.
_mm512_cvtph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm512_cvtps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm512_cvtps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm512_cvtps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_cvtpslo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of packed single-precision (32-bit) floating-point elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst.
_mm512_cvtsd_f64⚠(x86 or x86-64) and avx512f
    Copy the lower double-precision (64-bit) floating-point element of a to dst.
_mm512_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst.
_mm512_cvtsi512_si32⚠(x86 or x86-64) and avx512f
    Copy the lower 32-bit integer in a to dst.
_mm512_cvtss_f32⚠(x86 or x86-64) and avx512f
    Copy the lower single-precision (32-bit) floating-point element of a to dst.
_mm512_cvtt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvtt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_cvtt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvtt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_cvtt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvtt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_cvtt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_cvtt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_cvttpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm512_cvttpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm512_cvttpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm512_cvttpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm512_cvttps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm512_cvttps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm512_cvttps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm512_cvttps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm512_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm512_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm512_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm512_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm512_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm512_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst.
_mm512_dbsad_epu8⚠(x86 or x86-64) and avx512bw
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst. Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm512_div_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst.
_mm512_div_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst.
_mm512_div_round_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, =and store the results in dst.\
_mm512_div_round_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst.\
_mm512_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst.Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst. Intel’s documentation
_mm512_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm512_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm512_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm512_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm512_extractf32x4_ps⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the result in dst.
_mm512_extractf32x8_ps⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst.
_mm512_extractf64x2_pd⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst.
_mm512_extractf64x4_pd⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a, selected with imm8, and store the result in dst.
_mm512_extracti32x4_epi32⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM2, and store the result in dst.
_mm512_extracti32x8_epi32⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed 32-bit integers) from a, selected with IMM8, and stores the result in dst.
_mm512_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst.
_mm512_extracti64x4_epi64⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed 64-bit integers) from a, selected with IMM1, and store the result in dst.
_mm512_fixupimm_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm512_fixupimm_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm512_fixupimm_round_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.\
_mm512_fixupimm_round_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.\
_mm512_fmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm512_fmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm512_fmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.\
_mm512_fmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.\
_mm512_fmaddsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmaddsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmaddsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.\
_mm512_fmaddsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.\
_mm512_fmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm512_fmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm512_fmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.\
_mm512_fmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.\
_mm512_fmsubadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst.
_mm512_fmsubadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst.
_mm512_fmsubadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst.\
_mm512_fmsubadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst.\
_mm512_fnmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst.
_mm512_fnmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst.
_mm512_fnmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst.\
_mm512_fnmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst.\
_mm512_fnmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm512_fnmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm512_fnmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.\
_mm512_fnmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.\
_mm512_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm512_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm512_getexp_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_getexp_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_getexp_round_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_getexp_round_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_getmant_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_getmant_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign. The mantissa is normalized to the interval specified by interv, which can take the following values: _MM_MANT_NORM_1_2 // interval [1, 2) _MM_MANT_NORM_p5_2 // interval [0.5, 2) _MM_MANT_NORM_p5_1 // interval [0.5, 1) _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5) The sign is determined by sc which can take the following values: _MM_MANT_SIGN_src // sign = sign(src) _MM_MANT_SIGN_zero // sign = 0 _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_getmant_round_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_getmant_round_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512f
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512f
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512f
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm512_i32gather_epi32⚠(x86 or x86-64) and avx512f
    Gather 32-bit integers from memory using 32-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i32gather_epi64⚠(x86 or x86-64) and avx512f
    Gather 64-bit integers from memory using 32-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i32gather_pd⚠(x86 or x86-64) and avx512f
    Gather double-precision (64-bit) floating-point elements from memory using 32-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i32gather_ps⚠(x86 or x86-64) and avx512f
    Gather single-precision (32-bit) floating-point elements from memory using 32-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i32logather_epi64⚠(x86 or x86-64) and avx512f
    Loads 8 64-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale and stores them in dst.
_mm512_i32logather_pd⚠(x86 or x86-64) and avx512f
    Loads 8 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale and stores them in dst.
_mm512_i32loscatter_epi64⚠(x86 or x86-64) and avx512f
    Stores 8 64-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale.
_mm512_i32loscatter_pd⚠(x86 or x86-64) and avx512f
    Stores 8 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale.
_mm512_i32scatter_epi32⚠(x86 or x86-64) and avx512f
    Scatter 32-bit integers from a into memory using 32-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i32scatter_epi64⚠(x86 or x86-64) and avx512f
    Scatter 64-bit integers from a into memory using 32-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i32scatter_pd⚠(x86 or x86-64) and avx512f
    Scatter double-precision (64-bit) floating-point elements from a into memory using 32-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i32scatter_ps⚠(x86 or x86-64) and avx512f
    Scatter single-precision (32-bit) floating-point elements from a into memory using 32-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i64gather_epi32⚠(x86 or x86-64) and avx512f
    Gather 32-bit integers from memory using 64-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i64gather_epi64⚠(x86 or x86-64) and avx512f
    Gather 64-bit integers from memory using 64-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i64gather_pd⚠(x86 or x86-64) and avx512f
    Gather double-precision (64-bit) floating-point elements from memory using 64-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i64gather_ps⚠(x86 or x86-64) and avx512f
    Gather single-precision (32-bit) floating-point elements from memory using 64-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst. scale should be 1, 2, 4 or 8.
_mm512_i64scatter_epi32⚠(x86 or x86-64) and avx512f
    Scatter 32-bit integers from a into memory using 64-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i64scatter_epi64⚠(x86 or x86-64) and avx512f
    Scatter 64-bit integers from a into memory using 64-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i64scatter_pd⚠(x86 or x86-64) and avx512f
    Scatter double-precision (64-bit) floating-point elements from a into memory using 64-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). scale should be 1, 2, 4 or 8.
_mm512_i64scatter_ps⚠(x86 or x86-64) and avx512f
    Scatter single-precision (32-bit) floating-point elements from a into memory using 64-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_insertf32x4⚠(x86 or x86-64) and avx512f
    Copy a to dst, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into dst at the location specified by imm8.
_mm512_insertf32x8⚠(x86 or x86-64) and avx512dq
    Copy a to dst, then insert 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from b into dst at the location specified by IMM8.
_mm512_insertf64x2⚠(x86 or x86-64) and avx512dq
    Copy a to dst, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into dst at the location specified by IMM8.
_mm512_insertf64x4⚠(x86 or x86-64) and avx512f
    Copy a to dst, then insert 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from b into dst at the location specified by imm8.
_mm512_inserti32x4⚠(x86 or x86-64) and avx512f
    Copy a to dst, then insert 128 bits (composed of 4 packed 32-bit integers) from b into dst at the location specified by imm8.
_mm512_inserti32x8⚠(x86 or x86-64) and avx512dq
    Copy a to dst, then insert 256 bits (composed of 8 packed 32-bit integers) from b into dst at the location specified by IMM8.
_mm512_inserti64x2⚠(x86 or x86-64) and avx512dq
    Copy a to dst, then insert 128 bits (composed of 2 packed 64-bit integers) from b into dst at the location specified by IMM8.
_mm512_inserti64x4⚠(x86 or x86-64) and avx512f
    Copy a to dst, then insert 256 bits (composed of 4 packed 64-bit integers) from b into dst at the location specified by imm8.
_mm512_int2mask⚠(x86 or x86-64) and avx512f
    Converts integer mask into bitmask, storing the result in dst.
_mm512_kand⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of 16-bit masks a and b, and store the result in k.
_mm512_kandn⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 16-bit masks a and then AND with b, and store the result in k.
_mm512_kmov⚠(x86 or x86-64) and avx512f
    Copy 16-bit mask a to k.
_mm512_knot⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of 16-bit mask a, and store the result in k.
_mm512_kor⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 16-bit masks a and b, and store the result in k.
_mm512_kortestc⚠(x86 or x86-64) and avx512f
    Performs bitwise OR between k1 and k2, storing the result in dst. CF flag is set if dst consists of all 1’s.
_mm512_kortestz⚠(x86 or x86-64) and avx512f
    Performs bitwise OR between k1 and k2, storing the result in dst. ZF flag is set if dst is 0.
_mm512_kunpackb⚠(x86 or x86-64) and avx512f
    Unpack and interleave 8 bits from masks a and b, and store the 16-bit result in k.
_mm512_kunpackd⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 32 bits from masks a and b, and store the 64-bit result in k.
_mm512_kunpackw⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16 bits from masks a and b, and store the 32-bit result in k.
_mm512_kxnor⚠(x86 or x86-64) and avx512f
    Compute the bitwise XNOR of 16-bit masks a and b, and store the result in k.
_mm512_kxor⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of 16-bit masks a and b, and store the result in k.
_mm512_load_epi32⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 16 packed 32-bit integers) from memory into dst. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_load_epi64⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 8 packed 64-bit integers) from memory into dst. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_load_pd⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 8 packed double-precision (64-bit) floating-point elements) from memory into dst. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_load_ps⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 16 packed single-precision (32-bit) floating-point elements) from memory into dst. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_load_si512⚠(x86 or x86-64) and avx512f
    Load 512-bits of integer data from memory into dst. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_loadu_epi8⚠(x86 or x86-64) and avx512bw
    Load 512-bits (composed of 64 packed 8-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_epi16⚠(x86 or x86-64) and avx512bw
    Load 512-bits (composed of 32 packed 16-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_epi32⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 16 packed 32-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_epi64⚠(x86 or x86-64) and avx512f
    Load 512-bits (composed of 8 packed 64-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_pd⚠(x86 or x86-64) and avx512f
    Loads 512-bits (composed of 8 packed double-precision (64-bit) floating-point elements) from memory into result. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_ps⚠(x86 or x86-64) and avx512f
    Loads 512-bits (composed of 16 packed single-precision (32-bit) floating-point elements) from memory into result. mem_addr does not need to be aligned on any particular boundary.
_mm512_loadu_si512⚠(x86 or x86-64) and avx512f
    Load 512-bits of integer data from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm512_lzcnt_epi32⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst.
_mm512_lzcnt_epi64⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst.
_mm512_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm512_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm512_madd_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst.
_mm512_maddubs_epi16⚠(x86 or x86-64) and avx512bw
    Vertically multiply each unsigned 8-bit integer from a with the corresponding signed 8-bit integer from b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst.
_mm512_mask2_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask2_permutex2var_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm512_mask2_permutex2var_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm512_mask2_permutex2var_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm512_mask2_permutex2var_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set)
_mm512_mask2_permutex2var_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm512_mask2int⚠(x86 or x86-64) and avx512f
    Converts bit mask k1 into an integer value, storing the results in dst.
_mm512_mask3_fmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmaddsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmaddsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmaddsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmaddsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmsubadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsubadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsubadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fmsubadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fnmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fnmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fnmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask3_fnmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).\
_mm512_mask_abs_epi8⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_abs_epi16⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_abs_epi32⚠(x86 or x86-64) and avx512f
    Computes the absolute value of packed 32-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_abs_epi64⚠(x86 or x86-64) and avx512f
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_abs_pd⚠(x86 or x86-64) and avx512f
    Finds the absolute value of each packed double-precision (64-bit) floating-point element in v2, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_abs_ps⚠(x86 or x86-64) and avx512f
    Finds the absolute value of each packed single-precision (32-bit) floating-point element in v2, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_epi8⚠(x86 or x86-64) and avx512bw
    Add packed 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_epi16⚠(x86 or x86-64) and avx512bw
    Add packed 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_epi32⚠(x86 or x86-64) and avx512f
    Add packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_epi64⚠(x86 or x86-64) and avx512f
    Add packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_round_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_add_round_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_adds_epi8⚠(x86 or x86-64) and avx512bw
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_adds_epi16⚠(x86 or x86-64) and avx512bw
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_adds_epu8⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_adds_epu16⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_alignr_epi8⚠(x86 or x86-64) and avx512bw
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_alignr_epi32⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 64 bytes (16 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_alignr_epi64⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 64 bytes (8 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_and_epi32⚠(x86 or x86-64) and avx512f
    Performs element-by-element bitwise AND between packed 32-bit integer elements of a and b, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_and_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_and_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_and_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_andnot_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_andnot_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_andnot_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_andnot_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_avg_epu8⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_avg_epu16⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm512_mask_blend_epi8⚠(x86 or x86-64) and avx512bw
    Blend packed 8-bit integers from a and b using control mask k, and store the results in dst.
_mm512_mask_blend_epi16⚠(x86 or x86-64) and avx512bw
    Blend packed 16-bit integers from a and b using control mask k, and store the results in dst.
_mm512_mask_blend_epi32⚠(x86 or x86-64) and avx512f
    Blend packed 32-bit integers from a and b using control mask k, and store the results in dst.
_mm512_mask_blend_epi64⚠(x86 or x86-64) and avx512f
    Blend packed 64-bit integers from a and b using control mask k, and store the results in dst.
_mm512_mask_blend_pd⚠(x86 or x86-64) and avx512f
    Blend packed double-precision (64-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm512_mask_blend_ps⚠(x86 or x86-64) and avx512f
    Blend packed single-precision (32-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm512_mask_broadcast_f32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_f32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcast_f32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed single-precision (32-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_f64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_f64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed double-precision (64-bit) floating-point elements from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcast_i32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_i32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcast_i32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_i64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_broadcast_i64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 64-bit integers from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastb_epi8⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 8-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastd_epi32⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 32-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastq_epi64⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 64-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastsd_pd⚠(x86 or x86-64) and avx512f
    Broadcast the low double-precision (64-bit) floating-point element from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastss_ps⚠(x86 or x86-64) and avx512f
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_broadcastw_epi16⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 16-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_round_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cmp_round_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpeq_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmple_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmplt_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpneq_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpnle_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpnle_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpnlt_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b for not-less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpnlt_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b for not-less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpord_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b to see if neither is NaN, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpord_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b to see if neither is NaN, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpunord_pd_mask⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b to see if either is NaN, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmpunord_ps_mask⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b to see if either is NaN, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_compress_epi8⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compress_epi16⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compress_epi32⚠(x86 or x86-64) and avx512f
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compress_epi64⚠(x86 or x86-64) and avx512f
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compress_pd⚠(x86 or x86-64) and avx512f
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compress_ps⚠(x86 or x86-64) and avx512f
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm512_mask_compressstoreu_epi8⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_compressstoreu_epi16⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_compressstoreu_epi32⚠(x86 or x86-64) and avx512f
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_compressstoreu_epi64⚠(x86 or x86-64) and avx512f
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_compressstoreu_pd⚠(x86 or x86-64) and avx512f
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_compressstoreu_ps⚠(x86 or x86-64) and avx512f
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_conflict_epi32⚠(x86 or x86-64) and avx512cd
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm512_mask_conflict_epi64⚠(x86 or x86-64) and avx512cd
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm512_mask_cvt_roundepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_cvt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_mask_cvt_roundps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvt_roundps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_mask_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi8_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi8_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi16_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi16_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_pd⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepi32_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepi32lo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of packed 32-bit integer elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtepi64_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepi64_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepi64_storeu_epi32⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu8_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu8_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu16_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu16_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu32_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu32_pd⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu32lo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of 32-bit unsigned integer elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in single vector dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm512_mask_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm512_mask_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtpd_pslo⚠(x86 or x86-64) and avx512f
    Performs an element-by-element conversion of packed double-precision (64-bit) floating-point elements in v2 to single-precision (32-bit) floating-point elements and stores them in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The elements are stored in the lower half of the results vector, while the remaining upper half locations are set to 0.
_mm512_mask_cvtph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_mask_cvtpslo_pd⚠(x86 or x86-64) and avx512f
    Performs element-by-element conversion of the lower half of packed single-precision (32-bit) floating-point elements in v2 to packed double-precision (64-bit) floating-point elements, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi32_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtsepi32_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtsepi64_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtsepi64_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtsepi64_storeu_epi32⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvtt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_mask_cvtt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvtt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_mask_cvtt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvtt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_mask_cvtt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_cvtt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_mask_cvttpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvttpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvttps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvttps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi32_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtusepi32_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtusepi64_storeu_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtusepi64_storeu_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_cvtusepi64_storeu_epi32⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed 32-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm512_mask_dbsad_epu8⚠(x86 or x86-64) and avx512bw
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm512_mask_div_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_div_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_div_round_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_div_round_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm512_mask_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_epi8⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_epi16⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_epi32⚠(x86 or x86-64) and avx512f
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_epi64⚠(x86 or x86-64) and avx512f
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_pd⚠(x86 or x86-64) and avx512f
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expand_ps⚠(x86 or x86-64) and avx512f
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_epi32⚠(x86 or x86-64) and avx512f
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_epi64⚠(x86 or x86-64) and avx512f
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_pd⚠(x86 or x86-64) and avx512f
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_expandloadu_ps⚠(x86 or x86-64) and avx512f
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_extractf32x4_ps⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_extractf32x8_ps⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_extractf64x2_pd⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_extractf64x4_pd⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a, selected with imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_extracti32x4_epi32⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM2, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_extracti32x8_epi32⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed 32-bit integers) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_extracti64x4_epi64⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed 64-bit integers) from a, selected with IMM1, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_fixupimm_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm512_mask_fixupimm_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm512_mask_fixupimm_round_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.\
_mm512_mask_fixupimm_round_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.\
_mm512_mask_fmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmaddsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmaddsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmaddsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmaddsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmsubadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsubadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsubadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fmsubadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fnmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fnmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fnmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fnmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).\
_mm512_mask_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm512_mask_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm512_mask_getexp_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_mask_getexp_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_mask_getexp_round_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_getexp_round_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_getmant_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_mask_getmant_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_mask_getmant_round_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_getmant_round_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_mask_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_mask_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm512_mask_i32gather_epi32⚠(x86 or x86-64) and avx512f
    Gather 32-bit integers from memory using 32-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32gather_epi64⚠(x86 or x86-64) and avx512f
    Gather 64-bit integers from memory using 32-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32gather_pd⚠(x86 or x86-64) and avx512f
    Gather double-precision (64-bit) floating-point elements from memory using 32-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32gather_ps⚠(x86 or x86-64) and avx512f
    Gather single-precision (32-bit) floating-point elements from memory using 32-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32logather_epi64⚠(x86 or x86-64) and avx512f
    Loads 8 64-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale and stores them in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_i32logather_pd⚠(x86 or x86-64) and avx512f
    Loads 8 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale and stores them in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_i32loscatter_epi64⚠(x86 or x86-64) and avx512f
    Stores 8 64-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm512_mask_i32loscatter_pd⚠(x86 or x86-64) and avx512f
    Stores 8 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in the lower half of vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm512_mask_i32scatter_epi32⚠(x86 or x86-64) and avx512f
    Scatter 32-bit integers from a into memory using 32-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32scatter_epi64⚠(x86 or x86-64) and avx512f
    Scatter 64-bit integers from a into memory using 32-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32scatter_pd⚠(x86 or x86-64) and avx512f
    Scatter double-precision (64-bit) floating-point elements from a into memory using 32-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i32scatter_ps⚠(x86 or x86-64) and avx512f
    Scatter single-precision (32-bit) floating-point elements from a into memory using 32-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 32-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64gather_epi32⚠(x86 or x86-64) and avx512f
    Gather 32-bit integers from memory using 64-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64gather_epi64⚠(x86 or x86-64) and avx512f
    Gather 64-bit integers from memory using 64-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64gather_pd⚠(x86 or x86-64) and avx512f
    Gather double-precision (64-bit) floating-point elements from memory using 64-bit indices. 64-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64gather_ps⚠(x86 or x86-64) and avx512f
    Gather single-precision (32-bit) floating-point elements from memory using 64-bit indices. 32-bit elements are loaded from addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale). Gathered elements are merged into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64scatter_epi32⚠(x86 or x86-64) and avx512f
    Scatter 32-bit integers from a into memory using 64-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64scatter_epi64⚠(x86 or x86-64) and avx512f
    Scatter 64-bit integers from a into memory using 64-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64scatter_pd⚠(x86 or x86-64) and avx512f
    Scatter double-precision (64-bit) floating-point elements from a into memory using 64-bit indices. 64-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_i64scatter_ps⚠(x86 or x86-64) and avx512f
    Scatter single-precision (32-bit) floating-point elements from a into memory using 64-bit indices. 32-bit elements are stored at addresses starting at base_addr and offset by each 64-bit element in vindex (each index is scaled by the factor in scale) subject to mask k (elements are not stored when the corresponding mask bit is not set). scale should be 1, 2, 4 or 8.
_mm512_mask_insertf32x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_insertf32x8⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_insertf64x2⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_insertf64x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_inserti32x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 128 bits (composed of 4 packed 32-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_inserti32x8⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 256 bits (composed of 8 packed 32-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_inserti64x2⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 128 bits (composed of 2 packed 64-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_inserti64x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 256 bits (composed of 4 packed 64-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_load_epi32⚠(x86 or x86-64) and avx512f
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_load_epi64⚠(x86 or x86-64) and avx512f
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_load_pd⚠(x86 or x86-64) and avx512f
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_load_ps⚠(x86 or x86-64) and avx512f
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_loadu_epi8⚠(x86 or x86-64) and avx512bw
    Load packed 8-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_loadu_epi16⚠(x86 or x86-64) and avx512bw
    Load packed 16-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_loadu_epi32⚠(x86 or x86-64) and avx512f
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_loadu_epi64⚠(x86 or x86-64) and avx512f
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_loadu_pd⚠(x86 or x86-64) and avx512f
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_loadu_ps⚠(x86 or x86-64) and avx512f
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_lzcnt_epi32⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_lzcnt_epi64⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm512_mask_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm512_mask_madd_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_maddubs_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_max_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_max_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_min_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_min_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_min_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_mov_epi8⚠(x86 or x86-64) and avx512bw
    Move packed 8-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mov_epi16⚠(x86 or x86-64) and avx512bw
    Move packed 16-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mov_epi32⚠(x86 or x86-64) and avx512f
    Move packed 32-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mov_epi64⚠(x86 or x86-64) and avx512f
    Move packed 64-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mov_pd⚠(x86 or x86-64) and avx512f
    Move packed double-precision (64-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mov_ps⚠(x86 or x86-64) and avx512f
    Move packed single-precision (32-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_movedup_pd⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_movehdup_ps⚠(x86 or x86-64) and avx512f
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_moveldup_ps⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_epi32⚠(x86 or x86-64) and avx512f
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_epu32⚠(x86 or x86-64) and avx512f
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_mul_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_mulhi_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mulhi_epu16⚠(x86 or x86-64) and avx512bw
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mulhrs_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mullo_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mullo_epi32⚠(x86 or x86-64) and avx512f
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mullo_epi64⚠(x86 or x86-64) and avx512dq
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_mullox_epi64⚠(x86 or x86-64) and avx512f
    Multiplies elements in packed 64-bit integer vectors a and b together, storing the lower 64 bits of the result in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_or_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_or_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_or_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_or_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_packs_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_packs_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_packus_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_packus_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permute_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permute_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutevar_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Note that this intrinsic shuffles across 128-bit lanes, unlike past intrinsics that use the permutevar name. This intrinsic is identical to _mm512_mask_permutexvar_epi32, and it is recommended that you use that intrinsic name.
_mm512_mask_permutevar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutevar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex2var_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex2var_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex2var_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex2var_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex2var_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_permutex_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutex_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_permutexvar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm512_mask_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm512_mask_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm512_mask_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm512_mask_range_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_mask_range_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_mask_range_round_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_mask_range_round_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_mask_rcp14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_mask_rcp14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_mask_reduce_add_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm512_mask_reduce_add_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm512_mask_reduce_add_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by addition using mask k. Returns the sum of all active elements in a.
_mm512_mask_reduce_add_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by addition using mask k. Returns the sum of all active elements in a.
_mm512_mask_reduce_and_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by bitwise AND using mask k. Returns the bitwise AND of all active elements in a.
_mm512_mask_reduce_and_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm512_mask_reduce_max_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 32-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_max_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 64-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_max_epu32⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 32-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_max_epu64⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 64-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_max_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_max_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm512_mask_reduce_min_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 32-bit integers in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_min_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 64-bit integers in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_min_epu32⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 32-bit integers in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_min_epu64⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 64-bit integers in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_min_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_min_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by maximum using mask k. Returns the minimum of all active elements in a.
_mm512_mask_reduce_mul_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm512_mask_reduce_mul_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm512_mask_reduce_mul_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by multiplication using mask k. Returns the product of all active elements in a.
_mm512_mask_reduce_mul_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by multiplication using mask k. Returns the product of all active elements in a.
_mm512_mask_reduce_or_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm512_mask_reduce_or_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm512_mask_reduce_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_mask_reduce_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_mask_reduce_round_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_mask_reduce_round_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_mask_rol_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_rol_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_rolv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_rolv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_ror_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_ror_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_rorv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_rorv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_roundscale_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_mask_roundscale_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_mask_roundscale_round_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_mask_roundscale_round_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_mask_rsqrt14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_mask_rsqrt14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_mask_scalef_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_scalef_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_scalef_round_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_scalef_round_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_set1_epi8⚠(x86 or x86-64) and avx512bw
    Broadcast 8-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_set1_epi16⚠(x86 or x86-64) and avx512bw
    Broadcast 16-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_set1_epi32⚠(x86 or x86-64) and avx512f
    Broadcast 32-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_set1_epi64⚠(x86 or x86-64) and avx512f
    Broadcast 64-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using writemask k (elements are copied from src“ when the corresponding mask bit is not set).
_mm512_mask_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm512_mask_shuffle_epi8⚠(x86 or x86-64) and avx512bw
    Shuffle 8-bit integers in a within 128-bit lanes using the control in the corresponding 8-bit element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_f32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_f64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_i32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_i64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shuffle_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shufflehi_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_shufflelo_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sll_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sll_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sll_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_slli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_slli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_slli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sllv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sllv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sllv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sqrt_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sqrt_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sqrt_round_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_sqrt_round_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_sra_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sra_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sra_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srai_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srai_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srai_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srav_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srav_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srav_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srl_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srl_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srl_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srlv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srlv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_srlv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_store_epi32⚠(x86 or x86-64) and avx512f
    Store packed 32-bit integers from a into memory using writemask k. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_store_epi64⚠(x86 or x86-64) and avx512f
    Store packed 64-bit integers from a into memory using writemask k. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_store_pd⚠(x86 or x86-64) and avx512f
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_store_ps⚠(x86 or x86-64) and avx512f
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_mask_storeu_epi8⚠(x86 or x86-64) and avx512bw
    Store packed 8-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_storeu_epi16⚠(x86 or x86-64) and avx512bw
    Store packed 16-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_storeu_epi32⚠(x86 or x86-64) and avx512f
    Store packed 32-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_storeu_epi64⚠(x86 or x86-64) and avx512f
    Store packed 64-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_storeu_pd⚠(x86 or x86-64) and avx512f
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_storeu_ps⚠(x86 or x86-64) and avx512f
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm512_mask_sub_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_epi32⚠(x86 or x86-64) and avx512f
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_epi64⚠(x86 or x86-64) and avx512f
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_round_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_sub_round_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).\
_mm512_mask_subs_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_subs_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_subs_epu8⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_subs_epu16⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_ternarylogic_epi32⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 32-bit granularity (32-bit elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_ternarylogic_epi64⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 64-bit granularity (64-bit elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_test_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm512_mask_test_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm512_mask_test_epi32_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm512_mask_test_epi64_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm512_mask_testn_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm512_mask_testn_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm512_mask_testn_epi32_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm512_mask_testn_epi64_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm512_mask_unpackhi_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpackhi_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpackhi_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpackhi_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpackhi_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpackhi_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_unpacklo_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_xor_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_xor_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_xor_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_mask_xor_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm512_maskz_abs_epi8⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_abs_epi16⚠(x86 or x86-64) and avx512bw
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_abs_epi32⚠(x86 or x86-64) and avx512f
    Computes the absolute value of packed 32-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_abs_epi64⚠(x86 or x86-64) and avx512f
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_epi8⚠(x86 or x86-64) and avx512bw
    Add packed 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_epi16⚠(x86 or x86-64) and avx512bw
    Add packed 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_epi32⚠(x86 or x86-64) and avx512f
    Add packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_epi64⚠(x86 or x86-64) and avx512f
    Add packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_round_pd⚠(x86 or x86-64) and avx512f
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_add_round_ps⚠(x86 or x86-64) and avx512f
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_adds_epi8⚠(x86 or x86-64) and avx512bw
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_adds_epi16⚠(x86 or x86-64) and avx512bw
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_adds_epu8⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_adds_epu16⚠(x86 or x86-64) and avx512bw
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_alignr_epi8⚠(x86 or x86-64) and avx512bw
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_alignr_epi32⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 32-bit elements, and stores the low 64 bytes (16 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_alignr_epi64⚠(x86 or x86-64) and avx512f
    Concatenate a and b into a 128-byte immediate result, shift the result right by imm8 64-bit elements, and stores the low 64 bytes (8 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_and_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_and_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_and_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_and_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_andnot_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_andnot_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_andnot_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_andnot_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_avg_epu8⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_avg_epu16⚠(x86 or x86-64) and avx512bw
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcast_f32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed single-precision (32-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_f32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed single-precision (32-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcast_f32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed single-precision (32-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_f64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed double-precision (64-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_f64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed double-precision (64-bit) floating-point elements from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcast_i32x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_i32x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcast_i32x8⚠(x86 or x86-64) and avx512dq
    Broadcasts the 8 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_i64x2⚠(x86 or x86-64) and avx512dq
    Broadcasts the 2 packed 64-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_broadcast_i64x4⚠(x86 or x86-64) and avx512f
    Broadcast the 4 packed 64-bit integers from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastb_epi8⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 8-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastd_epi32⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 32-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastq_epi64⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 64-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastsd_pd⚠(x86 or x86-64) and avx512f
    Broadcast the low double-precision (64-bit) floating-point element from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastss_ps⚠(x86 or x86-64) and avx512f
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_broadcastw_epi16⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_compress_epi8⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 8-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_compress_epi16⚠(x86 or x86-64) and avx512vbmi2
    Contiguously store the active 16-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_compress_epi32⚠(x86 or x86-64) and avx512f
    Contiguously store the active 32-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_compress_epi64⚠(x86 or x86-64) and avx512f
    Contiguously store the active 64-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_compress_pd⚠(x86 or x86-64) and avx512f
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_compress_ps⚠(x86 or x86-64) and avx512f
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm512_maskz_conflict_epi32⚠(x86 or x86-64) and avx512cd
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm512_maskz_conflict_epi64⚠(x86 or x86-64) and avx512cd
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm512_maskz_cvt_roundepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_cvt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Rounding is done according to the ROUNDING parameter, which can be one of:
_mm512_maskz_cvt_roundps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvt_roundps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_maskz_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi8_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi8_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 8-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi16_epi32⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi16_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_epi64⚠(x86 or x86-64) and avx512f
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_pd⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_ps⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtepi64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu8_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu8_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 8-bit integers in the low 8 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu16_epi32⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu16_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 16-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu32_epi64⚠(x86 or x86-64) and avx512f
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu32_pd⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu32_ps⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu64_pd⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtepu64_ps⚠(x86 or x86-64) and avx512dq
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in single vector dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm512_maskz_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm512_maskz_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Converts packed BF16 (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtpd_ps⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_ps⚠(x86 or x86-64) and avx512f
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtps_pd⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtps_ph⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the rounding[3:0] parameter, which can be one of:
_mm512_maskz_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm512_maskz_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvtt_roundpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_maskz_cvtt_roundpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvtt_roundpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_maskz_cvtt_roundps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvtt_roundps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_maskz_cvtt_roundps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_cvtt_roundps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC to the sae parameter.
_mm512_maskz_cvttpd_epi32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttpd_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvttpd_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttpd_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding
_mm512_maskz_cvttps_epi32⚠(x86 or x86-64) and avx512f
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttps_epi64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvttps_epu32⚠(x86 or x86-64) and avx512f
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttps_epu64⚠(x86 or x86-64) and avx512dq
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_dbsad_epu8⚠(x86 or x86-64) and avx512bw
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm512_maskz_div_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_div_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_div_round_pd⚠(x86 or x86-64) and avx512f
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_div_round_ps⚠(x86 or x86-64) and avx512f
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512f
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm512_maskz_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_epi8⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_epi16⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_epi32⚠(x86 or x86-64) and avx512f
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_epi64⚠(x86 or x86-64) and avx512f
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_pd⚠(x86 or x86-64) and avx512f
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expand_ps⚠(x86 or x86-64) and avx512f
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_epi32⚠(x86 or x86-64) and avx512f
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_epi64⚠(x86 or x86-64) and avx512f
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_pd⚠(x86 or x86-64) and avx512f
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_expandloadu_ps⚠(x86 or x86-64) and avx512f
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_extractf32x4_ps⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from a, selected with imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_extractf32x8_ps⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_extractf64x2_pd⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_extractf64x4_pd⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from a, selected with imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_extracti32x4_epi32⚠(x86 or x86-64) and avx512f
    Extract 128 bits (composed of 4 packed 32-bit integers) from a, selected with IMM2, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_extracti32x8_epi32⚠(x86 or x86-64) and avx512dq
    Extracts 256 bits (composed of 8 packed 32-bit integers) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_extracti64x2_epi64⚠(x86 or x86-64) and avx512dq
    Extracts 128 bits (composed of 2 packed 64-bit integers) from a, selected with IMM8, and stores the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_extracti64x4_epi64⚠(x86 or x86-64) and avx512f
    Extract 256 bits (composed of 4 packed 64-bit integers) from a, selected with IMM1, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fixupimm_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm512_maskz_fixupimm_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm512_maskz_fixupimm_round_pd⚠(x86 or x86-64) and avx512f
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.\
_mm512_maskz_fixupimm_round_ps⚠(x86 or x86-64) and avx512f
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.\
_mm512_maskz_fmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in a using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmaddsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmaddsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmaddsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmaddsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmsubadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsubadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsubadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fmsubadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fnmadd_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmadd_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmadd_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fnmadd_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fnmsub_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmsub_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmsub_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_fnmsub_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_getexp_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_maskz_getexp_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_maskz_getexp_round_pd⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_getexp_round_ps⚠(x86 or x86-64) and avx512f
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_getmant_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_maskz_getmant_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm512_maskz_getmant_round_pd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_getmant_round_ps⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_maskz_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm512_maskz_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512f
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm512_maskz_insertf32x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 128 bits (composed of 4 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_insertf32x8⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 256 bits (composed of 8 packed single-precision (32-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_insertf64x2⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 128 bits (composed of 2 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_insertf64x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 256 bits (composed of 4 packed double-precision (64-bit) floating-point elements) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_inserti32x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 128 bits (composed of 4 packed 32-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_inserti32x8⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 256 bits (composed of 8 packed 32-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_inserti64x2⚠(x86 or x86-64) and avx512dq
    Copy a to tmp, then insert 128 bits (composed of 2 packed 64-bit integers) from b into tmp at the location specified by IMM8, and copy tmp to dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_inserti64x4⚠(x86 or x86-64) and avx512f
    Copy a to tmp, then insert 256 bits (composed of 4 packed 64-bit integers) from b into tmp at the location specified by imm8. Store tmp to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_load_epi32⚠(x86 or x86-64) and avx512f
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_maskz_load_epi64⚠(x86 or x86-64) and avx512f
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_maskz_load_pd⚠(x86 or x86-64) and avx512f
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_maskz_load_ps⚠(x86 or x86-64) and avx512f
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_maskz_loadu_epi8⚠(x86 or x86-64) and avx512bw
    Load packed 8-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_loadu_epi16⚠(x86 or x86-64) and avx512bw
    Load packed 16-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_loadu_epi32⚠(x86 or x86-64) and avx512f
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_loadu_epi64⚠(x86 or x86-64) and avx512f
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_loadu_pd⚠(x86 or x86-64) and avx512f
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_loadu_ps⚠(x86 or x86-64) and avx512f
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm512_maskz_lzcnt_epi32⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_lzcnt_epi64⚠(x86 or x86-64) and avx512cd
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_madd_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_maddubs_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_max_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_max_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_min_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_min_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_min_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_mov_epi8⚠(x86 or x86-64) and avx512bw
    Move packed 8-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mov_epi16⚠(x86 or x86-64) and avx512bw
    Move packed 16-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mov_epi32⚠(x86 or x86-64) and avx512f
    Move packed 32-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mov_epi64⚠(x86 or x86-64) and avx512f
    Move packed 64-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mov_pd⚠(x86 or x86-64) and avx512f
    Move packed double-precision (64-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mov_ps⚠(x86 or x86-64) and avx512f
    Move packed single-precision (32-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_movedup_pd⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_movehdup_ps⚠(x86 or x86-64) and avx512f
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_moveldup_ps⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_epi32⚠(x86 or x86-64) and avx512f
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_epu32⚠(x86 or x86-64) and avx512f
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_mul_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_mulhi_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mulhi_epu16⚠(x86 or x86-64) and avx512bw
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mulhrs_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mullo_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mullo_epi32⚠(x86 or x86-64) and avx512f
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mullo_epi64⚠(x86 or x86-64) and avx512dq
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_or_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_or_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_or_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_or_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_packs_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_packs_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_packus_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_packus_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permute_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permute_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutevar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutevar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex2var_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutex_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_permutexvar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm512_maskz_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm512_maskz_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm512_maskz_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm512_maskz_range_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_maskz_range_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_maskz_range_round_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_maskz_range_round_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_maskz_rcp14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_maskz_rcp14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_maskz_reduce_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_maskz_reduce_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_maskz_reduce_round_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_maskz_reduce_round_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm512_maskz_rol_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_rol_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_rolv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_rolv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_ror_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_ror_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_rorv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_rorv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_roundscale_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_maskz_roundscale_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_maskz_roundscale_round_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_maskz_roundscale_round_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_maskz_rsqrt14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_maskz_rsqrt14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm512_maskz_scalef_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_scalef_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_scalef_round_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_scalef_round_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_set1_epi8⚠(x86 or x86-64) and avx512bw
    Broadcast 8-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_set1_epi16⚠(x86 or x86-64) and avx512bw
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_set1_epi32⚠(x86 or x86-64) and avx512f
    Broadcast 32-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_set1_epi64⚠(x86 or x86-64) and avx512f
    Broadcast 64-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_epi8⚠(x86 or x86-64) and avx512bw
    Shuffle packed 8-bit integers in a according to shuffle control mask in the corresponding 8-bit element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_f32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_f64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_i32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_i64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shuffle_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shufflehi_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_shufflelo_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sll_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sll_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sll_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_slli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_slli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_slli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sllv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sllv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sllv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sqrt_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sqrt_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sqrt_round_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_sqrt_round_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_sra_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sra_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sra_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srai_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srai_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srai_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srav_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srav_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srav_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srl_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srl_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srl_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srlv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srlv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_srlv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_epi32⚠(x86 or x86-64) and avx512f
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_epi64⚠(x86 or x86-64) and avx512f
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_round_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_sub_round_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).\
_mm512_maskz_subs_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_subs_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_subs_epu8⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_subs_epu16⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_ternarylogic_epi32⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 32-bit granularity (32-bit elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_ternarylogic_epi64⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 64-bit granularity (64-bit elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpackhi_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_unpacklo_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_xor_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_xor_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_xor_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_maskz_xor_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm512_max_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst.
_mm512_max_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst.
_mm512_max_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst.
_mm512_max_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_max_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_min_epi8⚠(x86 or x86-64) and avx512bw
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epi16⚠(x86 or x86-64) and avx512bw
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epi32⚠(x86 or x86-64) and avx512f
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epi64⚠(x86 or x86-64) and avx512f
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epu8⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epu16⚠(x86 or x86-64) and avx512bw
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epu32⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_epu64⚠(x86 or x86-64) and avx512f
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst.
_mm512_min_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst.
_mm512_min_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst.
_mm512_min_round_pd⚠(x86 or x86-64) and avx512f
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_min_round_ps⚠(x86 or x86-64) and avx512f
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_movedup_pd⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst.
_mm512_movehdup_ps⚠(x86 or x86-64) and avx512f
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst.
_mm512_moveldup_ps⚠(x86 or x86-64) and avx512f
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst.
_mm512_movepi8_mask⚠(x86 or x86-64) and avx512bw
    Set each bit of mask register k based on the most significant bit of the corresponding packed 8-bit integer in a.
_mm512_movepi16_mask⚠(x86 or x86-64) and avx512bw
    Set each bit of mask register k based on the most significant bit of the corresponding packed 16-bit integer in a.
_mm512_movepi32_mask⚠(x86 or x86-64) and avx512dq
    Set each bit of mask register k based on the most significant bit of the corresponding packed 32-bit integer in a.
_mm512_movepi64_mask⚠(x86 or x86-64) and avx512dq
    Set each bit of mask register k based on the most significant bit of the corresponding packed 64-bit integer in a.
_mm512_movm_epi8⚠(x86 or x86-64) and avx512bw
    Set each packed 8-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm512_movm_epi16⚠(x86 or x86-64) and avx512bw
    Set each packed 16-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm512_movm_epi32⚠(x86 or x86-64) and avx512dq
    Set each packed 32-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm512_movm_epi64⚠(x86 or x86-64) and avx512dq
    Set each packed 64-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm512_mul_epi32⚠(x86 or x86-64) and avx512f
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst.
_mm512_mul_epu32⚠(x86 or x86-64) and avx512f
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst.
_mm512_mul_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst.
_mm512_mul_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst.
_mm512_mul_round_pd⚠(x86 or x86-64) and avx512f
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst.\
_mm512_mul_round_ps⚠(x86 or x86-64) and avx512f
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst.\
_mm512_mulhi_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst.
_mm512_mulhi_epu16⚠(x86 or x86-64) and avx512bw
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst.
_mm512_mulhrs_epi16⚠(x86 or x86-64) and avx512bw
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst.
_mm512_mullo_epi16⚠(x86 or x86-64) and avx512bw
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst.
_mm512_mullo_epi32⚠(x86 or x86-64) and avx512f
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst.
_mm512_mullo_epi64⚠(x86 or x86-64) and avx512dq
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst.
_mm512_mullox_epi64⚠(x86 or x86-64) and avx512f
    Multiplies elements in packed 64-bit integer vectors a and b together, storing the lower 64 bits of the result in dst.
_mm512_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst.
_mm512_or_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst.
_mm512_or_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the resut in dst.
_mm512_or_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst.
_mm512_or_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst.
_mm512_or_si512⚠(x86 or x86-64) and avx512f
    Compute the bitwise OR of 512 bits (representing integer data) in a and b, and store the result in dst.
_mm512_packs_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst.
_mm512_packs_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst.
_mm512_packus_epi16⚠(x86 or x86-64) and avx512bw
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst.
_mm512_packus_epi32⚠(x86 or x86-64) and avx512bw
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst.
_mm512_permute_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst.
_mm512_permute_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst.
_mm512_permutevar_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst. Note that this intrinsic shuffles across 128-bit lanes, unlike past intrinsics that use the permutevar name. This intrinsic is identical to _mm512_permutexvar_epi32, and it is recommended that you use that intrinsic name.
_mm512_permutevar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst.
_mm512_permutevar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst.
_mm512_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex2var_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex2var_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex2var_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex2var_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex2var_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutex_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a within 256-bit lanes using the control in imm8, and store the results in dst.
_mm512_permutex_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a within 256-bit lanes using the control in imm8, and store the results in dst.
_mm512_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm512_permutexvar_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm512_permutexvar_epi32⚠(x86 or x86-64) and avx512f
    Shuffle 32-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm512_permutexvar_epi64⚠(x86 or x86-64) and avx512f
    Shuffle 64-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm512_permutexvar_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements in a across lanes using the corresponding index in idx, and store the results in dst.
_mm512_permutexvar_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a across lanes using the corresponding index in idx.
_mm512_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm512_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm512_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm512_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm512_range_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_range_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm512_range_round_pd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_range_round_ps⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm512_rcp14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm512_rcp14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm512_reduce_add_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by addition. Returns the sum of all elements in a.
_mm512_reduce_add_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by addition. Returns the sum of all elements in a.
_mm512_reduce_add_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by addition. Returns the sum of all elements in a.
_mm512_reduce_add_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by addition. Returns the sum of all elements in a.
_mm512_reduce_and_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm512_reduce_and_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm512_reduce_max_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 32-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_max_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 64-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_max_epu32⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 32-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_max_epu64⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 64-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_max_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_max_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_min_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 32-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_min_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed signed 64-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_min_epu32⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 32-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_min_epu64⚠(x86 or x86-64) and avx512f
    Reduce the packed unsigned 64-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_min_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_min_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_mul_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by multiplication. Returns the product of all elements in a.
_mm512_reduce_mul_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by multiplication. Returns the product of all elements in a.
_mm512_reduce_mul_pd⚠(x86 or x86-64) and avx512f
    Reduce the packed double-precision (64-bit) floating-point elements in a by multiplication. Returns the product of all elements in a.
_mm512_reduce_mul_ps⚠(x86 or x86-64) and avx512f
    Reduce the packed single-precision (32-bit) floating-point elements in a by multiplication. Returns the product of all elements in a.
_mm512_reduce_or_epi32⚠(x86 or x86-64) and avx512f
    Reduce the packed 32-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm512_reduce_or_epi64⚠(x86 or x86-64) and avx512f
    Reduce the packed 64-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm512_reduce_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm512_reduce_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm512_reduce_round_pd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm512_reduce_round_ps⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm512_rol_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm512_rol_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm512_rolv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm512_rolv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm512_ror_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm512_ror_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm512_rorv_epi32⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm512_rorv_epi64⚠(x86 or x86-64) and avx512f
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm512_roundscale_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_roundscale_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_roundscale_round_pd⚠(x86 or x86-64) and avx512f
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_roundscale_round_ps⚠(x86 or x86-64) and avx512f
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm512_rsqrt14_pd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm512_rsqrt14_ps⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm512_sad_epu8⚠(x86 or x86-64) and avx512bw
    Compute the absolute differences of packed unsigned 8-bit integers in a and b, then horizontally sum each consecutive 8 differences to produce eight unsigned 16-bit integers, and pack these unsigned 16-bit integers in the low 16 bits of 64-bit elements in dst.
_mm512_scalef_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst.
_mm512_scalef_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst.
_mm512_scalef_round_pd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst.\
_mm512_scalef_round_ps⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst.\
_mm512_set1_epi8⚠(x86 or x86-64) and avx512f
    Broadcast 8-bit integer a to all elements of dst.
_mm512_set1_epi16⚠(x86 or x86-64) and avx512f
    Broadcast the low packed 16-bit integer from a to all elements of dst.
_mm512_set1_epi32⚠(x86 or x86-64) and avx512f
    Broadcast 32-bit integer a to all elements of dst.
_mm512_set1_epi64⚠(x86 or x86-64) and avx512f
    Broadcast 64-bit integer a to all elements of dst.
_mm512_set1_pd⚠(x86 or x86-64) and avx512f
    Broadcast 64-bit float a to all elements of dst.
_mm512_set1_ps⚠(x86 or x86-64) and avx512f
    Broadcast 32-bit float a to all elements of dst.
_mm512_set4_epi32⚠(x86 or x86-64) and avx512f
    Set packed 32-bit integers in dst with the repeated 4 element sequence.
_mm512_set4_epi64⚠(x86 or x86-64) and avx512f
    Set packed 64-bit integers in dst with the repeated 4 element sequence.
_mm512_set4_pd⚠(x86 or x86-64) and avx512f
    Set packed double-precision (64-bit) floating-point elements in dst with the repeated 4 element sequence.
_mm512_set4_ps⚠(x86 or x86-64) and avx512f
    Set packed single-precision (32-bit) floating-point elements in dst with the repeated 4 element sequence.
_mm512_set_epi8⚠(x86 or x86-64) and avx512f
    Set packed 8-bit integers in dst with the supplied values.
_mm512_set_epi16⚠(x86 or x86-64) and avx512f
    Set packed 16-bit integers in dst with the supplied values.
_mm512_set_epi32⚠(x86 or x86-64) and avx512f
    Sets packed 32-bit integers in dst with the supplied values.
_mm512_set_epi64⚠(x86 or x86-64) and avx512f
    Set packed 64-bit integers in dst with the supplied values.
_mm512_set_pd⚠(x86 or x86-64) and avx512f
    Set packed double-precision (64-bit) floating-point elements in dst with the supplied values.
_mm512_set_ps⚠(x86 or x86-64) and avx512f
    Sets packed 32-bit integers in dst with the supplied values.
_mm512_setr4_epi32⚠(x86 or x86-64) and avx512f
    Set packed 32-bit integers in dst with the repeated 4 element sequence in reverse order.
_mm512_setr4_epi64⚠(x86 or x86-64) and avx512f
    Set packed 64-bit integers in dst with the repeated 4 element sequence in reverse order.
_mm512_setr4_pd⚠(x86 or x86-64) and avx512f
    Set packed double-precision (64-bit) floating-point elements in dst with the repeated 4 element sequence in reverse order.
_mm512_setr4_ps⚠(x86 or x86-64) and avx512f
    Set packed single-precision (32-bit) floating-point elements in dst with the repeated 4 element sequence in reverse order.
_mm512_setr_epi32⚠(x86 or x86-64) and avx512f
    Sets packed 32-bit integers in dst with the supplied values in reverse order.
_mm512_setr_epi64⚠(x86 or x86-64) and avx512f
    Set packed 64-bit integers in dst with the supplied values in reverse order.
_mm512_setr_pd⚠(x86 or x86-64) and avx512f
    Set packed double-precision (64-bit) floating-point elements in dst with the supplied values in reverse order.
_mm512_setr_ps⚠(x86 or x86-64) and avx512f
    Sets packed 32-bit integers in dst with the supplied values in reverse order.
_mm512_setzero⚠(x86 or x86-64) and avx512f
    Return vector of type __m512 with all elements set to zero.
_mm512_setzero_epi32⚠(x86 or x86-64) and avx512f
    Return vector of type __m512i with all elements set to zero.
_mm512_setzero_pd⚠(x86 or x86-64) and avx512f
    Returns vector of type __m512d with all elements set to zero.
_mm512_setzero_ps⚠(x86 or x86-64) and avx512f
    Returns vector of type __m512 with all elements set to zero.
_mm512_setzero_si512⚠(x86 or x86-64) and avx512f
    Returns vector of type __m512i with all elements set to zero.
_mm512_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst).
_mm512_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst.
_mm512_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst).
_mm512_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst.
_mm512_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst.
_mm512_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst.
_mm512_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst.
_mm512_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst.
_mm512_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst.
_mm512_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst.
_mm512_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst.
_mm512_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst.
_mm512_shuffle_epi8⚠(x86 or x86-64) and avx512bw
    Shuffle packed 8-bit integers in a according to shuffle control mask in the corresponding 8-bit element of b, and store the results in dst.
_mm512_shuffle_epi32⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst.
_mm512_shuffle_f32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 single-precision (32-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst.
_mm512_shuffle_f64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 double-precision (64-bit) floating-point elements) selected by imm8 from a and b, and store the results in dst.
_mm512_shuffle_i32x4⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 4 32-bit integers) selected by imm8 from a and b, and store the results in dst.
_mm512_shuffle_i64x2⚠(x86 or x86-64) and avx512f
    Shuffle 128-bits (composed of 2 64-bit integers) selected by imm8 from a and b, and store the results in dst.
_mm512_shuffle_pd⚠(x86 or x86-64) and avx512f
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst.
_mm512_shuffle_ps⚠(x86 or x86-64) and avx512f
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst.
_mm512_shufflehi_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst.
_mm512_shufflelo_epi16⚠(x86 or x86-64) and avx512bw
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst.
_mm512_sll_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst.
_mm512_sll_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst.
_mm512_sll_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst.
_mm512_slli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst.
_mm512_slli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst.
_mm512_slli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst.
_mm512_sllv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_sllv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_sllv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_sqrt_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst.
_mm512_sqrt_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst.
_mm512_sqrt_round_pd⚠(x86 or x86-64) and avx512f
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst.\
_mm512_sqrt_round_ps⚠(x86 or x86-64) and avx512f
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst.\
_mm512_sra_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst.
_mm512_sra_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst.
_mm512_sra_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst.
_mm512_srai_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst.
_mm512_srai_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst.
_mm512_srai_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst.
_mm512_srav_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm512_srav_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm512_srav_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm512_srl_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst.
_mm512_srl_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst.
_mm512_srl_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst.
_mm512_srli_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst.
_mm512_srli_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst.
_mm512_srli_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst.
_mm512_srlv_epi16⚠(x86 or x86-64) and avx512bw
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_srlv_epi32⚠(x86 or x86-64) and avx512f
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_srlv_epi64⚠(x86 or x86-64) and avx512f
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm512_store_epi32⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 16 packed 32-bit integers) from a into memory. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_store_epi64⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 8 packed 64-bit integers) from a into memory. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_store_pd⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 8 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_store_ps⚠(x86 or x86-64) and avx512f
    Store 512-bits of integer data from a into memory. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_store_si512⚠(x86 or x86-64) and avx512f
    Store 512-bits of integer data from a into memory. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_storeu_epi8⚠(x86 or x86-64) and avx512bw
    Store 512-bits (composed of 64 packed 8-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_epi16⚠(x86 or x86-64) and avx512bw
    Store 512-bits (composed of 32 packed 16-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_epi32⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 16 packed 32-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_epi64⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 8 packed 64-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_pd⚠(x86 or x86-64) and avx512f
    Stores 512-bits (composed of 8 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_ps⚠(x86 or x86-64) and avx512f
    Stores 512-bits (composed of 16 packed single-precision (32-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_storeu_si512⚠(x86 or x86-64) and avx512f
    Store 512-bits of integer data from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm512_stream_load_si512⚠(x86 or x86-64) and avx512f
    Load 512-bits of integer data from memory into dst using a non-temporal memory hint. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)
_mm512_stream_pd⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 8 packed double-precision (64-bit) floating-point elements) from a into memory using a non-temporal memory hint. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_stream_ps⚠(x86 or x86-64) and avx512f
    Store 512-bits (composed of 16 packed single-precision (32-bit) floating-point elements) from a into memory using a non-temporal memory hint. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_stream_si512⚠(x86 or x86-64) and avx512f
    Store 512-bits of integer data from a into memory using a non-temporal memory hint. mem_addr must be aligned on a 64-byte boundary or a general-protection exception may be generated.
_mm512_sub_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst.
_mm512_sub_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst.
_mm512_sub_epi32⚠(x86 or x86-64) and avx512f
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst.
_mm512_sub_epi64⚠(x86 or x86-64) and avx512f
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst.
_mm512_sub_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst.
_mm512_sub_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst.
_mm512_sub_round_pd⚠(x86 or x86-64) and avx512f
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst.\
_mm512_sub_round_ps⚠(x86 or x86-64) and avx512f
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst.\
_mm512_subs_epi8⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst.
_mm512_subs_epi16⚠(x86 or x86-64) and avx512bw
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst.
_mm512_subs_epu8⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst.
_mm512_subs_epu16⚠(x86 or x86-64) and avx512bw
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst.
_mm512_ternarylogic_epi32⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm512_ternarylogic_epi64⚠(x86 or x86-64) and avx512f
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm512_test_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm512_test_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm512_test_epi32_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm512_test_epi64_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm512_testn_epi8_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm512_testn_epi16_mask⚠(x86 or x86-64) and avx512bw
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm512_testn_epi32_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm512_testn_epi64_mask⚠(x86 or x86-64) and avx512f
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm512_undefined⚠(x86 or x86-64) and avx512f
    Return vector of type __m512 with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm512_undefined_epi32⚠(x86 or x86-64) and avx512f
    Return vector of type __m512i with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm512_undefined_pd⚠(x86 or x86-64) and avx512f
    Returns vector of type __m512d with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm512_undefined_ps⚠(x86 or x86-64) and avx512f
    Returns vector of type __m512 with indeterminate elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm512_unpackhi_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpackhi_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpackhi_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpackhi_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpackhi_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpackhi_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_epi8⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_epi16⚠(x86 or x86-64) and avx512bw
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_epi32⚠(x86 or x86-64) and avx512f
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_epi64⚠(x86 or x86-64) and avx512f
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_pd⚠(x86 or x86-64) and avx512f
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_unpacklo_ps⚠(x86 or x86-64) and avx512f
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst.
_mm512_xor_epi32⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst.
_mm512_xor_epi64⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst.
_mm512_xor_pd⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst.
_mm512_xor_ps⚠(x86 or x86-64) and avx512dq
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst.
_mm512_xor_si512⚠(x86 or x86-64) and avx512f
    Compute the bitwise XOR of 512 bits (representing integer data) in a and b, and store the result in dst.
_mm512_zextpd128_pd512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128d to type __m512d; the upper 384 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_zextpd256_pd512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256d to type __m512d; the upper 256 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_zextps128_ps512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128 to type __m512; the upper 384 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_zextps256_ps512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256 to type __m512; the upper 256 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_zextsi128_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m128i to type __m512i; the upper 384 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_zextsi256_si512⚠(x86 or x86-64) and avx512f
    Cast vector of type __m256i to type __m512i; the upper 256 bits of the result are zeroed. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_abs_epi8⚠(x86 or x86-64) and ssse3
    Computes the absolute value of packed 8-bit signed integers in a and return the unsigned results.
_mm_abs_epi16⚠(x86 or x86-64) and ssse3
    Computes the absolute value of each of the packed 16-bit signed integers in a and return the 16-bit unsigned integer
_mm_abs_epi32⚠(x86 or x86-64) and ssse3
    Computes the absolute value of each of the packed 32-bit signed integers in a and return the 32-bit unsigned integer
_mm_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst.
_mm_add_epi8⚠(x86 or x86-64) and sse2
    Adds packed 8-bit integers in a and b.
_mm_add_epi16⚠(x86 or x86-64) and sse2
    Adds packed 16-bit integers in a and b.
_mm_add_epi32⚠(x86 or x86-64) and sse2
    Adds packed 32-bit integers in a and b.
_mm_add_epi64⚠(x86 or x86-64) and sse2
    Adds packed 64-bit integers in a and b.
_mm_add_pd⚠(x86 or x86-64) and sse2
    Adds packed double-precision (64-bit) floating-point elements in a and b.
_mm_add_ps⚠(x86 or x86-64) and sse
    Adds packed single-precision (32-bit) floating-point elements in a and b.
_mm_add_round_sd⚠(x86 or x86-64) and avx512f
    Add the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_add_round_ss⚠(x86 or x86-64) and avx512f
    Add the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_add_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the sum of the low elements of a and b.
_mm_add_ss⚠(x86 or x86-64) and sse
    Adds the first component of a and b, the other components are copied from a.
_mm_adds_epi8⚠(x86 or x86-64) and sse2
    Adds packed 8-bit integers in a and b using saturation.
_mm_adds_epi16⚠(x86 or x86-64) and sse2
    Adds packed 16-bit integers in a and b using saturation.
_mm_adds_epu8⚠(x86 or x86-64) and sse2
    Adds packed unsigned 8-bit integers in a and b using saturation.
_mm_adds_epu16⚠(x86 or x86-64) and sse2
    Adds packed unsigned 16-bit integers in a and b using saturation.
_mm_addsub_pd⚠(x86 or x86-64) and sse3
    Alternatively add and subtract packed double-precision (64-bit) floating-point elements in a to/from packed elements in b.
_mm_addsub_ps⚠(x86 or x86-64) and sse3
    Alternatively add and subtract packed single-precision (32-bit) floating-point elements in a to/from packed elements in b.
_mm_aesdec128kl_u8⚠(x86 or x86-64) and kl
    Decrypt 10 rounds of unsigned 8-bit integers in input using 128-bit AES key specified in the 384-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesdec256kl_u8⚠(x86 or x86-64) and kl
    Decrypt 14 rounds of unsigned 8-bit integers in input using 256-bit AES key specified in the 512-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesdec_si128⚠(x86 or x86-64) and aes
    Performs one round of an AES decryption flow on data (state) in a.
_mm_aesdeclast_si128⚠(x86 or x86-64) and aes
    Performs the last round of an AES decryption flow on data (state) in a.
_mm_aesdecwide128kl_u8⚠(x86 or x86-64) and widekl
    Decrypt 10 rounds of 8 groups of unsigned 8-bit integers in input using 128-bit AES key specified in the 384-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesdecwide256kl_u8⚠(x86 or x86-64) and widekl
    Decrypt 14 rounds of 8 groups of unsigned 8-bit integers in input using 256-bit AES key specified in the 512-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesenc128kl_u8⚠(x86 or x86-64) and kl
    Encrypt 10 rounds of unsigned 8-bit integers in input using 128-bit AES key specified in the 384-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesenc256kl_u8⚠(x86 or x86-64) and kl
    Encrypt 14 rounds of unsigned 8-bit integers in input using 256-bit AES key specified in the 512-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesenc_si128⚠(x86 or x86-64) and aes
    Performs one round of an AES encryption flow on data (state) in a.
_mm_aesenclast_si128⚠(x86 or x86-64) and aes
    Performs the last round of an AES encryption flow on data (state) in a.
_mm_aesencwide128kl_u8⚠(x86 or x86-64) and widekl
    Encrypt 10 rounds of 8 groups of unsigned 8-bit integers in input using 128-bit AES key specified in the 384-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesencwide256kl_u8⚠(x86 or x86-64) and widekl
    Encrypt 14 rounds of 8 groups of unsigned 8-bit integers in input using 256-bit AES key specified in the 512-bit key handle handle. Store the resulting unsigned 8-bit integers into the corresponding elements of output. Returns 0 if the operation was successful, and 1 if the operation failed due to a handle violation.
_mm_aesimc_si128⚠(x86 or x86-64) and aes
    Performs the InvMixColumns transformation on a.
_mm_aeskeygenassist_si128⚠(x86 or x86-64) and aes
    Assist in expanding the AES cipher key.
_mm_alignr_epi8⚠(x86 or x86-64) and ssse3
    Concatenate 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by n bytes, and returns the low 16 bytes.
_mm_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 16 bytes (4 elements) in dst.
_mm_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 16 bytes (2 elements) in dst.
_mm_and_pd⚠(x86 or x86-64) and sse2
    Computes the bitwise AND of packed double-precision (64-bit) floating-point elements in a and b.
_mm_and_ps⚠(x86 or x86-64) and sse
    Bitwise AND of packed single-precision (32-bit) floating-point elements.
_mm_and_si128⚠(x86 or x86-64) and sse2
    Computes the bitwise AND of 128 bits (representing integer data) in a and b.
_mm_andnot_pd⚠(x86 or x86-64) and sse2
    Computes the bitwise NOT of a and then AND with b.
_mm_andnot_ps⚠(x86 or x86-64) and sse
    Bitwise AND-NOT of packed single-precision (32-bit) floating-point elements.
_mm_andnot_si128⚠(x86 or x86-64) and sse2
    Computes the bitwise NOT of 128 bits (representing integer data) in a and then AND with b.
_mm_avg_epu8⚠(x86 or x86-64) and sse2
    Averages packed unsigned 8-bit integers in a and b.
_mm_avg_epu16⚠(x86 or x86-64) and sse2
    Averages packed unsigned 16-bit integers in a and b.
_mm_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg,avx512vl
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm_blend_epi16⚠(x86 or x86-64) and sse4.1
    Blend packed 16-bit integers from a and b using the mask IMM8.
_mm_blend_epi32⚠(x86 or x86-64) and avx2
    Blends packed 32-bit integers from a and b using control mask IMM4.
_mm_blend_pd⚠(x86 or x86-64) and sse4.1
    Blend packed double-precision (64-bit) floating-point elements from a and b using control mask IMM2
_mm_blend_ps⚠(x86 or x86-64) and sse4.1
    Blend packed single-precision (32-bit) floating-point elements from a and b using mask IMM4
_mm_blendv_epi8⚠(x86 or x86-64) and sse4.1
    Blend packed 8-bit integers from a and b using mask
_mm_blendv_pd⚠(x86 or x86-64) and sse4.1
    Blend packed double-precision (64-bit) floating-point elements from a and b using mask
_mm_blendv_ps⚠(x86 or x86-64) and sse4.1
    Blend packed single-precision (32-bit) floating-point elements from a and b using mask
_mm_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst.
_mm_broadcast_ss⚠(x86 or x86-64) and avx
    Broadcasts a single-precision (32-bit) floating-point element from memory to all elements of the returned vector.
_mm_broadcastb_epi8⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 8-bit integer from a to all elements of the 128-bit returned value.
_mm_broadcastd_epi32⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 32-bit integer from a to all elements of the 128-bit returned value.
_mm_broadcastmb_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Broadcast the low 8-bits from input mask k to all 64-bit elements of dst.
_mm_broadcastmw_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Broadcast the low 16-bits from input mask k to all 32-bit elements of dst.
_mm_broadcastq_epi64⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 64-bit integer from a to all elements of the 128-bit returned value.
_mm_broadcastsd_pd⚠(x86 or x86-64) and avx2
    Broadcasts the low double-precision (64-bit) floating-point element from a to all elements of the 128-bit returned value.
_mm_broadcastsi128_si256⚠(x86 or x86-64) and avx2
    Broadcasts 128 bits of integer data from a to all 128-bit lanes in the 256-bit returned value.
_mm_broadcastss_ps⚠(x86 or x86-64) and avx2
    Broadcasts the low single-precision (32-bit) floating-point element from a to all elements of the 128-bit returned value.
_mm_broadcastw_epi16⚠(x86 or x86-64) and avx2
    Broadcasts the low packed 16-bit integer from a to all elements of the 128-bit returned value
_mm_bslli_si128⚠(x86 or x86-64) and sse2
    Shifts a left by IMM8 bytes while shifting in zeros.
_mm_bsrli_si128⚠(x86 or x86-64) and sse2
    Shifts a right by IMM8 bytes while shifting in zeros.
_mm_castpd_ps⚠(x86 or x86-64) and sse2
    Casts a 128-bit floating-point vector of [2 x double] into a 128-bit floating-point vector of [4 x float].
_mm_castpd_si128⚠(x86 or x86-64) and sse2
    Casts a 128-bit floating-point vector of [2 x double] into a 128-bit integer vector.
_mm_castps_pd⚠(x86 or x86-64) and sse2
    Casts a 128-bit floating-point vector of [4 x float] into a 128-bit floating-point vector of [2 x double].
_mm_castps_si128⚠(x86 or x86-64) and sse2
    Casts a 128-bit floating-point vector of [4 x float] into a 128-bit integer vector.
_mm_castsi128_pd⚠(x86 or x86-64) and sse2
    Casts a 128-bit integer vector into a 128-bit floating-point vector of [2 x double].
_mm_castsi128_ps⚠(x86 or x86-64) and sse2
    Casts a 128-bit integer vector into a 128-bit floating-point vector of [4 x float].
_mm_ceil_pd⚠(x86 or x86-64) and sse4.1
    Round the packed double-precision (64-bit) floating-point elements in a up to an integer value, and stores the results as packed double-precision floating-point elements.
_mm_ceil_ps⚠(x86 or x86-64) and sse4.1
    Round the packed single-precision (32-bit) floating-point elements in a up to an integer value, and stores the results as packed single-precision floating-point elements.
_mm_ceil_sd⚠(x86 or x86-64) and sse4.1
    Round the lower double-precision (64-bit) floating-point element in b up to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copies the upper element from a to the upper element of the intrinsic result.
_mm_ceil_ss⚠(x86 or x86-64) and sse4.1
    Round the lower single-precision (32-bit) floating-point element in b up to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copies the upper 3 packed elements from a to the upper elements of the intrinsic result.
_mm_clflush⚠(x86 or x86-64) and sse2
    Invalidates and flushes the cache line that contains p from all levels of the cache hierarchy.
_mm_clmulepi64_si128⚠(x86 or x86-64) and pclmulqdq
    Performs a carry-less multiplication of two 64-bit polynomials over the finite field GF(2).
_mm_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_pd⚠(x86 or x86-64) and avx
    Compares packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by IMM5.
_mm_cmp_pd_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_ps⚠(x86 or x86-64) and avx
    Compares packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by IMM5.
_mm_cmp_ps_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_round_sd_mask⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cmp_round_ss_mask⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cmp_sd⚠(x86 or x86-64) and avx
    Compares the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by IMM5, store the result in the lower element of returned vector, and copies the upper element from a to the upper element of returned vector.
_mm_cmp_sd_mask⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k.
_mm_cmp_ss⚠(x86 or x86-64) and avx
    Compares the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by IMM5, store the result in the lower element of returned vector, and copies the upper 3 packed elements from a to the upper elements of returned vector.
_mm_cmp_ss_mask⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k.
_mm_cmpeq_epi8⚠(x86 or x86-64) and sse2
    Compares packed 8-bit integers in a and b for equality.
_mm_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epi16⚠(x86 or x86-64) and sse2
    Compares packed 16-bit integers in a and b for equality.
_mm_cmpeq_epi32⚠(x86 or x86-64) and sse2
    Compares packed 32-bit integers in a and b for equality.
_mm_cmpeq_epi64⚠(x86 or x86-64) and sse4.1
    Compares packed 64-bit integers in a and b for equality
_mm_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k.
_mm_cmpeq_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for equality.
_mm_cmpeq_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input elements were equal, or 0 otherwise.
_mm_cmpeq_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the equality comparison of the lower elements of a and b.
_mm_cmpeq_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for equality. The lowest 32 bits of the result will be 0xffffffff if the two inputs are equal, or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpestra⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return 1 if b did not contain a null character and the resulting mask was zero, and 0 otherwise.
_mm_cmpestrc⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return 1 if the resulting mask was non-zero, and 0 otherwise.
_mm_cmpestri⚠(x86 or x86-64) and sse4.2
    Compares packed strings a and b with lengths la and lb using the control in IMM8 and return the generated index. Similar to _mm_cmpistri with the exception that _mm_cmpistri implicitly determines the length of a and b.
_mm_cmpestrm⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return the generated mask.
_mm_cmpestro⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return bit 0 of the resulting bit mask.
_mm_cmpestrs⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return 1 if any character in a was null, and 0 otherwise.
_mm_cmpestrz⚠(x86 or x86-64) and sse4.2
    Compares packed strings in a and b with lengths la and lb using the control in IMM8, and return 1 if any character in b was null, and 0 otherwise.
_mm_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k.
_mm_cmpge_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for greater-than-or-equal.
_mm_cmpge_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is greater than or equal to the corresponding element in b, or 0 otherwise.
_mm_cmpge_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the greater-than-or-equal comparison of the lower elements of a and b.
_mm_cmpge_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for greater than or equal. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is greater than or equal b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpgt_epi8⚠(x86 or x86-64) and sse2
    Compares packed 8-bit integers in a and b for greater-than.
_mm_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epi16⚠(x86 or x86-64) and sse2
    Compares packed 16-bit integers in a and b for greater-than.
_mm_cmpgt_epi32⚠(x86 or x86-64) and sse2
    Compares packed 32-bit integers in a and b for greater-than.
_mm_cmpgt_epi64⚠(x86 or x86-64) and sse4.2
    Compares packed 64-bit integers in a and b for greater-than, return the results.
_mm_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k.
_mm_cmpgt_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for greater-than.
_mm_cmpgt_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is greater than the corresponding element in b, or 0 otherwise.
_mm_cmpgt_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the greater-than comparison of the lower elements of a and b.
_mm_cmpgt_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for greater than. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is greater than b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpistra⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and return 1 if b did not contain a null character and the resulting mask was zero, and 0 otherwise.
_mm_cmpistrc⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and return 1 if the resulting mask was non-zero, and 0 otherwise.
_mm_cmpistri⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8 and return the generated index. Similar to _mm_cmpestri with the exception that _mm_cmpestri requires the lengths of a and b to be explicitly specified.
_mm_cmpistrm⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and return the generated mask.
_mm_cmpistro⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and return bit 0 of the resulting bit mask.
_mm_cmpistrs⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and returns 1 if any character in a was null, and 0 otherwise.
_mm_cmpistrz⚠(x86 or x86-64) and sse4.2
    Compares packed strings with implicit lengths in a and b using the control in IMM8, and return 1 if any character in b was null. and 0 otherwise.
_mm_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k.
_mm_cmple_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for less-than-or-equal
_mm_cmple_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is less than or equal to the corresponding element in b, or 0 otherwise.
_mm_cmple_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the less-than-or-equal comparison of the lower elements of a and b.
_mm_cmple_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for less than or equal. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is less than or equal b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmplt_epi8⚠(x86 or x86-64) and sse2
    Compares packed 8-bit integers in a and b for less-than.
_mm_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epi16⚠(x86 or x86-64) and sse2
    Compares packed 16-bit integers in a and b for less-than.
_mm_cmplt_epi32⚠(x86 or x86-64) and sse2
    Compares packed 32-bit integers in a and b for less-than.
_mm_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k.
_mm_cmplt_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for less-than.
_mm_cmplt_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is less than the corresponding element in b, or 0 otherwise.
_mm_cmplt_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the less-than comparison of the lower elements of a and b.
_mm_cmplt_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for less than. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is less than b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k.
_mm_cmpneq_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for not-equal.
_mm_cmpneq_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input elements are not equal, or 0 otherwise.
_mm_cmpneq_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the not-equal comparison of the lower elements of a and b.
_mm_cmpneq_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for inequality. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is not equal to b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpnge_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for not-greater-than-or-equal.
_mm_cmpnge_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is not greater than or equal to the corresponding element in b, or 0 otherwise.
_mm_cmpnge_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the not-greater-than-or-equal comparison of the lower elements of a and b.
_mm_cmpnge_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for not-greater-than-or-equal. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is not greater than or equal to b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpngt_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for not-greater-than.
_mm_cmpngt_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is not greater than the corresponding element in b, or 0 otherwise.
_mm_cmpngt_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the not-greater-than comparison of the lower elements of a and b.
_mm_cmpngt_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for not-greater-than. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is not greater than b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpnle_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for not-less-than-or-equal.
_mm_cmpnle_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is not less than or equal to the corresponding element in b, or 0 otherwise.
_mm_cmpnle_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the not-less-than-or-equal comparison of the lower elements of a and b.
_mm_cmpnle_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for not-less-than-or-equal. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is not less than or equal to b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpnlt_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b for not-less-than.
_mm_cmpnlt_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. The result in the output vector will be 0xffffffff if the input element in a is not less than the corresponding element in b, or 0 otherwise.
_mm_cmpnlt_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the not-less-than comparison of the lower elements of a and b.
_mm_cmpnlt_ss⚠(x86 or x86-64) and sse
    Compares the lowest f32 of both inputs for not-less-than. The lowest 32 bits of the result will be 0xffffffff if a.extract(0) is not less than b.extract(0), or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpord_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b to see if neither is NaN.
_mm_cmpord_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. Returns four floats that have one of two possible bit patterns. The element in the output vector will be 0xffffffff if the input elements in a and b are ordered (i.e., neither of them is a NaN), or 0 otherwise.
_mm_cmpord_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the result of comparing both of the lower elements of a and b to NaN. If neither are equal to NaN then 0xFFFFFFFFFFFFFFFF is used and 0 otherwise.
_mm_cmpord_ss⚠(x86 or x86-64) and sse
    Checks if the lowest f32 of both inputs are ordered. The lowest 32 bits of the result will be 0xffffffff if neither of a.extract(0) or b.extract(0) is a NaN, or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_cmpunord_pd⚠(x86 or x86-64) and sse2
    Compares corresponding elements in a and b to see if either is NaN.
_mm_cmpunord_ps⚠(x86 or x86-64) and sse
    Compares each of the four floats in a to the corresponding element in b. Returns four floats that have one of two possible bit patterns. The element in the output vector will be 0xffffffff if the input elements in a and b are unordered (i.e., at least on of them is a NaN), or 0 otherwise.
_mm_cmpunord_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the result of comparing both of the lower elements of a and b to NaN. If either is equal to NaN then 0xFFFFFFFFFFFFFFFF is used and 0 otherwise.
_mm_cmpunord_ss⚠(x86 or x86-64) and sse
    Checks if the lowest f32 of both inputs are unordered. The lowest 32 bits of the result will be 0xffffffff if any of a.extract(0) or b.extract(0) is a NaN, or 0 otherwise. The upper 96 bits of the result are the upper 96 bits of a.
_mm_comi_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by imm8, and return the boolean result (0 or 1).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_comi_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by imm8, and return the boolean result (0 or 1).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_comieq_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for equality.
_mm_comieq_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if they are equal, or 0 otherwise.
_mm_comige_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for greater-than-or-equal.
_mm_comige_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is greater than or equal to the one from b, or 0 otherwise.
_mm_comigt_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for greater-than.
_mm_comigt_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is greater than the one from b, or 0 otherwise.
_mm_comile_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for less-than-or-equal.
_mm_comile_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is less than or equal to the one from b, or 0 otherwise.
_mm_comilt_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for less-than.
_mm_comilt_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is less than the one from b, or 0 otherwise.
_mm_comineq_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for not-equal.
_mm_comineq_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if they are not equal, or 0 otherwise.
_mm_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit. Each element’s comparison forms a zero extended bit vector in dst.
_mm_crc32_u8⚠(x86 or x86-64) and sse4.2
    Starting with the initial value in crc, return the accumulated CRC32-C value for unsigned 8-bit integer v.
_mm_crc32_u16⚠(x86 or x86-64) and sse4.2
    Starting with the initial value in crc, return the accumulated CRC32-C value for unsigned 16-bit integer v.
_mm_crc32_u32⚠(x86 or x86-64) and sse4.2
    Starting with the initial value in crc, return the accumulated CRC32-C value for unsigned 32-bit integer v.
_mm_crc32_u64⚠sse4.2
    Starting with the initial value in crc, return the accumulated CRC32-C value for unsigned 64-bit integer v.
_mm_cvt_roundi32_ss⚠(x86 or x86-64) and avx512f
    Convert the signed 32-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_cvt_roundi64_sd⚠avx512f
    Convert the signed 64-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundi64_ss⚠avx512f
    Convert the signed 64-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_i32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_i64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_si32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_si64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_ss⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_u32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsd_u64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsi32_ss⚠(x86 or x86-64) and avx512f
    Convert the signed 32-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_cvt_roundsi64_sd⚠avx512f
    Convert the signed 64-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundsi64_ss⚠avx512f
    Convert the signed 64-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_i32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_i64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_sd⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvt_roundss_si32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_si64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_u32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 32-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundss_u64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 64-bit integer, and store the result in dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundu32_ss⚠(x86 or x86-64) and avx512f
    Convert the unsigned 32-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundu64_sd⚠avx512f
    Convert the unsigned 64-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_roundu64_ss⚠avx512f
    Convert the unsigned 64-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_cvt_si2ss⚠(x86 or x86-64) and sse
    Alias for _mm_cvtsi32_ss.
_mm_cvt_ss2si⚠(x86 or x86-64) and sse
    Alias for _mm_cvtss_si32.
_mm_cvtepi8_epi16⚠(x86 or x86-64) and sse4.1
    Sign extend packed 8-bit integers in a to packed 16-bit integers
_mm_cvtepi8_epi32⚠(x86 or x86-64) and sse4.1
    Sign extend packed 8-bit integers in a to packed 32-bit integers
_mm_cvtepi8_epi64⚠(x86 or x86-64) and sse4.1
    Sign extend packed 8-bit integers in the low 8 bytes of a to packed 64-bit integers
_mm_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm_cvtepi16_epi32⚠(x86 or x86-64) and sse4.1
    Sign extend packed 16-bit integers in a to packed 32-bit integers
_mm_cvtepi16_epi64⚠(x86 or x86-64) and sse4.1
    Sign extend packed 16-bit integers in a to packed 64-bit integers
_mm_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm_cvtepi32_epi64⚠(x86 or x86-64) and sse4.1
    Sign extend packed 32-bit integers in a to packed 64-bit integers
_mm_cvtepi32_pd⚠(x86 or x86-64) and sse2
    Converts the lower two packed 32-bit integers in a to packed double-precision (64-bit) floating-point elements.
_mm_cvtepi32_ps⚠(x86 or x86-64) and sse2
    Converts packed 32-bit integers in a to packed single-precision (32-bit) floating-point elements.
_mm_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst.
_mm_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst.
_mm_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst.
_mm_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtepu8_epi16⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 8-bit integers in a to packed 16-bit integers
_mm_cvtepu8_epi32⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 8-bit integers in a to packed 32-bit integers
_mm_cvtepu8_epi64⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 8-bit integers in a to packed 64-bit integers
_mm_cvtepu16_epi32⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 16-bit integers in a to packed 32-bit integers
_mm_cvtepu16_epi64⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 16-bit integers in a to packed 64-bit integers
_mm_cvtepu32_epi64⚠(x86 or x86-64) and sse4.1
    Zeroes extend packed unsigned 32-bit integers in a to packed 64-bit integers
_mm_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvti32_sd⚠(x86 or x86-64) and avx512f
    Convert the signed 32-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvti32_ss⚠(x86 or x86-64) and avx512f
    Convert the signed 32-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvti64_sd⚠avx512f
    Convert the signed 64-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvti64_ss⚠avx512f
    Convert the signed 64-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two 128-bit vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in a 128-bit wide vector. Intel’s documentation
_mm_cvtneebf16_ps⚠(x86 or x86-64) and avxneconvert
    Convert packed BF16 (16-bit) floating-point even-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtneobf16_ps⚠(x86 or x86-64) and avxneconvert
    Convert packed BF16 (16-bit) floating-point odd-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtneps_avx_pbh⚠(x86 or x86-64) and avxneconvert
    Convert packed single precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst.
_mm_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst.
_mm_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to single-precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtpd_epi32⚠(x86 or x86-64) and sse2
    Converts packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers.
_mm_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm_cvtpd_ps⚠(x86 or x86-64) and sse2
    Converts packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements
_mm_cvtph_ps⚠(x86 or x86-64) and f16c
    Converts the 4 x 16-bit half-precision float values in the lowest 64-bit of the 128-bit vector a into 4 x 32-bit float values stored in a 128-bit wide vector.
_mm_cvtps_epi32⚠(x86 or x86-64) and sse2
    Converts packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers.
_mm_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst.
_mm_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst.
_mm_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst.
_mm_cvtps_pd⚠(x86 or x86-64) and sse2
    Converts packed single-precision (32-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements.
_mm_cvtps_ph⚠(x86 or x86-64) and f16c
    Converts the 4 x 32-bit float values in the 128-bit vector a into 4 x 16-bit half-precision float values stored in the lowest 64-bit of a 128-bit vector.
_mm_cvtsd_f64⚠(x86 or x86-64) and sse2
    Returns the lower double-precision (64-bit) floating-point element of a.
_mm_cvtsd_i32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
_mm_cvtsd_i64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
_mm_cvtsd_si32⚠(x86 or x86-64) and sse2
    Converts the lower double-precision (64-bit) floating-point element in a to a 32-bit integer.
_mm_cvtsd_si64⚠sse2
    Converts the lower double-precision (64-bit) floating-point element in a to a 64-bit integer.
_mm_cvtsd_si64x⚠sse2
    Alias for _mm_cvtsd_si64
_mm_cvtsd_ss⚠(x86 or x86-64) and sse2
    Converts the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of the return value, and copies the upper element from a to the upper element the return value.
_mm_cvtsd_u32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 32-bit integer, and store the result in dst.
_mm_cvtsd_u64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 64-bit integer, and store the result in dst.
_mm_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst.
_mm_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst.
_mm_cvtsi32_sd⚠(x86 or x86-64) and sse2
    Returns a with its lower element replaced by b after converting it to an f64.
_mm_cvtsi32_si128⚠(x86 or x86-64) and sse2
    Returns a vector whose lowest element is a and all higher elements are 0.
_mm_cvtsi32_ss⚠(x86 or x86-64) and sse
    Converts a 32 bit integer to a 32 bit float. The result vector is the input vector a with the lowest 32 bit float replaced by the converted integer.
_mm_cvtsi64_sd⚠sse2
    Returns a with its lower element replaced by b after converting it to an f64.
_mm_cvtsi64_si128⚠sse2
    Returns a vector whose lowest element is a and all higher elements are 0.
_mm_cvtsi64_ss⚠sse
    Converts a 64 bit integer to a 32 bit float. The result vector is the input vector a with the lowest 32 bit float replaced by the converted integer.
_mm_cvtsi64x_sd⚠sse2
    Returns a with its lower element replaced by b after converting it to an f64.
_mm_cvtsi64x_si128⚠sse2
    Returns a vector whose lowest element is a and all higher elements are 0.
_mm_cvtsi128_si32⚠(x86 or x86-64) and sse2
    Returns the lowest element of a.
_mm_cvtsi128_si64⚠sse2
    Returns the lowest element of a.
_mm_cvtsi128_si64x⚠sse2
    Returns the lowest element of a.
_mm_cvtss_f32⚠(x86 or x86-64) and sse
    Extracts the lowest 32 bit float from the input vector.
_mm_cvtss_i32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
_mm_cvtss_i64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
_mm_cvtss_sd⚠(x86 or x86-64) and sse2
    Converts the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of the return value, and copies the upper element from a to the upper element the return value.
_mm_cvtss_si32⚠(x86 or x86-64) and sse
    Converts the lowest 32 bit float in the input vector to a 32 bit integer.
_mm_cvtss_si64⚠sse
    Converts the lowest 32 bit float in the input vector to a 64 bit integer.
_mm_cvtss_u32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 32-bit integer, and store the result in dst.
_mm_cvtss_u64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 64-bit integer, and store the result in dst.
_mm_cvtt_roundsd_i32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundsd_i64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundsd_si32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundsd_si64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundsd_u32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundsd_u64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_i32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_i64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_si32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_si64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_u32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 32-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_roundss_u64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 64-bit integer with truncation, and store the result in dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cvtt_ss2si⚠(x86 or x86-64) and sse
    Alias for _mm_cvttss_si32.
_mm_cvttpd_epi32⚠(x86 or x86-64) and sse2
    Converts packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation.
_mm_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm_cvttps_epi32⚠(x86 or x86-64) and sse2
    Converts packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation.
_mm_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst.
_mm_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst.
_mm_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst.
_mm_cvttsd_i32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
_mm_cvttsd_i64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
_mm_cvttsd_si32⚠(x86 or x86-64) and sse2
    Converts the lower double-precision (64-bit) floating-point element in a to a 32-bit integer with truncation.
_mm_cvttsd_si64⚠sse2
    Converts the lower double-precision (64-bit) floating-point element in a to a 64-bit integer with truncation.
_mm_cvttsd_si64x⚠sse2
    Alias for _mm_cvttsd_si64
_mm_cvttsd_u32⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 32-bit integer with truncation, and store the result in dst.
_mm_cvttsd_u64⚠avx512f
    Convert the lower double-precision (64-bit) floating-point element in a to an unsigned 64-bit integer with truncation, and store the result in dst.
_mm_cvttss_i32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
_mm_cvttss_i64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
_mm_cvttss_si32⚠(x86 or x86-64) and sse
    Converts the lowest 32 bit float in the input vector to a 32 bit integer with truncation.
_mm_cvttss_si64⚠sse
    Converts the lowest 32 bit float in the input vector to a 64 bit integer with truncation.
_mm_cvttss_u32⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 32-bit integer with truncation, and store the result in dst.
_mm_cvttss_u64⚠avx512f
    Convert the lower single-precision (32-bit) floating-point element in a to an unsigned 64-bit integer with truncation, and store the result in dst.
_mm_cvtu32_sd⚠(x86 or x86-64) and avx512f
    Convert the unsigned 32-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvtu32_ss⚠(x86 or x86-64) and avx512f
    Convert the unsigned 32-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvtu64_sd⚠avx512f
    Convert the unsigned 64-bit integer b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvtu64_ss⚠avx512f
    Convert the unsigned 64-bit integer b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst.
_mm_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst.
_mm_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst.
_mm_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst. Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm_div_pd⚠(x86 or x86-64) and sse2
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b.
_mm_div_ps⚠(x86 or x86-64) and sse
    Divides packed single-precision (32-bit) floating-point elements in a and b.
_mm_div_round_sd⚠(x86 or x86-64) and avx512f
    Divide the lower double-precision (64-bit) floating-point element in a by the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_div_round_ss⚠(x86 or x86-64) and avx512f
    Divide the lower single-precision (32-bit) floating-point element in a by the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_div_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the result of diving the lower element of a by the lower element of b.
_mm_div_ss⚠(x86 or x86-64) and sse
    Divides the first component of b by a, the other components are copied from a.
_mm_dp_pd⚠(x86 or x86-64) and sse4.1
    Returns the dot product of two __m128d vectors.
_mm_dp_ps⚠(x86 or x86-64) and sse4.1
    Returns the dot product of two __m128 vectors.
_mm_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst. Intel’s documentation
_mm_dpbssd_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpbssds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_dpbsud_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpbsuds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_dpbusd_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpbusds_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm_dpbuud_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpbuuds_epi32⚠(x86 or x86-64) and avxvnniint8
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_dpwssd_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpwssds_avx_epi32⚠(x86 or x86-64) and avxvnni
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst.
_mm_dpwsud_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpwsuds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_dpwusd_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding signed 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpwusds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding signed 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_dpwuud_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst.
_mm_dpwuuds_epi32⚠(x86 or x86-64) and avxvnniint16
    Multiply groups of 2 adjacent pairs of unsigned 16-bit integers in a with corresponding unsigned 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src with signed saturation, and store the packed 32-bit results in dst.
_mm_encodekey128_u32⚠(x86 or x86-64) and kl
    Wrap a 128-bit AES key into a 384-bit key handle and stores it in handle. Returns the control parameter used to create the IWKey.
_mm_encodekey256_u32⚠(x86 or x86-64) and kl
    Wrap a 256-bit AES key into a 512-bit key handle and stores it in handle. Returns the control parameter used to create the IWKey.
_mm_extract_epi8⚠(x86 or x86-64) and sse4.1
    Extracts an 8-bit integer from a, selected with IMM8. Returns a 32-bit integer containing the zero-extended integer data.
_mm_extract_epi16⚠(x86 or x86-64) and sse2
    Returns the imm8 element of a.
_mm_extract_epi32⚠(x86 or x86-64) and sse4.1
    Extracts an 32-bit integer from a selected with IMM8
_mm_extract_epi64⚠sse4.1
    Extracts an 64-bit integer from a selected with IMM1
_mm_extract_ps⚠(x86 or x86-64) and sse4.1
    Extracts a single-precision (32-bit) floating-point element from a, selected with IMM8. The returned i32 stores the float’s bit-pattern, and may be converted back to a floating point number via casting.
_mm_extract_si64⚠(x86 or x86-64) and sse4a
    Extracts the bit range specified by y from the lower 64 bits of x.
_mm_extracti_si64⚠(x86 or x86-64) and sse4a
    Extracts the specified bits from the lower 64 bits of the 128-bit integer vector operand at the index idx and of the length len.
_mm_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst. imm8 is used to set the required flags reporting.
_mm_fixupimm_round_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_fixupimm_round_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_fixupimm_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
_mm_fixupimm_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
_mm_floor_pd⚠(x86 or x86-64) and sse4.1
    Round the packed double-precision (64-bit) floating-point elements in a down to an integer value, and stores the results as packed double-precision floating-point elements.
_mm_floor_ps⚠(x86 or x86-64) and sse4.1
    Round the packed single-precision (32-bit) floating-point elements in a down to an integer value, and stores the results as packed single-precision floating-point elements.
_mm_floor_sd⚠(x86 or x86-64) and sse4.1
    Round the lower double-precision (64-bit) floating-point element in b down to an integer value, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copies the upper element from a to the upper element of the intrinsic result.
_mm_floor_ss⚠(x86 or x86-64) and sse4.1
    Round the lower single-precision (32-bit) floating-point element in b down to an integer value, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copies the upper 3 packed elements from a to the upper elements of the intrinsic result.
_mm_fmadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to packed elements in c.
_mm_fmadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to packed elements in c.
_mm_fmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_fmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_fmadd_sd⚠(x86 or x86-64) and fma
    Multiplies the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Stores the result in the lower element of the returned value, and copy the upper element from a to the upper elements of the result.
_mm_fmadd_ss⚠(x86 or x86-64) and fma
    Multiplies the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Stores the result in the lower element of the returned value, and copy the 3 upper elements from a to the upper elements of the result.
_mm_fmaddsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and alternatively add and subtract packed elements in c to/from the intermediate result.
_mm_fmaddsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and alternatively add and subtract packed elements in c to/from the intermediate result.
_mm_fmsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result.
_mm_fmsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result.
_mm_fmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_fmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_fmsub_sd⚠(x86 or x86-64) and fma
    Multiplies the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of the returned value, and copy the upper element from a to the upper elements of the result.
_mm_fmsub_ss⚠(x86 or x86-64) and fma
    Multiplies the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from a to the upper elements of the result.
_mm_fmsubadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and alternatively subtract and add packed elements in c from/to the intermediate result.
_mm_fmsubadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and alternatively subtract and add packed elements in c from/to the intermediate result.
_mm_fnmadd_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to packed elements in c.
_mm_fnmadd_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to packed elements in c.
_mm_fnmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_fnmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_fnmadd_sd⚠(x86 or x86-64) and fma
    Multiplies the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of the returned value, and copy the upper element from a to the upper elements of the result.
_mm_fnmadd_ss⚠(x86 or x86-64) and fma
    Multiplies the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of the returned value, and copy the 3 upper elements from a to the upper elements of the result.
_mm_fnmsub_pd⚠(x86 or x86-64) and fma
    Multiplies packed double-precision (64-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result.
_mm_fnmsub_ps⚠(x86 or x86-64) and fma
    Multiplies packed single-precision (32-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result.
_mm_fnmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_fnmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, subtract the lower element in c from the negated intermediate result, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_fnmsub_sd⚠(x86 or x86-64) and fma
    Multiplies the lower double-precision (64-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result. Store the result in the lower element of the returned value, and copy the upper element from a to the upper elements of the result.
_mm_fnmsub_ss⚠(x86 or x86-64) and fma
    Multiplies the lower single-precision (32-bit) floating-point elements in a and b, and subtract packed elements in c from the negated intermediate result. Store the result in the lower element of the returned value, and copy the 3 upper elements from a to the upper elements of the result.
_mm_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm_fpclass_sd_mask⚠(x86 or x86-64) and avx512dq
    Test the lower double-precision (64-bit) floating-point element in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm_fpclass_ss_mask⚠(x86 or x86-64) and avx512dq
    Test the lower single-precision (32-bit) floating-point element in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm_getcsr⚠Deprecated(x86 or x86-64) and sse
    Gets the unsigned 32-bit value of the MXCSR control and status register.
_mm_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_getexp_round_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_getexp_round_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_getexp_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_getexp_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign. The mantissa is normalized to the interval specified by interv, which can take the following values: _MM_MANT_NORM_1_2 // interval [1, 2) _MM_MANT_NORM_p5_2 // interval [0.5, 2) _MM_MANT_NORM_p5_1 // interval [0.5, 1) _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5) The sign is determined by sc which can take the following values: _MM_MANT_SIGN_src // sign = sign(src) _MM_MANT_SIGN_zero // sign = 0 _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_getmant_round_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_getmant_round_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_getmant_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_getmant_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_gf2p8mul_epi8⚠(x86 or x86-64) and gfni
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm_hadd_epi16⚠(x86 or x86-64) and ssse3
    Horizontally adds the adjacent pairs of values contained in 2 packed 128-bit vectors of [8 x i16].
_mm_hadd_epi32⚠(x86 or x86-64) and ssse3
    Horizontally adds the adjacent pairs of values contained in 2 packed 128-bit vectors of [4 x i32].
_mm_hadd_pd⚠(x86 or x86-64) and sse3
    Horizontally adds adjacent pairs of double-precision (64-bit) floating-point elements in a and b, and pack the results.
_mm_hadd_ps⚠(x86 or x86-64) and sse3
    Horizontally adds adjacent pairs of single-precision (32-bit) floating-point elements in a and b, and pack the results.
_mm_hadds_epi16⚠(x86 or x86-64) and ssse3
    Horizontally adds the adjacent pairs of values contained in 2 packed 128-bit vectors of [8 x i16]. Positive sums greater than 7FFFh are saturated to 7FFFh. Negative sums less than 8000h are saturated to 8000h.
_mm_hsub_epi16⚠(x86 or x86-64) and ssse3
    Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of [8 x i16].
_mm_hsub_epi32⚠(x86 or x86-64) and ssse3
    Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of [4 x i32].
_mm_hsub_pd⚠(x86 or x86-64) and sse3
    Horizontally subtract adjacent pairs of double-precision (64-bit) floating-point elements in a and b, and pack the results.
_mm_hsub_ps⚠(x86 or x86-64) and sse3
    Horizontally adds adjacent pairs of single-precision (32-bit) floating-point elements in a and b, and pack the results.
_mm_hsubs_epi16⚠(x86 or x86-64) and ssse3
    Horizontally subtract the adjacent pairs of values contained in 2 packed 128-bit vectors of [8 x i16]. Positive differences greater than 7FFFh are saturated to 7FFFh. Negative differences less than 8000h are saturated to 8000h.
_mm_i32gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i32gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i32gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i32gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i32scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 32-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm_i32scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 64-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm_i32scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm_i32scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale
_mm_i64gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i64gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i64gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i64gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8.
_mm_i64scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 32-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm_i64scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 64-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm_i64scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm_i64scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale
_mm_insert_epi8⚠(x86 or x86-64) and sse4.1
    Returns a copy of a with the 8-bit integer from i inserted at a location specified by IMM8.
_mm_insert_epi16⚠(x86 or x86-64) and sse2
    Returns a new vector where the imm8 element of a is replaced with i.
_mm_insert_epi32⚠(x86 or x86-64) and sse4.1
    Returns a copy of a with the 32-bit integer from i inserted at a location specified by IMM8.
_mm_insert_epi64⚠sse4.1
    Returns a copy of a with the 64-bit integer from i inserted at a location specified by IMM1.
_mm_insert_ps⚠(x86 or x86-64) and sse4.1
    Select a single value in b to store at some position in a, Then zero elements according to IMM8.
_mm_insert_si64⚠(x86 or x86-64) and sse4a
    Inserts the [length:0] bits of y into x at index.
_mm_inserti_si64⚠(x86 or x86-64) and sse4a
    Inserts the len least-significant bits from the lower 64 bits of the 128-bit integer vector operand y into the lower 64 bits of the 128-bit integer vector operand x at the index idx and of the length len.
_mm_lddqu_si128⚠(x86 or x86-64) and sse3
    Loads 128-bits of integer data from unaligned memory. This intrinsic may perform better than _mm_loadu_si128 when the data crosses a cache line boundary.
_mm_lfence⚠(x86 or x86-64) and sse2
    Performs a serializing operation on all load-from-memory instructions that were issued prior to this instruction.
_mm_load1_pd⚠(x86 or x86-64) and sse2
    Loads a double-precision (64-bit) floating-point element from memory into both elements of returned vector.
_mm_load1_ps⚠(x86 or x86-64) and sse
    Construct a __m128 by duplicating the value read from p into all elements.
_mm_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load 128-bits (composed of 4 packed 32-bit integers) from memory into dst. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load 128-bits (composed of 2 packed 64-bit integers) from memory into dst. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_load_pd⚠(x86 or x86-64) and sse2
    Loads 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_load_pd1⚠(x86 or x86-64) and sse2
    Loads a double-precision (64-bit) floating-point element from memory into both elements of returned vector.
_mm_load_ps⚠(x86 or x86-64) and sse
    Loads four f32 values from aligned memory into a __m128. If the pointer is not aligned to a 128-bit boundary (16 bytes) a general protection fault will be triggered (fatal program crash).
_mm_load_ps1⚠(x86 or x86-64) and sse
    Alias for _mm_load1_ps
_mm_load_sd⚠(x86 or x86-64) and sse2
    Loads a 64-bit double-precision value to the low element of a 128-bit integer vector and clears the upper element.
_mm_load_si128⚠(x86 or x86-64) and sse2
    Loads 128-bits of integer data from memory into a new vector.
_mm_load_ss⚠(x86 or x86-64) and sse
    Construct a __m128 with the lowest element read from p and the other elements set to zero.
_mm_loaddup_pd⚠(x86 or x86-64) and sse3
    Loads a double-precision (64-bit) floating-point element from memory into both elements of return vector.
_mm_loadh_pd⚠(x86 or x86-64) and sse2
    Loads a double-precision value into the high-order bits of a 128-bit vector of [2 x double]. The low-order bits are copied from the low-order bits of the first operand.
_mm_loadiwkey⚠(x86 or x86-64) and kl
    Load internal wrapping key (IWKey). The 32-bit unsigned integer control specifies IWKey’s KeySource and whether backing up the key is permitted. IWKey’s 256-bit encryption key is loaded from key_lo and key_hi.
_mm_loadl_epi64⚠(x86 or x86-64) and sse2
    Loads 64-bit integer from memory into first element of returned vector.
_mm_loadl_pd⚠(x86 or x86-64) and sse2
    Loads a double-precision value into the low-order bits of a 128-bit vector of [2 x double]. The high-order bits are copied from the high-order bits of the first operand.
_mm_loadr_pd⚠(x86 or x86-64) and sse2
    Loads 2 double-precision (64-bit) floating-point elements from memory into the returned vector in reverse order. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_loadr_ps⚠(x86 or x86-64) and sse
    Loads four f32 values from aligned memory into a __m128 in reverse order.
_mm_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load 128-bits (composed of 16 packed 8-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load 128-bits (composed of 8 packed 16-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load 128-bits (composed of 4 packed 32-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load 128-bits (composed of 2 packed 64-bit integers) from memory into dst. mem_addr does not need to be aligned on any particular boundary.
_mm_loadu_pd⚠(x86 or x86-64) and sse2
    Loads 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from memory into the returned vector. mem_addr does not need to be aligned on any particular boundary.
_mm_loadu_ps⚠(x86 or x86-64) and sse
    Loads four f32 values from memory into a __m128. There are no restrictions on memory alignment. For aligned memory _mm_load_ps may be faster.
_mm_loadu_si16⚠(x86 or x86-64) and sse2
    Loads unaligned 16-bits of integer data from memory into new vector.
_mm_loadu_si32⚠(x86 or x86-64) and sse2
    Loads unaligned 32-bits of integer data from memory into new vector.
_mm_loadu_si64⚠(x86 or x86-64) and sse2
    Loads unaligned 64-bits of integer data from memory into new vector.
_mm_loadu_si128⚠(x86 or x86-64) and sse2
    Loads 128-bits of integer data from memory into a new vector.
_mm_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst.
_mm_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst.
_mm_madd52hi_avx_epu64⚠(x86 or x86-64) and avxifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm_madd52lo_avx_epu64⚠(x86 or x86-64) and avxifma
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst.
_mm_madd_epi16⚠(x86 or x86-64) and sse2
    Multiplies and then horizontally add signed 16 bit integers in a and b.
_mm_maddubs_epi16⚠(x86 or x86-64) and ssse3
    Multiplies corresponding pairs of packed 8-bit unsigned integer values contained in the first source operand and packed 8-bit signed integer values contained in the second source operand, add pairs of contiguous products with signed saturation, and writes the 16-bit sums to the corresponding bits in the destination.
_mm_mask2_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask2_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm_mask2_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm_mask2_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm_mask2_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set)
_mm_mask2_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from idx when the corresponding mask bit is not set).
_mm_mask3_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.\
_mm_mask3_fmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.\
_mm_mask3_fmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.
_mm_mask3_fmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.
_mm_mask3_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.\
_mm_mask3_fmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.\
_mm_mask3_fmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.
_mm_mask3_fmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.
_mm_mask3_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.\
_mm_mask3_fnmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.\
_mm_mask3_fnmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.
_mm_mask3_fnmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.
_mm_mask3_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.\
_mm_mask3_fnmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.\
_mm_mask3_fnmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from c to the upper element of dst.
_mm_mask3_fnmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from c to the upper elements of dst.
_mm_mask_abs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set)
_mm_mask_abs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_abs_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 32-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_round_sd⚠(x86 or x86-64) and avx512f
    Add the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_add_round_ss⚠(x86 or x86-64) and avx512f
    Add the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_add_sd⚠(x86 or x86-64) and avx512f
    Add the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_add_ss⚠(x86 or x86-64) and avx512f
    Add the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_adds_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_adds_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_adds_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_adds_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_alignr_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 16 bytes (4 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 16 bytes (2 elements) in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_and_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Performs element-by-element bitwise AND between packed 32-bit integer elements of a and b, storing the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_and_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_and_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_and_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_andnot_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_andnot_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_andnot_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_andnot_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_avg_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_avg_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_bitshuffle_epi64_mask⚠(x86 or x86-64) and avx512bitalg,avx512vl
    Considers the input b as packed 64-bit integers and c as packed 8-bit integers. Then groups 8 8-bit values from cas indices into the bits of the corresponding 64-bit integer. It then selects these bits and packs them into the output.
_mm_mask_blend_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Blend packed 8-bit integers from a and b using control mask k, and store the results in dst.
_mm_mask_blend_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Blend packed 16-bit integers from a and b using control mask k, and store the results in dst.
_mm_mask_blend_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed 32-bit integers from a and b using control mask k, and store the results in dst.
_mm_mask_blend_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed 64-bit integers from a and b using control mask k, and store the results in dst.
_mm_mask_blend_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed double-precision (64-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm_mask_blend_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Blend packed single-precision (32-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm_mask_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_broadcastb_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 8-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_broadcastd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 32-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_broadcastq_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 64-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_broadcastss_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_broadcastw_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cmp_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_pd_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_ps_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_round_sd_mask⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1 (the element is zeroed out when mask bit 0 is not set).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_cmp_round_ss_mask⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1 (the element is zeroed out when mask bit 0 is not seti).
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_cmp_sd_mask⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1 (the element is zeroed out when mask bit 0 is not set).
_mm_mask_cmp_ss_mask⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point element in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1 (the element is zeroed out when mask bit 0 is not set).
_mm_mask_cmpeq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpeq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for equality, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpge_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpgt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for greater-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmple_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than-or-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmplt_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for less-than, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epu8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epu16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epu32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmpneq_epu64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b for not-equal, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_compress_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compress_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compress_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compress_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compress_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compress_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to dst, and pass through the remaining elements from src.
_mm_mask_compressstoreu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_compressstoreu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_compressstoreu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_compressstoreu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_compressstoreu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_compressstoreu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm_mask_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using writemask k (elements are copied from src when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm_mask_cvt_roundps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_cvt_roundsd_ss⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_mask_cvt_roundss_sd⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in the low 2 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi32_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 4 bytes of a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 2 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in single vector dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm_mask_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtpd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_cvtsd_ss⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtsepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtsepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtsepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtsepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtss_sd⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_cvttpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvttps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi16_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi32_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtusepi32_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtusepi64_storeu_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 8-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtusepi64_storeu_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 16-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_cvtusepi64_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed 32-bit integers with unsigned saturation, and store the active results (those with their respective bit set in writemask k) to unaligned memory at base_addr.
_mm_mask_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm_mask_div_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_div_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_div_round_sd⚠(x86 or x86-64) and avx512f
    Divide the lower double-precision (64-bit) floating-point element in a by the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_div_round_ss⚠(x86 or x86-64) and avx512f
    Divide the lower single-precision (32-bit) floating-point element in a by the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_div_sd⚠(x86 or x86-64) and avx512f
    Divide the lower double-precision (64-bit) floating-point element in a by the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_div_ss⚠(x86 or x86-64) and avx512f
    Divide the lower single-precision (32-bit) floating-point element in a by the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Intel’s documentation
_mm_mask_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expand_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_expandloadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm_mask_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm_mask_fixupimm_round_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_fixupimm_round_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_fixupimm_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
_mm_mask_fixupimm_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
_mm_mask_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_fmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_fmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_fmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_fmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_fmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_fmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fnmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_fnmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_fnmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_fnmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_fnmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_fnmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_fnmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_fnmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_fpclass_pd_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed double-precision (64-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_fpclass_ps_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Test packed single-precision (32-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_fpclass_sd_mask⚠(x86 or x86-64) and avx512dq
    Test the lower double-precision (64-bit) floating-point element in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_fpclass_ss_mask⚠(x86 or x86-64) and avx512dq
    Test the lower single-precision (32-bit) floating-point element in a for special categories specified by imm8, and store the results in mask vector k using zeromask k1 (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_mask_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_mask_getexp_round_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_getexp_round_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_getexp_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_mask_getexp_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_mask_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_mask_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_mask_getmant_round_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_getmant_round_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_getmant_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_getmant_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_mask_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_mask_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm_mask_i32gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i32gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i32gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i32gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i32scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 32-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i32scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 64-bit integer elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i32scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i32scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 4 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i64gather_epi32⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i64gather_epi64⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i64gather_pd⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i64gather_ps⚠(x86 or x86-64) and avx2
    Returns values from slice at offsets determined by offsets * scale, where scale should be 1, 2, 4 or 8. If mask is set, load the value from src in that position instead.
_mm_mask_i64scatter_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 32-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i64scatter_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 64-bit integer elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i64scatter_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 double-precision (64-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding mask bit is not set are not written to memory).
_mm_mask_i64scatter_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Stores 2 single-precision (32-bit) floating-point elements from a to memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements whose corresponding
_mm_mask_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_load_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_load_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_load_sd⚠(x86 or x86-64) and avx512f
    Load a double-precision (64-bit) floating-point element from memory into the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and set the upper element of dst to zero. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_load_ss⚠(x86 or x86-64) and avx512f
    Load a single-precision (32-bit) floating-point element from memory into the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and set the upper 3 packed elements of dst to zero. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 8-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 16-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_loadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_loadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using writemask k (elements are copied from src when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_mask_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm_mask_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are copied from k when the corresponding mask bit is not set).
_mm_mask_madd_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_maddubs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_max_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_max_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_max_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_max_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_min_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_min_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_min_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_min_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_mov_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 8-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mov_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 16-bit integers from a into dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mov_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 32-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mov_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 64-bit integers from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mov_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed double-precision (64-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mov_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed single-precision (32-bit) floating-point elements from a to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_move_sd⚠(x86 or x86-64) and avx512f
    Move the lower double-precision (64-bit) floating-point element from b to the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_move_ss⚠(x86 or x86-64) and avx512f
    Move the lower single-precision (32-bit) floating-point element from b to the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_movedup_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_movehdup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_moveldup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_mul_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_mul_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_mul_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_mulhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mulhi_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mulhrs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mullo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mullo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_or_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_or_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_packs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_packs_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_packus_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_packus_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permute_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permute_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permutevar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permutevar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm_mask_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm_mask_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm_mask_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm_mask_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_mask_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_mask_range_round_sd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_range_round_ss⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_range_sd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_mask_range_ss⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_mask_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rcp14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rcp14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_mask_reduce_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm_mask_reduce_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by addition using mask k. Returns the sum of all active elements in a.
_mm_mask_reduce_and_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise AND using mask k. Returns the bitwise AND of all active elements in a.
_mm_mask_reduce_and_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise AND using mask k. Returns the bitwise AND of all active elements in a.
_mm_mask_reduce_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm_mask_reduce_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm_mask_reduce_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm_mask_reduce_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by maximum using mask k. Returns the maximum of all active elements in a.
_mm_mask_reduce_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm_mask_reduce_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm_mask_reduce_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm_mask_reduce_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by minimum using mask k. Returns the minimum of all active elements in a.
_mm_mask_reduce_mul_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm_mask_reduce_mul_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by multiplication using mask k. Returns the product of all active elements in a.
_mm_mask_reduce_or_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm_mask_reduce_or_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise OR using mask k. Returns the bitwise OR of all active elements in a.
_mm_mask_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src to dst if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_reduce_round_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_reduce_round_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_reduce_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_reduce_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_mask_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_roundscale_round_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_roundscale_round_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_roundscale_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_roundscale_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_mask_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rsqrt14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_mask_rsqrt14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_mask_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_scalef_round_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_scalef_round_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_scalef_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_scalef_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_set1_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 8-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_set1_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 16-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_set1_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 32-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_set1_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 64-bit integer a to all elements of dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using writemask k (elements are copied from src“ when the corresponding mask bit is not set).
_mm_mask_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using writemask k (elements are copied from a when the corresponding mask bit is not set).
_mm_mask_shuffle_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 8-bit integers in a within 128-bit lanes using the control in the corresponding 8-bit element of b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shuffle_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shuffle_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shuffle_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a using the control in imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shufflehi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_shufflelo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sll_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sll_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sll_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_slli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_slli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_slli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sllv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sllv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sqrt_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sqrt_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sqrt_round_sd⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_sqrt_round_ss⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_sqrt_sd⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_sqrt_ss⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_sra_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sra_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srai_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srai_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srav_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srl_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srl_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srl_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srlv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_srlv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_store_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 32-bit integers from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_store_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 64-bit integers from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_store_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_store_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_store_sd⚠(x86 or x86-64) and avx512f
    Store a double-precision (64-bit) floating-point element from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_store_ss⚠(x86 or x86-64) and avx512f
    Store a single-precision (32-bit) floating-point element from a into memory using writemask k. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_mask_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Store packed 8-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_storeu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Store packed 16-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 32-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_storeu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed 64-bit integers from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_storeu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed double-precision (64-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_storeu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Store packed single-precision (32-bit) floating-point elements from a into memory using writemask k. mem_addr does not need to be aligned on any particular boundary.
_mm_mask_sub_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_round_sd⚠(x86 or x86-64) and avx512f
    Subtract the lower double-precision (64-bit) floating-point element in b from the lower double-precision (64-bit) floating-point element in a, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_mask_sub_round_ss⚠(x86 or x86-64) and avx512f
    Subtract the lower single-precision (32-bit) floating-point element in b from the lower single-precision (32-bit) floating-point element in a, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mask_sub_sd⚠(x86 or x86-64) and avx512f
    Subtract the lower double-precision (64-bit) floating-point element in b from the lower double-precision (64-bit) floating-point element in a, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_sub_ss⚠(x86 or x86-64) and avx512f
    Subtract the lower single-precision (32-bit) floating-point element in b from the lower single-precision (32-bit) floating-point element in a, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_subs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_subs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_subs_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_subs_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 32-bit granularity (32-bit elements are copied from src when the corresponding mask bit is not set).
_mm_mask_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from src, a, and b are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using writemask k at 64-bit granularity (64-bit elements are copied from src when the corresponding mask bit is not set).
_mm_mask_test_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm_mask_test_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm_mask_test_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm_mask_test_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is non-zero.
_mm_mask_testn_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm_mask_testn_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm_mask_testn_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm_mask_testn_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k (subject to writemask k) if the intermediate value is zero.
_mm_mask_unpackhi_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpackhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpackhi_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpackhi_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpackhi_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpackhi_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_unpacklo_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_xor_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_mask_xor_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using writemask k (elements are copied from src if the corresponding bit is not set).
_mm_maskload_epi32⚠(x86 or x86-64) and avx2
    Loads packed 32-bit integers from memory pointed by mem_addr using mask (elements are zeroed out when the highest bit is not set in the corresponding element).
_mm_maskload_epi64⚠(x86 or x86-64) and avx2
    Loads packed 64-bit integers from memory pointed by mem_addr using mask (elements are zeroed out when the highest bit is not set in the corresponding element).
_mm_maskload_pd⚠(x86 or x86-64) and avx
    Loads packed double-precision (64-bit) floating-point elements from memory into result using mask (elements are zeroed out when the high bit of the corresponding element is not set).
_mm_maskload_ps⚠(x86 or x86-64) and avx
    Loads packed single-precision (32-bit) floating-point elements from memory into result using mask (elements are zeroed out when the high bit of the corresponding element is not set).
_mm_maskmoveu_si128⚠(x86 or x86-64) and sse2
    Conditionally store 8-bit integer elements from a into memory using mask.
_mm_maskstore_epi32⚠(x86 or x86-64) and avx2
    Stores packed 32-bit integers from a into memory pointed by mem_addr using mask (elements are not stored when the highest bit is not set in the corresponding element).
_mm_maskstore_epi64⚠(x86 or x86-64) and avx2
    Stores packed 64-bit integers from a into memory pointed by mem_addr using mask (elements are not stored when the highest bit is not set in the corresponding element).
_mm_maskstore_pd⚠(x86 or x86-64) and avx
    Stores packed double-precision (64-bit) floating-point elements from a into memory using mask.
_mm_maskstore_ps⚠(x86 or x86-64) and avx
    Stores packed single-precision (32-bit) floating-point elements from a into memory using mask.
_mm_maskz_abs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 8-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_abs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the absolute value of packed signed 16-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_abs_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 32-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_abs_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the absolute value of packed signed 64-bit integers in a, and store the unsigned results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Add packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_round_sd⚠(x86 or x86-64) and avx512f
    Add the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_add_round_ss⚠(x86 or x86-64) and avx512f
    Add the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_add_sd⚠(x86 or x86-64) and avx512f
    Add the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_add_ss⚠(x86 or x86-64) and avx512f
    Add the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_adds_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_adds_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed signed 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_adds_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 8-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_adds_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Add packed unsigned 16-bit integers in a and b using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_alignr_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Concatenate pairs of 16-byte blocks in a and b into a 32-byte temporary result, shift the result right by imm8 bytes, and store the low 16 bytes in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_alignr_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 32-bit elements, and store the low 16 bytes (4 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_alignr_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Concatenate a and b into a 32-byte immediate result, shift the result right by imm8 64-bit elements, and store the low 16 bytes (2 elements) in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_and_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_and_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_and_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_and_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise AND of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_andnot_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 32-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_andnot_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NOT of packed 64-bit integers in a and then AND with b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_andnot_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed double-precision (64-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_andnot_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise NOT of packed single-precision (32-bit) floating point numbers in a and then bitwise AND with b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_avg_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 8-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_avg_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Average packed unsigned 16-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_broadcast_i32x2⚠(x86 or x86-64) and avx512dq,avx512vl
    Broadcasts the lower 2 packed 32-bit integers from a to all elements of dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_broadcastb_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 8-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_broadcastd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 32-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_broadcastq_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low packed 64-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_broadcastss_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast the low single-precision (32-bit) floating-point element from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_broadcastw_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_compress_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 8-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_compress_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Contiguously store the active 16-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_compress_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 32-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_compress_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active 64-bit integers in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_compress_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active double-precision (64-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_compress_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Contiguously store the active single-precision (32-bit) floating-point elements in a (those with their respective bit set in zeromask k) to dst, and set the remaining elements to zero.
_mm_maskz_conflict_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 32-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm_maskz_conflict_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Test each 64-bit element of a for equality with all other elements in a closer to the least significant bit using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Each element’s comparison forms a zero extended bit vector in dst.
_mm_maskz_cvt_roundps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_cvt_roundsd_ss⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the rounding[3:0] parameter, which can be one of:\
_mm_maskz_cvt_roundss_sd⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_cvtepi8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Sign extend packed 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 8-bit integers in the low 2 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed 16-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 16-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 32-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Sign extend packed 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 8-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed 64-bit integers in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtepi64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed signed 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtepu8_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Zero extend packed unsigned 8-bit integers in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu8_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in th elow 4 bytes of a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu8_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 8-bit integers in the low 2 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu16_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu16_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 16-bit integers in the low 4 bytes of a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu32_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Zero extend packed unsigned 32-bit integers in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu32_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu64_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtepu64_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed unsigned 64-bit integers in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtne2ps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in two vectors a and b to packed BF16 (16-bit) floating-point elements, and store the results in single vector dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm_maskz_cvtneps_pbh⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed single-precision (32-bit) floating-point elements in a to packed BF16 (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtpbh_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Converts packed BF16 (16-bit) floating-point elements in a to single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtpd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtps_ph⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_cvtsd_ss⚠(x86 or x86-64) and avx512f
    Convert the lower double-precision (64-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_cvtsepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtsepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtsepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 32-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst.
_mm_maskz_cvtsepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 8-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtsepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 16-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtsepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed signed 64-bit integers in a to packed 32-bit integers with signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtss_sd⚠(x86 or x86-64) and avx512f
    Convert the lower single-precision (32-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_cvttpd_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttpd_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvttpd_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttpd_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvttps_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttps_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed signed 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvttps_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed double-precision (32-bit) floating-point elements in a to packed unsigned 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttps_epu64⚠(x86 or x86-64) and avx512dq,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed unsigned 64-bit integers with truncation, and store the result in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_cvtusepi16_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed unsigned 16-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtusepi32_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtusepi32_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 32-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtusepi64_epi8⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 8-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtusepi64_epi16⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 16-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtusepi64_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Convert packed unsigned 64-bit integers in a to packed unsigned 32-bit integers with unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_dbsad_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the sum of absolute differences (SADs) of quadruplets of unsigned 8-bit integers in a compared to those in b, and store the 16-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Four SADs are performed on four 8-bit quadruplets for each 64-bit lane. The first two SADs use the lower 8-bit quadruplet of the lane from a, and the last two SADs use the uppper 8-bit quadruplet of the lane from a. Quadruplets from b are selected from within 128-bit lanes according to the control in imm8, and each SAD in each 64-bit lane uses the selected quadruplet at 8-bit offsets.
_mm_maskz_div_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed double-precision (64-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_div_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Divide packed single-precision (32-bit) floating-point elements in a by packed elements in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_div_round_sd⚠(x86 or x86-64) and avx512f
    Divide the lower double-precision (64-bit) floating-point element in a by the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_div_round_ss⚠(x86 or x86-64) and avx512f
    Divide the lower single-precision (32-bit) floating-point element in a by the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_div_sd⚠(x86 or x86-64) and avx512f
    Divide the lower double-precision (64-bit) floating-point element in a by the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_div_ss⚠(x86 or x86-64) and avx512f
    Divide the lower single-precision (32-bit) floating-point element in a by the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_dpbf16_ps⚠(x86 or x86-64) and avx512bf16,avx512vl
    Compute dot-product of BF16 (16-bit) floating-point pairs in a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in src, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Intel’s documentation
_mm_maskz_dpbusd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_dpbusds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate signed 16-bit results. Sum these 4 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_dpwssd_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_dpwssds_epi32⚠(x86 or x86-64) and avx512vnni,avx512vl
    Multiply groups of 2 adjacent pairs of signed 16-bit integers in a with corresponding 16-bit integers in b, producing 2 intermediate signed 32-bit results. Sum these 2 results with the corresponding 32-bit integer in src using signed saturation, and store the packed 32-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expand_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from a (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_epi8⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 8-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Load contiguous active 16-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 32-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active 64-bit integers from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active double-precision (64-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_expandloadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load contiguous active single-precision (32-bit) floating-point elements from unaligned memory at mem_addr (those with their respective bit set in mask k), and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fixupimm_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed double-precision (64-bit) floating-point elements in a and b using packed 64-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm_maskz_fixupimm_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Fix up packed single-precision (32-bit) floating-point elements in a and b using packed 32-bit integers in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm8 is used to set the required flags reporting.
_mm_maskz_fixupimm_round_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_fixupimm_round_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_fixupimm_sd⚠(x86 or x86-64) and avx512f
    Fix up the lower double-precision (64-bit) floating-point elements in a and b using the lower 64-bit integer in c, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. imm8 is used to set the required flags reporting.
_mm_maskz_fixupimm_ss⚠(x86 or x86-64) and avx512f
    Fix up the lower single-precision (32-bit) floating-point elements in a and b using the lower 32-bit integer in c, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. imm8 is used to set the required flags reporting.
_mm_maskz_fmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_fmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_fmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_fmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_fmaddsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmaddsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_fmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_fmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_fmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_fmsubadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsubadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c from/to the intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmadd_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmadd_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, add the negated intermediate result to packed elements in c, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmadd_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_fnmadd_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_fnmadd_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_fnmadd_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and add the negated intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_fnmsub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmsub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmsub_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_fnmsub_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_fnmsub_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_fnmsub_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point elements in a and b, and subtract the lower element in c from the negated intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_getexp_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed double-precision (64-bit) floating-point element in a to a double-precision (64-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_maskz_getexp_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Convert the exponent of each packed single-precision (32-bit) floating-point element in a to a single-precision (32-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_maskz_getexp_round_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_getexp_round_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_getexp_sd⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower double-precision (64-bit) floating-point element in b to a double-precision (64-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_maskz_getexp_ss⚠(x86 or x86-64) and avx512f
    Convert the exponent of the lower single-precision (32-bit) floating-point element in b to a single-precision (32-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_maskz_getmant_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_maskz_getmant_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Normalize the mantissas of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
_mm_maskz_getmant_round_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_getmant_round_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_getmant_sd⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_getmant_ss⚠(x86 or x86-64) and avx512f
    Normalize the mantissas of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by interv and the sign depends on sc and the source sign.
    The mantissa is normalized to the interval specified by interv, which can take the following values:
    _MM_MANT_NORM_1_2 // interval [1, 2)
    _MM_MANT_NORM_p5_2 // interval [0.5, 2)
    _MM_MANT_NORM_p5_1 // interval [0.5, 1)
    _MM_MANT_NORM_p75_1p5 // interval [0.75, 1.5)
    The sign is determined by sc which can take the following values:
    _MM_MANT_SIGN_src // sign = sign(src)
    _MM_MANT_SIGN_zero // sign = 0
    _MM_MANT_SIGN_nan // dst = NaN if sign(src) = 1
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_gf2p8affine_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the packed bytes in x. That is computes a*x+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_maskz_gf2p8affineinv_epi64_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs an affine transformation on the inverted packed bytes in x. That is computes a*inv(x)+b over the Galois Field 2^8 for each packed byte with a being a 8x8 bit matrix and b being a constant 8-bit immediate value. The inverse of a byte is defined with respect to the reduction polynomial x^8+x^4+x^3+x+1. The inverse of 0 is 0. Each pack of 8 bytes in x is paired with the 64-bit word at the same position in a.
_mm_maskz_gf2p8mul_epi8⚠(x86 or x86-64) and gfni,avx512bw,avx512vl
    Performs a multiplication in GF(2^8) on the packed bytes. The field is in polynomial representation with the reduction polynomial x^8 + x^4 + x^3 + x + 1.
_mm_maskz_load_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_load_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_load_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_load_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_load_sd⚠(x86 or x86-64) and avx512f
    Load a double-precision (64-bit) floating-point element from memory into the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and set the upper element of dst to zero. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_load_ss⚠(x86 or x86-64) and avx512f
    Load a single-precision (32-bit) floating-point element from memory into the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and set the upper 3 packed elements of dst to zero. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_maskz_loadu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 8-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_loadu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Load packed 16-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_loadu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 32-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_loadu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed 64-bit integers from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_loadu_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed double-precision (64-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_loadu_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Load packed single-precision (32-bit) floating-point elements from memory into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). mem_addr does not need to be aligned on any particular boundary.
_mm_maskz_lzcnt_epi32⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 32-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_lzcnt_epi64⚠(x86 or x86-64) and avx512cd,avx512vl
    Counts the number of leading zero bits in each packed 64-bit integer in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_madd52hi_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the high 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_madd52lo_epu64⚠(x86 or x86-64) and avx512ifma,avx512vl
    Multiply packed unsigned 52-bit integers in each 64-bit element of b and c to form a 104-bit intermediate result. Add the low 52-bit unsigned integer from the intermediate result with the corresponding unsigned 64-bit integer in a, and store the results in dst using writemask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_madd_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Horizontally add adjacent pairs of intermediate 32-bit integers, and pack the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_maddubs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed unsigned 8-bit integers in a by packed signed 8-bit integers in b, producing intermediate signed 16-bit integers. Horizontally add adjacent pairs of intermediate signed 16-bit integers, and pack the saturated results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_max_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_max_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_max_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_max_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed signed 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 8-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Compare packed unsigned 16-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 32-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed double-precision (64-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed single-precision (32-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_min_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_min_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_min_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_min_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_mov_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 8-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mov_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Move packed 16-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mov_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 32-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mov_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed 64-bit integers from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mov_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed double-precision (64-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mov_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Move packed single-precision (32-bit) floating-point elements from a into dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_move_sd⚠(x86 or x86-64) and avx512f
    Move the lower double-precision (64-bit) floating-point element from b to the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_move_ss⚠(x86 or x86-64) and avx512f
    Move the lower single-precision (32-bit) floating-point element from b to the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_movedup_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed double-precision (64-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_movehdup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_moveldup_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low signed 32-bit integers from each packed 64-bit element in a and b, and store the signed 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_epu32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the low unsigned 32-bit integers from each packed 64-bit element in a and b, and store the unsigned 64-bit results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_mul_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_mul_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_mul_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_mulhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed signed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mulhi_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed unsigned 16-bit integers in a and b, producing intermediate 32-bit integers, and store the high 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mulhrs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply packed signed 16-bit integers in a and b, producing intermediate signed 32-bit integers. Truncate each intermediate integer to the 18 most significant bits, round by adding 1, and store bits [16:1] to dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mullo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Multiply the packed 16-bit integers in a and b, producing intermediate 32-bit integers, and store the low 16 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mullo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Multiply the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and store the low 32 bits of the intermediate integers in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_or_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_or_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise OR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_packs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_packs_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using signed saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_packus_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_packus_epi32⚠(x86 or x86-64) and avx512bw,avx512vl
    Convert packed signed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permute_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permute_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutevar_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutevar_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a within 128-bit lanes using the control in b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm_maskz_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm_maskz_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm_maskz_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm_maskz_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_maskz_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_maskz_range_round_sd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_range_round_ss⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_maskz_range_sd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_maskz_range_ss⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_maskz_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rcp14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rcp14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out if the corresponding mask bit is not set). Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_reduce_round_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_reduce_round_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_reduce_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_reduce_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_maskz_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_roundscale_round_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_roundscale_round_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_roundscale_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_roundscale_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_maskz_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rsqrt14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_rsqrt14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_maskz_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_scalef_round_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_scalef_round_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_scalef_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_scalef_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_set1_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast 8-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_set1_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Broadcast the low packed 16-bit integer from a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_set1_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 32-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_set1_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Broadcast 64-bit integer a to all elements of dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shuffle_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle packed 8-bit integers in a according to shuffle control mask in the corresponding 8-bit element of b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shuffle_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shuffle_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements within 128-bit lanes using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shuffle_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a using the control in imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shufflehi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the high 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the high 64 bits of 128-bit lanes of dst, with the low 64 bits of 128-bit lanes being copied from a to dst, using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_shufflelo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in the low 64 bits of 128-bit lanes of a using the control in imm8. Store the results in the low 64 bits of 128-bit lanes of dst, with the high 64 bits of 128-bit lanes being copied from a to dst, using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_maskz_sll_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sll_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sll_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_slli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_slli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_slli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sllv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sllv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sqrt_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sqrt_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sqrt_round_sd⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_sqrt_round_ss⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_sqrt_sd⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_sqrt_ss⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_sra_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sra_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srai_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srai_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srav_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srl_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srl_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srl_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srli_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srli_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srli_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srlv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_srlv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 8-bit integers in b from packed 8-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed 16-bit integers in b from packed 16-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 32-bit integers in b from packed 32-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed 64-bit integers in b from packed 64-bit integers in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed double-precision (64-bit) floating-point elements in b from packed double-precision (64-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Subtract packed single-precision (32-bit) floating-point elements in b from packed single-precision (32-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_round_sd⚠(x86 or x86-64) and avx512f
    Subtract the lower double-precision (64-bit) floating-point element in b from the lower double-precision (64-bit) floating-point element in a, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.\
_mm_maskz_sub_round_ss⚠(x86 or x86-64) and avx512f
    Subtract the lower single-precision (32-bit) floating-point element in b from the lower single-precision (32-bit) floating-point element in a, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_maskz_sub_sd⚠(x86 or x86-64) and avx512f
    Subtract the lower double-precision (64-bit) floating-point element in b from the lower double-precision (64-bit) floating-point element in a, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_sub_ss⚠(x86 or x86-64) and avx512f
    Subtract the lower single-precision (32-bit) floating-point element in b from the lower single-precision (32-bit) floating-point element in a, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_subs_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 8-bit integers in b from packed 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_subs_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed signed 16-bit integers in b from packed 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_subs_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_subs_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 32-bit granularity (32-bit elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst using zeromask k at 64-bit granularity (64-bit elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpackhi_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the high half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 8-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Unpack and interleave 16-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 32-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave 64-bit integers from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave double-precision (64-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_unpacklo_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Unpack and interleave single-precision (32-bit) floating-point elements from the low half of each 128-bit lane in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_xor_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed double-precision (64-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_maskz_xor_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Compute the bitwise XOR of packed single-precision (32-bit) floating point numbers in a and b and store the results in dst using zeromask k (elements are zeroed out if the corresponding bit is not set).
_mm_max_epi8⚠(x86 or x86-64) and sse4.1
    Compares packed 8-bit integers in a and b and returns packed maximum values in dst.
_mm_max_epi16⚠(x86 or x86-64) and sse2
    Compares packed 16-bit integers in a and b, and returns the packed maximum values.
_mm_max_epi32⚠(x86 or x86-64) and sse4.1
    Compares packed 32-bit integers in a and b, and returns packed maximum values.
_mm_max_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed maximum values in dst.
_mm_max_epu8⚠(x86 or x86-64) and sse2
    Compares packed unsigned 8-bit integers in a and b, and returns the packed maximum values.
_mm_max_epu16⚠(x86 or x86-64) and sse4.1
    Compares packed unsigned 16-bit integers in a and b, and returns packed maximum.
_mm_max_epu32⚠(x86 or x86-64) and sse4.1
    Compares packed unsigned 32-bit integers in a and b, and returns packed maximum values.
_mm_max_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed maximum values in dst.
_mm_max_pd⚠(x86 or x86-64) and sse2
    Returns a new vector with the maximum values from corresponding elements in a and b.
_mm_max_ps⚠(x86 or x86-64) and sse
    Compares packed single-precision (32-bit) floating-point elements in a and b, and return the corresponding maximum values.
_mm_max_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the maximum value in the lower element of dst, and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_max_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the maximum value in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_max_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the maximum of the lower elements of a and b.
_mm_max_ss⚠(x86 or x86-64) and sse
    Compares the first single-precision (32-bit) floating-point element of a and b, and return the maximum value in the first element of the return value, the other elements are copied from a.
_mm_mfence⚠(x86 or x86-64) and sse2
    Performs a serializing operation on all load-from-memory and store-to-memory instructions that were issued prior to this instruction.
_mm_min_epi8⚠(x86 or x86-64) and sse4.1
    Compares packed 8-bit integers in a and b and returns packed minimum values in dst.
_mm_min_epi16⚠(x86 or x86-64) and sse2
    Compares packed 16-bit integers in a and b, and returns the packed minimum values.
_mm_min_epi32⚠(x86 or x86-64) and sse4.1
    Compares packed 32-bit integers in a and b, and returns packed minimum values.
_mm_min_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed signed 64-bit integers in a and b, and store packed minimum values in dst.
_mm_min_epu8⚠(x86 or x86-64) and sse2
    Compares packed unsigned 8-bit integers in a and b, and returns the packed minimum values.
_mm_min_epu16⚠(x86 or x86-64) and sse4.1
    Compares packed unsigned 16-bit integers in a and b, and returns packed minimum.
_mm_min_epu32⚠(x86 or x86-64) and sse4.1
    Compares packed unsigned 32-bit integers in a and b, and returns packed minimum values.
_mm_min_epu64⚠(x86 or x86-64) and avx512f,avx512vl
    Compare packed unsigned 64-bit integers in a and b, and store packed minimum values in dst.
_mm_min_pd⚠(x86 or x86-64) and sse2
    Returns a new vector with the minimum values from corresponding elements in a and b.
_mm_min_ps⚠(x86 or x86-64) and sse
    Compares packed single-precision (32-bit) floating-point elements in a and b, and return the corresponding minimum values.
_mm_min_round_sd⚠(x86 or x86-64) and avx512f
    Compare the lower double-precision (64-bit) floating-point elements in a and b, store the minimum value in the lower element of dst , and copy the upper element from a to the upper element of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_min_round_ss⚠(x86 or x86-64) and avx512f
    Compare the lower single-precision (32-bit) floating-point elements in a and b, store the minimum value in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_min_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the minimum of the lower elements of a and b.
_mm_min_ss⚠(x86 or x86-64) and sse
    Compares the first single-precision (32-bit) floating-point element of a and b, and return the minimum value in the first element of the return value, the other elements are copied from a.
_mm_minpos_epu16⚠(x86 or x86-64) and sse4.1
    Finds the minimum unsigned 16-bit element in the 128-bit __m128i vector, returning a vector containing its value in its first position, and its index in its second position; all other elements are set to zero.
_mm_mmask_i32gather_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 32-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i32gather_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 64-bit integer elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i32gather_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i32gather_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 4 single-precision (32-bit) floating-point elements from memory starting at location base_addr at packed 32-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i64gather_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 32-bit integer elements from memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i64gather_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 64-bit integer elements from memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i64gather_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 double-precision (64-bit) floating-point elements from memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mmask_i64gather_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Loads 2 single-precision (32-bit) floating-point elements from memory starting at location base_addr at packed 64-bit integer indices stored in vindex scaled by scale using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_move_epi64⚠(x86 or x86-64) and sse2
    Returns a vector where the low element is extracted from a and its upper element is zero.
_mm_move_sd⚠(x86 or x86-64) and sse2
    Constructs a 128-bit floating-point vector of [2 x double]. The lower 64 bits are set to the lower 64 bits of the second parameter. The upper 64 bits are set to the upper 64 bits of the first parameter.
_mm_move_ss⚠(x86 or x86-64) and sse
    Returns a __m128 with the first component from b and the remaining components from a.
_mm_movedup_pd⚠(x86 or x86-64) and sse3
    Duplicate the low double-precision (64-bit) floating-point element from a.
_mm_movehdup_ps⚠(x86 or x86-64) and sse3
    Duplicate odd-indexed single-precision (32-bit) floating-point elements from a.
_mm_movehl_ps⚠(x86 or x86-64) and sse
    Combine higher half of a and b. The higher half of b occupies the lower half of result.
_mm_moveldup_ps⚠(x86 or x86-64) and sse3
    Duplicate even-indexed single-precision (32-bit) floating-point elements from a.
_mm_movelh_ps⚠(x86 or x86-64) and sse
    Combine lower half of a and b. The lower half of b occupies the higher half of result.
_mm_movemask_epi8⚠(x86 or x86-64) and sse2
    Returns a mask of the most significant bit of each element in a.
_mm_movemask_pd⚠(x86 or x86-64) and sse2
    Returns a mask of the most significant bit of each element in a.
_mm_movemask_ps⚠(x86 or x86-64) and sse
    Returns a mask of the most significant bit of each element in a.
_mm_movepi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 8-bit integer in a.
_mm_movepi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 16-bit integer in a.
_mm_movepi32_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 32-bit integer in a.
_mm_movepi64_mask⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each bit of mask register k based on the most significant bit of the corresponding packed 64-bit integer in a.
_mm_movm_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each packed 8-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm_movm_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Set each packed 16-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm_movm_epi32⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each packed 32-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm_movm_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Set each packed 64-bit integer in dst to all ones or all zeros based on the value of the corresponding bit in k.
_mm_mpsadbw_epu8⚠(x86 or x86-64) and sse4.1
    Subtracts 8-bit unsigned integer values and computes the absolute values of the differences to the corresponding bits in the destination. Then sums of the absolute differences are returned according to the bit fields in the immediate operand.
_mm_mul_epi32⚠(x86 or x86-64) and sse4.1
    Multiplies the low 32-bit integers from each packed 64-bit element in a and b, and returns the signed 64-bit result.
_mm_mul_epu32⚠(x86 or x86-64) and sse2
    Multiplies the low unsigned 32-bit integers from each packed 64-bit element in a and b.
_mm_mul_pd⚠(x86 or x86-64) and sse2
    Multiplies packed double-precision (64-bit) floating-point elements in a and b.
_mm_mul_ps⚠(x86 or x86-64) and sse
    Multiplies packed single-precision (32-bit) floating-point elements in a and b.
_mm_mul_round_sd⚠(x86 or x86-64) and avx512f
    Multiply the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_mul_round_ss⚠(x86 or x86-64) and avx512f
    Multiply the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_mul_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by multiplying the low elements of a and b.
_mm_mul_ss⚠(x86 or x86-64) and sse
    Multiplies the first component of a and b, the other components are copied from a.
_mm_mulhi_epi16⚠(x86 or x86-64) and sse2
    Multiplies the packed 16-bit integers in a and b.
_mm_mulhi_epu16⚠(x86 or x86-64) and sse2
    Multiplies the packed unsigned 16-bit integers in a and b.
_mm_mulhrs_epi16⚠(x86 or x86-64) and ssse3
    Multiplies packed 16-bit signed integer values, truncate the 32-bit product to the 18 most significant bits by right-shifting, round the truncated value by adding 1, and write bits [16:1] to the destination.
_mm_mullo_epi16⚠(x86 or x86-64) and sse2
    Multiplies the packed 16-bit integers in a and b.
_mm_mullo_epi32⚠(x86 or x86-64) and sse4.1
    Multiplies the packed 32-bit integers in a and b, producing intermediate 64-bit integers, and returns the lowest 32-bit, whatever they might be, reinterpreted as a signed integer. While pmulld __m128i::splat(2), __m128i::splat(2) returns the obvious __m128i::splat(4), due to wrapping arithmetic pmulld __m128i::splat(i32::MAX), __m128i::splat(2) would return a negative number.
_mm_mullo_epi64⚠(x86 or x86-64) and avx512dq,avx512vl
    Multiply packed 64-bit integers in a and b, producing intermediate 128-bit integers, and store the low 64 bits of the intermediate integers in dst.
_mm_multishift_epi64_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    For each 64-bit element in b, select 8 unaligned bytes using a byte-granular shift control within the corresponding 64-bit element of a, and store the 8 assembled bytes to the corresponding 64-bit element of dst.
_mm_or_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 32-bit integers in a and b, and store the results in dst.
_mm_or_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise OR of packed 64-bit integers in a and b, and store the resut in dst.
_mm_or_pd⚠(x86 or x86-64) and sse2
    Computes the bitwise OR of a and b.
_mm_or_ps⚠(x86 or x86-64) and sse
    Bitwise OR of packed single-precision (32-bit) floating-point elements.
_mm_or_si128⚠(x86 or x86-64) and sse2
    Computes the bitwise OR of 128 bits (representing integer data) in a and b.
_mm_packs_epi16⚠(x86 or x86-64) and sse2
    Converts packed 16-bit integers from a and b to packed 8-bit integers using signed saturation.
_mm_packs_epi32⚠(x86 or x86-64) and sse2
    Converts packed 32-bit integers from a and b to packed 16-bit integers using signed saturation.
_mm_packus_epi16⚠(x86 or x86-64) and sse2
    Converts packed 16-bit integers from a and b to packed 8-bit integers using unsigned saturation.
_mm_packus_epi32⚠(x86 or x86-64) and sse4.1
    Converts packed 32-bit integers from a and b to packed 16-bit integers using unsigned saturation
_mm_pause⚠x86 or x86-64
    Provides a hint to the processor that the code sequence is a spin-wait loop.
_mm_permute_pd⚠(x86 or x86-64) and avx
    Shuffles double-precision (64-bit) floating-point elements in a using the control in imm8.
_mm_permute_ps⚠(x86 or x86-64) and avx
    Shuffles single-precision (32-bit) floating-point elements in a using the control in imm8.
_mm_permutevar_pd⚠(x86 or x86-64) and avx
    Shuffles double-precision (64-bit) floating-point elements in a using the control in b.
_mm_permutevar_ps⚠(x86 or x86-64) and avx
    Shuffles single-precision (32-bit) floating-point elements in a using the control in b.
_mm_permutex2var_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutex2var_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutex2var_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 32-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutex2var_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle 64-bit integers in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutex2var_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle double-precision (64-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutex2var_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Shuffle single-precision (32-bit) floating-point elements in a and b across lanes using the corresponding selector and index in idx, and store the results in dst.
_mm_permutexvar_epi8⚠(x86 or x86-64) and avx512vbmi,avx512vl
    Shuffle 8-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm_permutexvar_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shuffle 16-bit integers in a across lanes using the corresponding index in idx, and store the results in dst.
_mm_popcnt_epi8⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 8-bit integer maps the value to the number of logical 1 bits.
_mm_popcnt_epi16⚠(x86 or x86-64) and avx512bitalg,avx512vl
    For each packed 16-bit integer maps the value to the number of logical 1 bits.
_mm_popcnt_epi32⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 32-bit integer maps the value to the number of logical 1 bits.
_mm_popcnt_epi64⚠(x86 or x86-64) and avx512vpopcntdq,avx512vl
    For each packed 64-bit integer maps the value to the number of logical 1 bits.
_mm_prefetch⚠(x86 or x86-64) and sse
    Fetch the cache line that contains address p using the given STRATEGY.
_mm_range_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed double-precision (64-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_range_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for packed single-precision (32-bit) floating-point elements in a and b, and store the results in dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit.
_mm_range_round_sd⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower double-precision (64-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_range_round_ss⚠(x86 or x86-64) and avx512dq
    Calculate the max, min, absolute max, or absolute min (depending on control in imm8) for the lower single-precision (32-bit) floating-point element in a and b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. Lower 2 bits of IMM8 specifies the operation control: 00 = min, 01 = max, 10 = absolute min, 11 = absolute max. Upper 2 bits of IMM8 specifies the sign control: 00 = sign from a, 01 = sign from compare result, 10 = clear sign bit, 11 = set sign bit. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_rcp14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rcp14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rcp14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rcp14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rcp_ps⚠(x86 or x86-64) and sse
    Returns the approximate reciprocal of packed single-precision (32-bit) floating-point elements in a.
_mm_rcp_ss⚠(x86 or x86-64) and sse
    Returns the approximate reciprocal of the first single-precision (32-bit) floating-point element in a, the other elements are unchanged.
_mm_reduce_add_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by addition. Returns the sum of all elements in a.
_mm_reduce_add_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by addition. Returns the sum of all elements in a.
_mm_reduce_and_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm_reduce_and_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise AND. Returns the bitwise AND of all elements in a.
_mm_reduce_max_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm_reduce_max_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm_reduce_max_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm_reduce_max_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by maximum. Returns the maximum of all elements in a.
_mm_reduce_min_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm_reduce_min_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm_reduce_min_epu8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 8-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm_reduce_min_epu16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed unsigned 16-bit integers in a by minimum. Returns the minimum of all elements in a.
_mm_reduce_mul_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by multiplication. Returns the product of all elements in a.
_mm_reduce_mul_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by multiplication. Returns the product of all elements in a.
_mm_reduce_or_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 8-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm_reduce_or_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Reduce the packed 16-bit integers in a by bitwise OR. Returns the bitwise OR of all elements in a.
_mm_reduce_pd⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed double-precision (64-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_reduce_ps⚠(x86 or x86-64) and avx512dq,avx512vl
    Extract the reduced argument of packed single-precision (32-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_reduce_round_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_reduce_round_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst, and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_reduce_sd⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower double-precision (64-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using, and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_reduce_ss⚠(x86 or x86-64) and avx512dq
    Extract the reduced argument of the lower single-precision (32-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst, and copy the upper element from a. to the upper element of dst. Rounding is done according to the imm8 parameter, which can be one of:
_mm_rol_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm_rol_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in imm8, and store the results in dst.
_mm_rolv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm_rolv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the left by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm_ror_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm_ror_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in imm8, and store the results in dst.
_mm_rorv_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 32-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm_rorv_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Rotate the bits in each packed 64-bit integer in a to the right by the number of bits specified in the corresponding element of b, and store the results in dst.
_mm_round_pd⚠(x86 or x86-64) and sse4.1
    Round the packed double-precision (64-bit) floating-point elements in a using the ROUNDING parameter, and stores the results as packed double-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:
_mm_round_ps⚠(x86 or x86-64) and sse4.1
    Round the packed single-precision (32-bit) floating-point elements in a using the ROUNDING parameter, and stores the results as packed single-precision floating-point elements. Rounding is done according to the rounding parameter, which can be one of:
_mm_round_sd⚠(x86 or x86-64) and sse4.1
    Round the lower double-precision (64-bit) floating-point element in b using the ROUNDING parameter, store the result as a double-precision floating-point element in the lower element of the intrinsic result, and copies the upper element from a to the upper element of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:
_mm_round_ss⚠(x86 or x86-64) and sse4.1
    Round the lower single-precision (32-bit) floating-point element in b using the ROUNDING parameter, store the result as a single-precision floating-point element in the lower element of the intrinsic result, and copies the upper 3 packed elements from a to the upper elements of the intrinsic result. Rounding is done according to the rounding parameter, which can be one of:
_mm_roundscale_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed double-precision (64-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_roundscale_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Round packed single-precision (32-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_roundscale_round_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_roundscale_round_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_roundscale_sd⚠(x86 or x86-64) and avx512f
    Round the lower double-precision (64-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_roundscale_ss⚠(x86 or x86-64) and avx512f
    Round the lower single-precision (32-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
    Rounding is done according to the imm8[2:0] parameter, which can be one of:\
_mm_rsqrt14_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed double-precision (64-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rsqrt14_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rsqrt14_sd⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rsqrt14_ss⚠(x86 or x86-64) and avx512f
    Compute the approximate reciprocal square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 2^-14.
_mm_rsqrt_ps⚠(x86 or x86-64) and sse
    Returns the approximate reciprocal square root of packed single-precision (32-bit) floating-point elements in a.
_mm_rsqrt_ss⚠(x86 or x86-64) and sse
    Returns the approximate reciprocal square root of the first single-precision (32-bit) floating-point element in a, the other elements are unchanged.
_mm_sad_epu8⚠(x86 or x86-64) and sse2
    Sum the absolute differences of packed unsigned 8-bit integers.
_mm_scalef_pd⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, and store the results in dst.
_mm_scalef_ps⚠(x86 or x86-64) and avx512f,avx512vl
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, and store the results in dst.
_mm_scalef_round_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_scalef_round_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_scalef_sd⚠(x86 or x86-64) and avx512f
    Scale the packed double-precision (64-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_scalef_ss⚠(x86 or x86-64) and avx512f
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_set1_epi8⚠(x86 or x86-64) and sse2
    Broadcasts 8-bit integer a to all elements.
_mm_set1_epi16⚠(x86 or x86-64) and sse2
    Broadcasts 16-bit integer a to all elements.
_mm_set1_epi32⚠(x86 or x86-64) and sse2
    Broadcasts 32-bit integer a to all elements.
_mm_set1_epi64x⚠(x86 or x86-64) and sse2
    Broadcasts 64-bit integer a to all elements.
_mm_set1_pd⚠(x86 or x86-64) and sse2
    Broadcasts double-precision (64-bit) floating-point value a to all elements of the return value.
_mm_set1_ps⚠(x86 or x86-64) and sse
    Construct a __m128 with all element set to a.
_mm_set_epi8⚠(x86 or x86-64) and sse2
    Sets packed 8-bit integers with the supplied values.
_mm_set_epi16⚠(x86 or x86-64) and sse2
    Sets packed 16-bit integers with the supplied values.
_mm_set_epi32⚠(x86 or x86-64) and sse2
    Sets packed 32-bit integers with the supplied values.
_mm_set_epi64x⚠(x86 or x86-64) and sse2
    Sets packed 64-bit integers with the supplied values, from highest to lowest.
_mm_set_pd⚠(x86 or x86-64) and sse2
    Sets packed double-precision (64-bit) floating-point elements in the return value with the supplied values.
_mm_set_pd1⚠(x86 or x86-64) and sse2
    Broadcasts double-precision (64-bit) floating-point value a to all elements of the return value.
_mm_set_ps⚠(x86 or x86-64) and sse
    Construct a __m128 from four floating point values highest to lowest.
_mm_set_ps1⚠(x86 or x86-64) and sse
    Alias for _mm_set1_ps
_mm_set_sd⚠(x86 or x86-64) and sse2
    Copies double-precision (64-bit) floating-point element a to the lower element of the packed 64-bit return value.
_mm_set_ss⚠(x86 or x86-64) and sse
    Construct a __m128 with the lowest element set to a and the rest set to zero.
_mm_setcsr⚠Deprecated(x86 or x86-64) and sse
    Sets the MXCSR register with the 32-bit unsigned integer value.
_mm_setr_epi8⚠(x86 or x86-64) and sse2
    Sets packed 8-bit integers with the supplied values in reverse order.
_mm_setr_epi16⚠(x86 or x86-64) and sse2
    Sets packed 16-bit integers with the supplied values in reverse order.
_mm_setr_epi32⚠(x86 or x86-64) and sse2
    Sets packed 32-bit integers with the supplied values in reverse order.
_mm_setr_pd⚠(x86 or x86-64) and sse2
    Sets packed double-precision (64-bit) floating-point elements in the return value with the supplied values in reverse order.
_mm_setr_ps⚠(x86 or x86-64) and sse
    Construct a __m128 from four floating point values lowest to highest.
_mm_setzero_pd⚠(x86 or x86-64) and sse2
    Returns packed double-precision (64-bit) floating-point elements with all zeros.
_mm_setzero_ps⚠(x86 or x86-64) and sse
    Construct a __m128 with all elements initialized to zero.
_mm_setzero_si128⚠(x86 or x86-64) and sse2
    Returns a vector with all elements set to zero.
_mm_sfence⚠(x86 or x86-64) and sse
    Performs a serializing operation on all non-temporal (“streaming”) store instructions that were issued by the current thread prior to this instruction.
_mm_sha1msg1_epu32⚠(x86 or x86-64) and sha
    Performs an intermediate calculation for the next four SHA1 message values (unsigned 32-bit integers) using previous message values from a and b, and returning the result.
_mm_sha1msg2_epu32⚠(x86 or x86-64) and sha
    Performs the final calculation for the next four SHA1 message values (unsigned 32-bit integers) using the intermediate result in a and the previous message values in b, and returns the result.
_mm_sha1nexte_epu32⚠(x86 or x86-64) and sha
    Calculate SHA1 state variable E after four rounds of operation from the current SHA1 state variable a, add that value to the scheduled values (unsigned 32-bit integers) in b, and returns the result.
_mm_sha1rnds4_epu32⚠(x86 or x86-64) and sha
    Performs four rounds of SHA1 operation using an initial SHA1 state (A,B,C,D) from a and some pre-computed sum of the next 4 round message values (unsigned 32-bit integers), and state variable E from b, and return the updated SHA1 state (A,B,C,D). FUNC contains the logic functions and round constants.
_mm_sha256msg1_epu32⚠(x86 or x86-64) and sha
    Performs an intermediate calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from a and b, and return the result.
_mm_sha256msg2_epu32⚠(x86 or x86-64) and sha
    Performs the final calculation for the next four SHA256 message values (unsigned 32-bit integers) using previous message values from a and b, and return the result.
_mm_sha256rnds2_epu32⚠(x86 or x86-64) and sha
    Performs 2 rounds of SHA256 operation using an initial SHA256 state (C,D,G,H) from a, an initial SHA256 state (A,B,E,F) from b, and a pre-computed sum of the next 2 round message values (unsigned 32-bit integers) and the corresponding round constants from k, and store the updated SHA256 state (A,B,E,F) in dst.
_mm_shldi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by imm8 bits, and store the upper 16-bits in dst).
_mm_shldi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by imm8 bits, and store the upper 32-bits in dst.
_mm_shldi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by imm8 bits, and store the upper 64-bits in dst).
_mm_shldv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in a and b producing an intermediate 32-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 16-bits in dst.
_mm_shldv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in a and b producing an intermediate 64-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 32-bits in dst.
_mm_shldv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in a and b producing an intermediate 128-bit result. Shift the result left by the amount specified in the corresponding element of c, and store the upper 64-bits in dst.
_mm_shrdi_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by imm8 bits, and store the lower 16-bits in dst.
_mm_shrdi_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by imm8 bits, and store the lower 32-bits in dst.
_mm_shrdi_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by imm8 bits, and store the lower 64-bits in dst.
_mm_shrdv_epi16⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 16-bit integers in b and a producing an intermediate 32-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 16-bits in dst.
_mm_shrdv_epi32⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 32-bit integers in b and a producing an intermediate 64-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 32-bits in dst.
_mm_shrdv_epi64⚠(x86 or x86-64) and avx512vbmi2,avx512vl
    Concatenate packed 64-bit integers in b and a producing an intermediate 128-bit result. Shift the result right by the amount specified in the corresponding element of c, and store the lower 64-bits in dst.
_mm_shuffle_epi8⚠(x86 or x86-64) and ssse3
    Shuffles bytes from a according to the content of b.
_mm_shuffle_epi32⚠(x86 or x86-64) and sse2
    Shuffles 32-bit integers in a using the control in IMM8.
_mm_shuffle_pd⚠(x86 or x86-64) and sse2
    Constructs a 128-bit floating-point vector of [2 x double] from two 128-bit vector parameters of [2 x double], using the immediate-value parameter as a specifier.
_mm_shuffle_ps⚠(x86 or x86-64) and sse
    Shuffles packed single-precision (32-bit) floating-point elements in a and b using MASK.
_mm_shufflehi_epi16⚠(x86 or x86-64) and sse2
    Shuffles 16-bit integers in the high 64 bits of a using the control in IMM8.
_mm_shufflelo_epi16⚠(x86 or x86-64) and sse2
    Shuffles 16-bit integers in the low 64 bits of a using the control in IMM8.
_mm_sign_epi8⚠(x86 or x86-64) and ssse3
    Negates packed 8-bit integers in a when the corresponding signed 8-bit integer in b is negative, and returns the result. Elements in result are zeroed out when the corresponding element in b is zero.
_mm_sign_epi16⚠(x86 or x86-64) and ssse3
    Negates packed 16-bit integers in a when the corresponding signed 16-bit integer in b is negative, and returns the results. Elements in result are zeroed out when the corresponding element in b is zero.
_mm_sign_epi32⚠(x86 or x86-64) and ssse3
    Negates packed 32-bit integers in a when the corresponding signed 32-bit integer in b is negative, and returns the results. Element in result are zeroed out when the corresponding element in b is zero.
_mm_sll_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a left by count while shifting in zeros.
_mm_sll_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a left by count while shifting in zeros.
_mm_sll_epi64⚠(x86 or x86-64) and sse2
    Shifts packed 64-bit integers in a left by count while shifting in zeros.
_mm_slli_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a left by IMM8 while shifting in zeros.
_mm_slli_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a left by IMM8 while shifting in zeros.
_mm_slli_epi64⚠(x86 or x86-64) and sse2
    Shifts packed 64-bit integers in a left by IMM8 while shifting in zeros.
_mm_slli_si128⚠(x86 or x86-64) and sse2
    Shifts a left by IMM8 bytes while shifting in zeros.
_mm_sllv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm_sllv_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and returns the result.
_mm_sllv_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a left by the amount specified by the corresponding element in count while shifting in zeros, and returns the result.
_mm_sm3msg1_epi32⚠(x86 or x86-64) and sm3,avx
    This is one of the two SM3 message scheduling intrinsics. The intrinsic performs an initial calculation for the next four SM3 message words. The calculated results are stored in dst.
_mm_sm3msg2_epi32⚠(x86 or x86-64) and sm3,avx
    This is one of the two SM3 message scheduling intrinsics. The intrinsic performs the final calculation for the next four SM3 message words. The calculated results are stored in dst.
_mm_sm3rnds2_epi32⚠(x86 or x86-64) and sm3,avx
    The intrinsic performs two rounds of SM3 operation using initial SM3 state (C, D, G, H) from a, an initial SM3 states (A, B, E, F) from b and a pre-computed words from the c. a with initial SM3 state of (C, D, G, H) assumes input of non-rotated left variables from previous state. The updated SM3 state (A, B, E, F) is written to a. The imm8 should contain the even round number for the first of the two rounds computed by this instruction. The computation masks the imm8 value by ANDing it with 0x3E so that only even round numbers from 0 through 62 are used for this operation. The calculated results are stored in dst.
_mm_sm4key4_epi32⚠(x86 or x86-64) and sm4,avx
    This intrinsic performs four rounds of SM4 key expansion. The intrinsic operates on independent 128-bit lanes. The calculated results are stored in dst.
_mm_sm4rnds4_epi32⚠(x86 or x86-64) and sm4,avx
    This intrinsic performs four rounds of SM4 encryption. The intrinsic operates on independent 128-bit lanes. The calculated results are stored in dst.
_mm_sqrt_pd⚠(x86 or x86-64) and sse2
    Returns a new vector with the square root of each of the values in a.
_mm_sqrt_ps⚠(x86 or x86-64) and sse
    Returns the square root of packed single-precision (32-bit) floating-point elements in a.
_mm_sqrt_round_sd⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower double-precision (64-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_sqrt_round_ss⚠(x86 or x86-64) and avx512f
    Compute the square root of the lower single-precision (32-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_sqrt_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by the square root of the lower element b.
_mm_sqrt_ss⚠(x86 or x86-64) and sse
    Returns the square root of the first single-precision (32-bit) floating-point element in a, the other elements are unchanged.
_mm_sra_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a right by count while shifting in sign bits.
_mm_sra_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a right by count while shifting in sign bits.
_mm_sra_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by count while shifting in sign bits, and store the results in dst.
_mm_srai_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a right by IMM8 while shifting in sign bits.
_mm_srai_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a right by IMM8 while shifting in sign bits.
_mm_srai_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by imm8 while shifting in sign bits, and store the results in dst.
_mm_srav_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm_srav_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits.
_mm_srav_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Shift packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in sign bits, and store the results in dst.
_mm_srl_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a right by count while shifting in zeros.
_mm_srl_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a right by count while shifting in zeros.
_mm_srl_epi64⚠(x86 or x86-64) and sse2
    Shifts packed 64-bit integers in a right by count while shifting in zeros.
_mm_srli_epi16⚠(x86 or x86-64) and sse2
    Shifts packed 16-bit integers in a right by IMM8 while shifting in zeros.
_mm_srli_epi32⚠(x86 or x86-64) and sse2
    Shifts packed 32-bit integers in a right by IMM8 while shifting in zeros.
_mm_srli_epi64⚠(x86 or x86-64) and sse2
    Shifts packed 64-bit integers in a right by IMM8 while shifting in zeros.
_mm_srli_si128⚠(x86 or x86-64) and sse2
    Shifts a right by IMM8 bytes while shifting in zeros.
_mm_srlv_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Shift packed 16-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros, and store the results in dst.
_mm_srlv_epi32⚠(x86 or x86-64) and avx2
    Shifts packed 32-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros,
_mm_srlv_epi64⚠(x86 or x86-64) and avx2
    Shifts packed 64-bit integers in a right by the amount specified by the corresponding element in count while shifting in zeros,
_mm_store1_pd⚠(x86 or x86-64) and sse2
    Stores the lower double-precision (64-bit) floating-point element from a into 2 contiguous elements in memory. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_store1_ps⚠(x86 or x86-64) and sse
    Stores the lowest 32 bit float of a repeated four times into aligned memory.
_mm_store_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store 128-bits (composed of 4 packed 32-bit integers) from a into memory. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_store_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store 128-bits (composed of 2 packed 64-bit integers) from a into memory. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_store_pd⚠(x86 or x86-64) and sse2
    Stores 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_store_pd1⚠(x86 or x86-64) and sse2
    Stores the lower double-precision (64-bit) floating-point element from a into 2 contiguous elements in memory. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_store_ps⚠(x86 or x86-64) and sse
    Stores four 32-bit floats into aligned memory.
_mm_store_ps1⚠(x86 or x86-64) and sse
    Alias for _mm_store1_ps
_mm_store_sd⚠(x86 or x86-64) and sse2
    Stores the lower 64 bits of a 128-bit vector of [2 x double] to a memory location.
_mm_store_si128⚠(x86 or x86-64) and sse2
    Stores 128-bits of integer data from a into memory.
_mm_store_ss⚠(x86 or x86-64) and sse
    Stores the lowest 32 bit float of a into memory.
_mm_storeh_pd⚠(x86 or x86-64) and sse2
    Stores the upper 64 bits of a 128-bit vector of [2 x double] to a memory location.
_mm_storel_epi64⚠(x86 or x86-64) and sse2
    Stores the lower 64-bit integer a to a memory location.
_mm_storel_pd⚠(x86 or x86-64) and sse2
    Stores the lower 64 bits of a 128-bit vector of [2 x double] to a memory location.
_mm_storer_pd⚠(x86 or x86-64) and sse2
    Stores 2 double-precision (64-bit) floating-point elements from a into memory in reverse order. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated.
_mm_storer_ps⚠(x86 or x86-64) and sse
    Stores four 32-bit floats into aligned memory in reverse order.
_mm_storeu_epi8⚠(x86 or x86-64) and avx512bw,avx512vl
    Store 128-bits (composed of 16 packed 8-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm_storeu_epi16⚠(x86 or x86-64) and avx512bw,avx512vl
    Store 128-bits (composed of 8 packed 16-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm_storeu_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Store 128-bits (composed of 4 packed 32-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm_storeu_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Store 128-bits (composed of 2 packed 64-bit integers) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm_storeu_pd⚠(x86 or x86-64) and sse2
    Stores 128-bits (composed of 2 packed double-precision (64-bit) floating-point elements) from a into memory. mem_addr does not need to be aligned on any particular boundary.
_mm_storeu_ps⚠(x86 or x86-64) and sse
    Stores four 32-bit floats into memory. There are no restrictions on memory alignment. For aligned memory _mm_store_ps may be faster.
_mm_storeu_si16⚠(x86 or x86-64) and sse2
    Store 16-bit integer from the first element of a into memory.
_mm_storeu_si32⚠(x86 or x86-64) and sse2
    Store 32-bit integer from the first element of a into memory.
_mm_storeu_si64⚠(x86 or x86-64) and sse2
    Store 64-bit integer from the first element of a into memory.
_mm_storeu_si128⚠(x86 or x86-64) and sse2
    Stores 128-bits of integer data from a into memory.
_mm_stream_load_si128⚠(x86 or x86-64) and sse4.1
    Load 128-bits of integer data from memory into dst. mem_addr must be aligned on a 16-byte boundary or a general-protection exception may be generated. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon)
_mm_stream_pd⚠(x86 or x86-64) and sse2
    Stores a 128-bit floating point vector of [2 x double] to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm_stream_ps⚠(x86 or x86-64) and sse
    Stores a into the memory at mem_addr using a non-temporal memory hint.
_mm_stream_sd⚠(x86 or x86-64) and sse4a
    Non-temporal store of a.0 into p.
_mm_stream_si32⚠(x86 or x86-64) and sse2
    Stores a 32-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm_stream_si64⚠sse2
    Stores a 64-bit integer value in the specified memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm_stream_si128⚠(x86 or x86-64) and sse2
    Stores a 128-bit integer vector to a 128-bit aligned memory location. To minimize caching, the data is flagged as non-temporal (unlikely to be used again soon).
_mm_stream_ss⚠(x86 or x86-64) and sse4a
    Non-temporal store of a.0 into p.
_mm_sub_epi8⚠(x86 or x86-64) and sse2
    Subtracts packed 8-bit integers in b from packed 8-bit integers in a.
_mm_sub_epi16⚠(x86 or x86-64) and sse2
    Subtracts packed 16-bit integers in b from packed 16-bit integers in a.
_mm_sub_epi32⚠(x86 or x86-64) and sse2
    Subtract packed 32-bit integers in b from packed 32-bit integers in a.
_mm_sub_epi64⚠(x86 or x86-64) and sse2
    Subtract packed 64-bit integers in b from packed 64-bit integers in a.
_mm_sub_pd⚠(x86 or x86-64) and sse2
    Subtract packed double-precision (64-bit) floating-point elements in b from a.
_mm_sub_ps⚠(x86 or x86-64) and sse
    Subtracts packed single-precision (32-bit) floating-point elements in a and b.
_mm_sub_round_sd⚠(x86 or x86-64) and avx512f
    Subtract the lower double-precision (64-bit) floating-point element in b from the lower double-precision (64-bit) floating-point element in a, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.\
_mm_sub_round_ss⚠(x86 or x86-64) and avx512f
    Subtract the lower single-precision (32-bit) floating-point element in b from the lower single-precision (32-bit) floating-point element in a, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.\
_mm_sub_sd⚠(x86 or x86-64) and sse2
    Returns a new vector with the low element of a replaced by subtracting the low element by b from the low element of a.
_mm_sub_ss⚠(x86 or x86-64) and sse
    Subtracts the first component of b from a, the other components are copied from a.
_mm_subs_epi8⚠(x86 or x86-64) and sse2
    Subtract packed 8-bit integers in b from packed 8-bit integers in a using saturation.
_mm_subs_epi16⚠(x86 or x86-64) and sse2
    Subtract packed 16-bit integers in b from packed 16-bit integers in a using saturation.
_mm_subs_epu8⚠(x86 or x86-64) and sse2
    Subtract packed unsigned 8-bit integers in b from packed unsigned 8-bit integers in a using saturation.
_mm_subs_epu16⚠(x86 or x86-64) and sse2
    Subtract packed unsigned 16-bit integers in b from packed unsigned 16-bit integers in a using saturation.
_mm_ternarylogic_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 32-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm_ternarylogic_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Bitwise ternary logic that provides the capability to implement any three-operand binary function; the specific binary function is specified by value in imm8. For each bit in each packed 64-bit integer, the corresponding bit from a, b, and c are used to form a 3 bit index into imm8, and the value at that bit in imm8 is written to the corresponding bit in dst.
_mm_test_all_ones⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are all ones.
_mm_test_all_zeros⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are all zeros.
_mm_test_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm_test_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise AND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm_test_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm_test_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise AND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is non-zero.
_mm_test_mix_ones_zeros⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.
_mm_testc_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return the CF value.
_mm_testc_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return the CF value.
_mm_testc_si128⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are all ones.
_mm_testn_epi8_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 8-bit integers in a and b, producing intermediate 8-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm_testn_epi16_mask⚠(x86 or x86-64) and avx512bw,avx512vl
    Compute the bitwise NAND of packed 16-bit integers in a and b, producing intermediate 16-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm_testn_epi32_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 32-bit integers in a and b, producing intermediate 32-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm_testn_epi64_mask⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise NAND of packed 64-bit integers in a and b, producing intermediate 64-bit values, and set the corresponding bit in result mask k if the intermediate value is zero.
_mm_testnzc_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return 1 if both the ZF and CF values are zero, otherwise return 0.
_mm_testnzc_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return 1 if both the ZF and CF values are zero, otherwise return 0.
_mm_testnzc_si128⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are neither all zeros nor all ones.
_mm_testz_pd⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing double-precision (64-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 64-bit element in the intermediate value is zero, otherwise set CF to 0. Return the ZF value.
_mm_testz_ps⚠(x86 or x86-64) and avx
    Computes the bitwise AND of 128 bits (representing single-precision (32-bit) floating-point elements) in a and b, producing an intermediate 128-bit value, and set ZF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set ZF to 0. Compute the bitwise NOT of a and then AND with b, producing an intermediate value, and set CF to 1 if the sign bit of each 32-bit element in the intermediate value is zero, otherwise set CF to 0. Return the ZF value.
_mm_testz_si128⚠(x86 or x86-64) and sse4.1
    Tests whether the specified bits in a 128-bit integer vector are all zeros.
_mm_tzcnt_32⚠(x86 or x86-64) and bmi1
    Counts the number of trailing least significant zero bits.
_mm_tzcnt_64⚠bmi1
    Counts the number of trailing least significant zero bits.
_mm_ucomieq_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for equality.
_mm_ucomieq_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if they are equal, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_ucomige_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for greater-than-or-equal.
_mm_ucomige_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is greater than or equal to the one from b, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_ucomigt_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for greater-than.
_mm_ucomigt_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is greater than the one from b, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_ucomile_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for less-than-or-equal.
_mm_ucomile_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is less than or equal to the one from b, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_ucomilt_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for less-than.
_mm_ucomilt_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if the value from a is less than the one from b, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_ucomineq_sd⚠(x86 or x86-64) and sse2
    Compares the lower element of a and b for not-equal.
_mm_ucomineq_ss⚠(x86 or x86-64) and sse
    Compares two 32-bit floats from the low-order bits of a and b. Returns 1 if they are not equal, or 0 otherwise. This instruction will not signal an exception if either argument is a quiet NaN.
_mm_undefined_pd⚠(x86 or x86-64) and sse2
    Returns vector of type __m128d with indeterminate elements.with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm_undefined_ps⚠(x86 or x86-64) and sse
    Returns vector of type __m128 with indeterminate elements.with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm_undefined_si128⚠(x86 or x86-64) and sse2
    Returns vector of type __m128i with indeterminate elements.with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm_unpackhi_epi8⚠(x86 or x86-64) and sse2
    Unpacks and interleave 8-bit integers from the high half of a and b.
_mm_unpackhi_epi16⚠(x86 or x86-64) and sse2
    Unpacks and interleave 16-bit integers from the high half of a and b.
_mm_unpackhi_epi32⚠(x86 or x86-64) and sse2
    Unpacks and interleave 32-bit integers from the high half of a and b.
_mm_unpackhi_epi64⚠(x86 or x86-64) and sse2
    Unpacks and interleave 64-bit integers from the high half of a and b.
_mm_unpackhi_pd⚠(x86 or x86-64) and sse2
    The resulting __m128d element is composed by the low-order values of the two __m128d interleaved input elements, i.e.:
_mm_unpackhi_ps⚠(x86 or x86-64) and sse
    Unpacks and interleave single-precision (32-bit) floating-point elements from the higher half of a and b.
_mm_unpacklo_epi8⚠(x86 or x86-64) and sse2
    Unpacks and interleave 8-bit integers from the low half of a and b.
_mm_unpacklo_epi16⚠(x86 or x86-64) and sse2
    Unpacks and interleave 16-bit integers from the low half of a and b.
_mm_unpacklo_epi32⚠(x86 or x86-64) and sse2
    Unpacks and interleave 32-bit integers from the low half of a and b.
_mm_unpacklo_epi64⚠(x86 or x86-64) and sse2
    Unpacks and interleave 64-bit integers from the low half of a and b.
_mm_unpacklo_pd⚠(x86 or x86-64) and sse2
    The resulting __m128d element is composed by the high-order values of the two __m128d interleaved input elements, i.e.:
_mm_unpacklo_ps⚠(x86 or x86-64) and sse
    Unpacks and interleave single-precision (32-bit) floating-point elements from the lower half of a and b.
_mm_xor_epi32⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 32-bit integers in a and b, and store the results in dst.
_mm_xor_epi64⚠(x86 or x86-64) and avx512f,avx512vl
    Compute the bitwise XOR of packed 64-bit integers in a and b, and store the results in dst.
_mm_xor_pd⚠(x86 or x86-64) and sse2
    Computes the bitwise XOR of a and b.
_mm_xor_ps⚠(x86 or x86-64) and sse
    Bitwise exclusive OR of packed single-precision (32-bit) floating-point elements.
_mm_xor_si128⚠(x86 or x86-64) and sse2
    Computes the bitwise XOR of 128 bits (representing integer data) in a and b.
_mulx_u32⚠(x86 or x86-64) and bmi2
    Unsigned multiply without affecting flags.
_mulx_u64⚠bmi2
    Unsigned multiply without affecting flags.
_pdep_u32⚠(x86 or x86-64) and bmi2
    Scatter contiguous low order bits of a to the result at the positions specified by the mask.
_pdep_u64⚠bmi2
    Scatter contiguous low order bits of a to the result at the positions specified by the mask.
_pext_u32⚠(x86 or x86-64) and bmi2
    Gathers the bits of x specified by the mask into the contiguous low order bit positions of the result.
_pext_u64⚠bmi2
    Gathers the bits of x specified by the mask into the contiguous low order bit positions of the result.
_popcnt32⚠(x86 or x86-64) and popcnt
    Counts the bits that are set.
_popcnt64⚠popcnt
    Counts the bits that are set.
_rdrand16_step⚠(x86 or x86-64) and rdrand
    Read a hardware generated 16-bit random value and store the result in val. Returns 1 if a random value was generated, and 0 otherwise.
_rdrand32_step⚠(x86 or x86-64) and rdrand
    Read a hardware generated 32-bit random value and store the result in val. Returns 1 if a random value was generated, and 0 otherwise.
_rdrand64_step⚠rdrand
    Read a hardware generated 64-bit random value and store the result in val. Returns 1 if a random value was generated, and 0 otherwise.
_rdseed16_step⚠(x86 or x86-64) and rdseed
    Read a 16-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.
_rdseed32_step⚠(x86 or x86-64) and rdseed
    Read a 32-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.
_rdseed64_step⚠rdseed
    Read a 64-bit NIST SP800-90B and SP800-90C compliant random value and store in val. Return 1 if a random value was generated, and 0 otherwise.
_rdtsc⚠x86 or x86-64
    Reads the current value of the processor’s time-stamp counter.
_store_mask8⚠(x86 or x86-64) and avx512dq
    Store 8-bit mask to memory
_store_mask16⚠(x86 or x86-64) and avx512f
    Store 16-bit mask to memory
_store_mask32⚠(x86 or x86-64) and avx512bw
    Store 32-bit mask from a into memory.
_store_mask64⚠(x86 or x86-64) and avx512bw
    Store 64-bit mask from a into memory.
_subborrow_u32⚠x86 or x86-64
    Adds unsigned 32-bit integers a and b with unsigned 8-bit carry-in c_in (carry or overflow flag), and store the unsigned 32-bit result in out, and the carry-out is returned (carry or overflow flag).
_subborrow_u64⚠
    Adds unsigned 64-bit integers a and b with unsigned 8-bit carry-in c_in. (carry or overflow flag), and store the unsigned 64-bit result in out, and the carry-out is returned (carry or overflow flag).
_t1mskc_u32⚠(x86 or x86-64) and tbm
    Clears all bits below the least significant zero of x and sets all other bits.
_t1mskc_u64⚠tbm
    Clears all bits below the least significant zero of x and sets all other bits.
_tzcnt_u16⚠(x86 or x86-64) and bmi1
    Counts the number of trailing least significant zero bits.
_tzcnt_u32⚠(x86 or x86-64) and bmi1
    Counts the number of trailing least significant zero bits.
_tzcnt_u64⚠bmi1
    Counts the number of trailing least significant zero bits.
_tzmsk_u32⚠(x86 or x86-64) and tbm
    Sets all bits below the least significant one of x and clears all other bits.
_tzmsk_u64⚠tbm
    Sets all bits below the least significant one of x and clears all other bits.
_xgetbv⚠(x86 or x86-64) and xsave
    Reads the contents of the extended control register XCR specified in xcr_no.
_xrstor⚠(x86 or x86-64) and xsave
    Performs a full or partial restore of the enabled processor states using the state information stored in memory at mem_addr.
_xrstor64⚠xsave
    Performs a full or partial restore of the enabled processor states using the state information stored in memory at mem_addr.
_xrstors⚠(x86 or x86-64) and xsave,xsaves
    Performs a full or partial restore of the enabled processor states using the state information stored in memory at mem_addr.
_xrstors64⚠xsave,xsaves
    Performs a full or partial restore of the enabled processor states using the state information stored in memory at mem_addr.
_xsave⚠(x86 or x86-64) and xsave
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsave64⚠xsave
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsavec⚠(x86 or x86-64) and xsave,xsavec
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsavec64⚠xsave,xsavec
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsaveopt⚠(x86 or x86-64) and xsave,xsaveopt
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsaveopt64⚠xsave,xsaveopt
    Performs a full or partial save of the enabled processor states to memory at mem_addr.
_xsaves⚠(x86 or x86-64) and xsave,xsaves
    Performs a full or partial save of the enabled processor states to memory at mem_addr
_xsaves64⚠xsave,xsaves
    Performs a full or partial save of the enabled processor states to memory at mem_addr
_xsetbv⚠(x86 or x86-64) and xsave
    Copies 64-bits from val to the extended control register (XCR) specified by a.
cmpxchg16b⚠cmpxchg16b
    Compares and exchange 16 bytes (128 bits) of data atomically.
_MM_SHUFFLEExperimentalx86 or x86-64
    A utility function for creating masks to use with Intel shuffle and permute intrinsics.
_mm256_abs_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Finds the absolute value of each packed half-precision (16-bit) floating-point element in v2, storing the result in dst.
_mm256_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm256_bcstnebf16_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert scalar BF16 (16-bit) floating point element stored at memory locations starting at location a to single precision (32-bit) floating-point, broadcast it to packed single precision (32-bit) floating-point elements, and store the results in dst.
_mm256_bcstnesh_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert scalar half-precision (16-bit) floating-point element stored at memory locations starting at location a to a single-precision (32-bit) floating-point, broadcast it to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm256_castpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256d to type __m256h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castph128_ph256⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m256h. The upper 8 elements of the result are undefined. In practice, the upper elements are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm256_castph256_ph128⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m128h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m256d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m256. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castph_si256⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m256i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256 to type __m256h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_castsi256_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256i to type __m256h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm256_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm256_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm256_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm256_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 64 bits of dst are zeroed out.
_mm256_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm256_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm256_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 64 bits of dst are zeroed out.
_mm256_cvtneeph_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert packed half-precision (16-bit) floating-point even-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtneoph_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert packed half-precision (16-bit) floating-point odd-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 64 bits of dst are zeroed out.
_mm256_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst.
_mm256_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm256_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst.
_mm256_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst.
_mm256_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst.
_mm256_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst.
_mm256_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm256_cvtsh_h⚠Experimental(x86 or x86-64) and avx512fp16
    Copy the lower half-precision (16-bit) floating-point element from a to dst.
_mm256_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst.
_mm256_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm256_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst.
_mm256_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst.
_mm256_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst.
_mm256_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst.
_mm256_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm256_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm256_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst.
_mm256_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm256_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm256_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm256_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst.
_mm256_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst.
_mm256_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm256_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm256_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm256_load_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Load 256-bits (composed of 16 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address must be aligned to 32 bytes or a general-protection exception may be generated.
_mm256_loadu_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Load 256-bits (composed of 16 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address does not need to be aligned to any particular boundary.
_mm256_mask3_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_mask3_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_mask3_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask3_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask3_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm256_mask_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_blend_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Blend packed half-precision (16-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm256_mask_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_mask_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_mask_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_mask_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_mask_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_mask_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_mask_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm256_mask_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_mask_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_mask_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_mask_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_mask_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm256_mask_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm256_mask_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_mask_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm256_mask_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm256_mask_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm256_mask_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_mask_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_mask_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_mask_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_mask_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm256_maskz_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_maskz_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_maskz_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_maskz_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_maskz_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm256_maskz_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_maskz_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm256_maskz_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_maskz_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_maskz_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm256_maskz_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm256_maskz_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm256_maskz_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm256_maskz_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm256_maskz_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_maskz_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_maskz_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_maskz_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_maskz_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm256_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm256_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm256_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm256_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm256_permutex2var_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Shuffle half-precision (16-bit) floating-point elements in a and b using the corresponding selector and index in idx, and store the results in dst.
_mm256_permutexvar_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Shuffle half-precision (16-bit) floating-point elements in a using the corresponding index in idx, and store the results in dst.
_mm256_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_reduce_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by addition. Returns the sum of all elements in a.
_mm256_reduce_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by maximum. Returns the maximum of all elements in a.
_mm256_reduce_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by minimum. Returns the minimum of all elements in a.
_mm256_reduce_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by multiplication. Returns the product of all elements in a.
_mm256_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst.
_mm256_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
_mm256_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm256_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst.
_mm256_set1_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Broadcast the half-precision (16-bit) floating-point value a to all elements of dst.
_mm256_set_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values.
_mm256_setr_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values in reverse order.
_mm256_setzero_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Return vector of type __m256h with all elements set to zero.
_mm256_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst.
_mm256_store_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Store 256-bits (composed of 16 packed half-precision (16-bit) floating-point elements) from a into memory. The address must be aligned to 32 bytes or a general-protection exception may be generated.
_mm256_storeu_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Store 256-bits (composed of 16 packed half-precision (16-bit) floating-point elements) from a into memory. The address does not need to be aligned to any particular boundary.
_mm256_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst.
_mm256_undefined_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Return vector of type __m256h with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm256_zextph128_ph256⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m128h. The upper 8 elements of the result are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm512_abs_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Finds the absolute value of each packed half-precision (16-bit) floating-point element in v2, storing the result in dst.
_mm512_add_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm512_add_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst. Rounding is done according to the rounding parameter, which can be one of:
_mm512_castpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512d to type __m512h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castph128_ph512⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m512h. The upper 24 elements of the result are undefined. In practice, the upper elements are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm512_castph256_ph512⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m512h. The upper 16 elements of the result are undefined. In practice, the upper elements are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm512_castph512_ph128⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512h to type __m128h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castph512_ph256⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512h to type __m256h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512h to type __m512d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512h to type __m512. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castph_si512⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512h to type __m512i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512 to type __m512h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_castsi512_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m512i to type __m512h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm512_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmp_round_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm512_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_cmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the complex conjugates of complex numbers in a, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_cvt_roundepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst.
_mm512_cvt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm512_cvt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst.
_mm512_cvt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst.
_mm512_cvt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst.
_mm512_cvt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst.
_mm512_cvt_roundph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst.
_mm512_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm512_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst.
_mm512_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst.
_mm512_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst.
_mm512_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst.
_mm512_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm512_cvtsh_h⚠Experimental(x86 or x86-64) and avx512fp16
    Copy the lower half-precision (16-bit) floating-point element from a to dst.
_mm512_cvtt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst.
_mm512_cvtt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm512_cvtt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst.
_mm512_cvtt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst.
_mm512_cvtt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst.
_mm512_cvtt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst.
_mm512_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst.
_mm512_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm512_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst.
_mm512_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst.
_mm512_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst.
_mm512_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst.
_mm512_cvtx_roundph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtx_roundps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm512_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm512_div_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst.
_mm512_div_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst. Rounding is done according to the rounding parameter, which can be one of:
_mm512_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_fcmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_fcmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm512_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm512_fmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_fmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm512_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmaddsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm512_fmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm512_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmsubadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst.
_mm512_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_fmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1]. Rounding is done according to the rounding parameter, which can be one of:
_mm512_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst.
_mm512_fnmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst.
_mm512_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm512_fnmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm512_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm512_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_getexp_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm512_getmant_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_load_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Load 512-bits (composed of 32 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address must be aligned to 64 bytes or a general-protection exception may be generated.
_mm512_loadu_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Load 512-bits (composed of 32 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address does not need to be aligned to any particular boundary.
_mm512_mask3_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask3_fcmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c using writemask k (the element is copied from c when the corresponding mask bit is not set), and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1, or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask3_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask3_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask3_fmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmaddsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fmsubadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask3_fnmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm512_mask_add_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_add_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_mask_blend_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Blend packed half-precision (16-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm512_mask_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmp_round_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_mask_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_cmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the complex conjugates of complex numbers in a, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_cvt_roundepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvt_roundph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_cvtx_roundph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtx_roundps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm512_mask_div_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_div_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_mask_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_fcmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_fcmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_mask_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask_fmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmaddsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmsubadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask_fmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1]. Rounding is done according to the rounding parameter, which can be one of:
_mm512_mask_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fnmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm512_mask_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm512_mask_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_mask_getexp_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_mask_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm512_mask_getmant_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_mask_max_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_mask_max_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_mask_min_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_mask_min_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_mask_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_mul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mask_mul_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_mask_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_mask_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_reduce_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_roundscale_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_mask_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_mask_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_scalef_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sqrt_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_mask_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm512_mask_sub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_add_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_add_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_cmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the complex conjugates of complex numbers in a, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_cvt_roundepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvt_roundph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtt_roundph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtx_roundph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtx_roundps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_div_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_div_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_fcmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c using zeromask k (the element is zeroed out when the corresponding mask bit is not set), and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1, or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_fcmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm512_maskz_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_maskz_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmadd_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_maskz_fmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmaddsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmsubadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_maskz_fmul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1]. Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmadd_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_fnmsub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm512_maskz_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm512_maskz_getexp_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_maskz_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm512_maskz_getmant_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_maskz_max_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_maskz_max_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_maskz_min_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_maskz_min_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_maskz_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_maskz_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_mul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_maskz_mul_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_maskz_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_reduce_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_roundscale_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_maskz_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_maskz_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_scalef_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sqrt_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_maskz_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm512_maskz_sub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm512_max_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_max_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm512_min_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_min_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm512_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm512_mul_round_pch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm512_mul_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst. Rounding is done according to the rounding parameter, which can be one of:
_mm512_permutex2var_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Shuffle half-precision (16-bit) floating-point elements in a and b using the corresponding selector and index in idx, and store the results in dst.
_mm512_permutexvar_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Shuffle half-precision (16-bit) floating-point elements in a using the corresponding index in idx, and store the results in dst.
_mm512_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_reduce_add_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Reduce the packed half-precision (16-bit) floating-point elements in a by addition. Returns the sum of all elements in a.
_mm512_reduce_max_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Reduce the packed half-precision (16-bit) floating-point elements in a by maximum. Returns the maximum of all elements in a.
_mm512_reduce_min_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Reduce the packed half-precision (16-bit) floating-point elements in a by minimum. Returns the minimum of all elements in a.
_mm512_reduce_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Reduce the packed half-precision (16-bit) floating-point elements in a by multiplication. Returns the product of all elements in a.
_mm512_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst.
_mm512_reduce_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst.
_mm512_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
_mm512_roundscale_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm512_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm512_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst.
_mm512_scalef_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst.
_mm512_set1_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Broadcast the half-precision (16-bit) floating-point value a to all elements of dst.
_mm512_set_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values.
_mm512_setr_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values in reverse order.
_mm512_setzero_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Return vector of type __m512h with all elements set to zero.
_mm512_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst.
_mm512_sqrt_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. Rounding is done according to the rounding parameter, which can be one of:
_mm512_store_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Store 512-bits (composed of 32 packed half-precision (16-bit) floating-point elements) from a into memory. The address must be aligned to 64 bytes or a general-protection exception may be generated.
_mm512_storeu_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Store 512-bits (composed of 32 packed half-precision (16-bit) floating-point elements) from a into memory. The address does not need to be aligned to any particular boundary.
_mm512_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst.
_mm512_sub_round_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst. Rounding is done according to the rounding parameter, which can be one of:
_mm512_undefined_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Return vector of type __m512h with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_mm512_zextph128_ph512⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m512h. The upper 24 elements of the result are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm512_zextph256_ph512⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m256h to type __m512h. The upper 16 elements of the result are zeroed. This intrinsic can generate the vzeroupper instruction, but most of the time it does not generate any instructions.
_mm_abs_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Finds the absolute value of each packed half-precision (16-bit) floating-point element in v2, storing the results in dst.
_mm_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm_add_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_add_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_bcstnebf16_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert scalar BF16 (16-bit) floating point element stored at memory locations starting at location a to single precision (32-bit) floating-point, broadcast it to packed single precision (32-bit) floating-point elements, and store the results in dst.
_mm_bcstnesh_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert scalar half-precision (16-bit) floating-point element stored at memory locations starting at location a to a single-precision (32-bit) floating-point, broadcast it to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm_castpd_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128d to type __m128h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_castph_pd⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m128d. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_castph_ps⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m128. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_castph_si128⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128h to type __m128i. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_castps_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128 to type __m128h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_castsi128_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Cast vector of type __m128i to type __m128h. This intrinsic is only used for compilation and does not generate any instructions, thus it has zero latency.
_mm_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k.
_mm_cmp_round_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the result in mask vector k. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_cmp_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the result in mask vector k.
_mm_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_cmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm_cmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm_comi_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and return the boolean result (0 or 1). Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_comi_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and return the boolean result (0 or 1).
_mm_comieq_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for equality, and return the boolean result (0 or 1).
_mm_comige_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for greater-than-or-equal, and return the boolean result (0 or 1).
_mm_comigt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for greater-than, and return the boolean result (0 or 1).
_mm_comile_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for less-than-or-equal, and return the boolean result (0 or 1).
_mm_comilt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for less-than, and return the boolean result (0 or 1).
_mm_comineq_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for not-equal, and return the boolean result (0 or 1).
_mm_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_cvt_roundi32_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the signed 32-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvt_roundi64_sh⚠Experimentalavx512fp16
    Convert the signed 64-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvt_roundsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvt_roundsh_i32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
_mm_cvt_roundsh_i64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
_mm_cvt_roundsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvt_roundsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvt_roundsh_u32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit unsigned integer, and store the result in dst.
_mm_cvt_roundsh_u64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit unsigned integer, and store the result in dst.
_mm_cvt_roundss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvt_roundu32_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the unsigned 32-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvt_roundu64_sh⚠Experimentalavx512fp16
    Convert the unsigned 64-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 1 packed elements from a to the upper elements of dst.
_mm_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 64 bits of dst are zeroed out.
_mm_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 96 bits of dst are zeroed out.
_mm_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 64 bits of dst are zeroed out.
_mm_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 96 bits of dst are zeroed out.
_mm_cvti32_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the signed 32-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvti64_sh⚠Experimentalavx512fp16
    Convert the signed 64-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvtneeph_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert packed half-precision (16-bit) floating-point even-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtneoph_ps⚠Experimental(x86 or x86-64) and avxneconvert
    Convert packed half-precision (16-bit) floating-point odd-indexed elements stored at memory locations starting at location a to single precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtness_sbh⚠Experimental(x86 or x86-64) and avx512bf16,avx512vl
    Converts a single-precision (32-bit) floating-point element in a to a BF16 (16-bit) floating-point element, and store the result in dst.
_mm_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst. The upper 96 bits of dst are zeroed out.
_mm_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst.
_mm_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst.
_mm_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst.
_mm_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst.
_mm_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst.
_mm_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst.
_mm_cvtsbh_ss⚠Experimental(x86 or x86-64) and avx512bf16,avx512f
    Converts a single BF16 (16-bit) floating-point element in a to a single-precision (32-bit) floating-point element, and store the result in dst.
_mm_cvtsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvtsh_h⚠Experimental(x86 or x86-64) and avx512fp16
    Copy the lower half-precision (16-bit) floating-point element from a to dst.
_mm_cvtsh_i32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit integer, and store the result in dst.
_mm_cvtsh_i64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit integer, and store the result in dst.
_mm_cvtsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst, and copy the upper element from a to the upper element of dst.
_mm_cvtsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst, and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_cvtsh_u32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit unsigned integer, and store the result in dst.
_mm_cvtsh_u64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit unsigned integer, and store the result in dst.
_mm_cvtsi16_si128⚠Experimental(x86 or x86-64) and avx512fp16
    Copy 16-bit integer a to the lower elements of dst, and zero the upper elements of dst.
_mm_cvtsi128_si16⚠Experimental(x86 or x86-64) and avx512fp16
    Copy the lower 16-bit integer in a to dst.
_mm_cvtss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvtt_roundsh_i32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
_mm_cvtt_roundsh_i64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
_mm_cvtt_roundsh_u32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit unsigned integer with truncation, and store the result in dst.
_mm_cvtt_roundsh_u64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit unsigned integer with truncation, and store the result in dst.
_mm_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst.
_mm_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst.
_mm_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst.
_mm_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst.
_mm_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst.
_mm_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst.
_mm_cvttsh_i32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit integer with truncation, and store the result in dst.
_mm_cvttsh_i64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit integer with truncation, and store the result in dst.
_mm_cvttsh_u32⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 32-bit unsigned integer with truncation, and store the result in dst.
_mm_cvttsh_u64⚠Experimentalavx512fp16
    Convert the lower half-precision (16-bit) floating-point element in a to a 64-bit unsigned integer with truncation, and store the result in dst.
_mm_cvtu32_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the unsigned 32-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_cvtu64_sh⚠Experimentalavx512fp16
    Convert the unsigned 64-bit integer b to a half-precision (16-bit) floating-point element, store the result in the lower element of dst, and copy the upper 1 packed elements from a to the upper elements of dst.
_mm_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst.
_mm_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst.
_mm_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst.
_mm_div_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_div_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_fcmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_fcmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_fcmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm_fcmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst.
_mm_fmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst.
_mm_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst.
_mm_fmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst.
_mm_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst.
_mm_fnmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fnmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst.
_mm_fnmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fnmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k. imm can be a combination of:
_mm_fpclass_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Test the lower half-precision (16-bit) floating-point element in a for special categories specified by imm8, and store the result in mask vector k. imm can be a combination of:
_mm_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst. This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_getexp_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_getexp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_getmant_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_getmant_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_load_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Load 128-bits (composed of 8 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address must be aligned to 16 bytes or a general-protection exception may be generated.
_mm_load_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Load a half-precision (16-bit) floating-point element from memory into the lower element of a new vector, and zero the upper elements
_mm_loadu_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Load 128-bits (composed of 8 packed half-precision (16-bit) floating-point elements) from memory into a new vector. The address does not need to be aligned to any particular boundary.
_mm_mask3_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask3_fcmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (the element is copied from c when the corresponding mask bit is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask3_fcmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (the element is copied from c when the corresponding mask bit is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask3_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask3_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (elements are copied from c when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask3_fmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (elements are copied from c when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask3_fmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fnmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from c when the corresponding mask bit is not set).
_mm_mask3_fnmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask3_fnmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from c when the mask bit 0 is not set), and copy the upper 7 packed elements from c to the upper elements of dst.
_mm_mask_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_add_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_mask_add_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set).
_mm_mask_blend_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Blend packed half-precision (16-bit) floating-point elements from a and b using control mask k, and store the results in dst.
_mm_mask_cmp_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_mask_cmp_round_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter.
_mm_mask_cmp_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b based on the comparison operand specified by imm8, and store the result in mask vector k using zeromask k1.
_mm_mask_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_cmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_cmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm_mask_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_cvt_roundsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using writemask k (the element if copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_cvt_roundsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src to dst when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_cvt_roundsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src to dst when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_cvt_roundss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using writemask k (the element if copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm_mask_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_mask_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_mask_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm_mask_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_mask_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_mask_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_mask_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm_mask_cvtsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using writemask k (the element if copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_cvtsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src to dst when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_mask_cvtsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using writemask k (the element is copied from src to dst when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_mask_cvtss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using writemask k (the element if copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set).
_mm_mask_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using writemask k (elements are copied from src to dst when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_mask_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_div_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_mask_div_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set).
_mm_mask_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fcmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (the element is copied from a when the corresponding mask bit is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fcmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (the element is copied from a when the corresponding mask bit is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fcmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fcmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_mask_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (elements are copied from a when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using writemask k (elements are copied from a when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fnmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fnmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using writemask k (the element is copied from a when the corresponding mask bit is not set).
_mm_mask_fnmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fnmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using writemask k (the element is copied from a when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_fpclass_ph_mask⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Test packed half-precision (16-bit) floating-point elements in a for special categories specified by imm8, and store the results in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_fpclass_sh_mask⚠Experimental(x86 or x86-64) and avx512fp16
    Test the lower half-precision (16-bit) floating-point element in a for special categories specified by imm8, and store the result in mask vector k using zeromask k (elements are zeroed out when the corresponding mask bit is not set). imm can be a combination of:
_mm_mask_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_mask_getexp_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_mask_getexp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_mask_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_mask_getmant_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_mask_getmant_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_mask_load_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Load a half-precision (16-bit) floating-point element from memory into the lower element of a new vector using writemask k (the element is copied from src when mask bit 0 is not set), and zero the upper elements.
_mm_mask_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_mask_max_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_mask_max_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_mask_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_mask_min_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_mask_min_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_mask_move_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Move the lower half-precision (16-bit) floating-point element from b to the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using writemask k (the element is copied from src when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_mul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_mul_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_mask_mul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mask_mul_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set).
_mm_mask_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_mask_rcp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_mask_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_reduce_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_reduce_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_roundscale_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_roundscale_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_mask_rsqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_mask_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_scalef_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_scalef_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sqrt_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_mask_sqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using writemask k (the element is copied from src when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mask_store_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Store the lower half-precision (16-bit) floating-point element from a into memory using writemask k
_mm_mask_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using writemask k (elements are copied from src when the corresponding mask bit is not set).
_mm_mask_sub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_mask_sub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using writemask k (the element is copied from src when mask bit 0 is not set).
_mm_maskz_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Add packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_add_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_maskz_add_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Add the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set).
_mm_maskz_cmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_cmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_cmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1],
_mm_maskz_conj_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the complex conjugates of complex numbers in a, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_cvt_roundsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_cvt_roundsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_cvt_roundsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_cvt_roundss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_cvtepi16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepi32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_maskz_cvtepi64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed signed 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_maskz_cvtepu16_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 16-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtepu32_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 32-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_maskz_cvtepu64_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed unsigned 64-bit integers in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_maskz_cvtpd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed double-precision (64-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 96 bits of dst are zeroed out.
_mm_maskz_cvtph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtph_pd⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed double-precision (64-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtsd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower double-precision (64-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_cvtsh_sd⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a double-precision (64-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper element from a to the upper element of dst.
_mm_maskz_cvtsh_ss⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower half-precision (16-bit) floating-point element in b to a single-precision (32-bit) floating-point element, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 3 packed elements from a to the upper elements of dst.
_mm_maskz_cvtss_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the lower single-precision (32-bit) floating-point element in b to a half-precision (16-bit) floating-point elements, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_cvttph_epi16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttph_epi32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttph_epi64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttph_epu16⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed unsigned 16-bit integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttph_epu32⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 32-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvttph_epu64⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed 64-bit unsigned integers with truncation, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtxph_ps⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed half-precision (16-bit) floating-point elements in a to packed single-precision (32-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_cvtxps_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert packed single-precision (32-bit) floating-point elements in a to packed half-precision (16-bit) floating-point elements, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The upper 64 bits of dst are zeroed out.
_mm_maskz_div_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Divide packed half-precision (16-bit) floating-point elements in a by b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_div_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_maskz_div_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Divide the lower half-precision (16-bit) floating-point elements in a by b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set).
_mm_maskz_fcmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fcmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c using zeromask k (the element is zeroed out when the corresponding mask bit is not set), and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1, or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fcmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex number in a by the complex conjugate of the lower complex number in b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fcmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a by the complex conjugates of packed complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fcmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fcmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a by the complex conjugates of the lower complex numbers in b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1], or the complex conjugate conjugate = vec.fp16[0] - i * vec.fp16[1].
_mm_maskz_fmadd_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, accumulate to the corresponding complex numbers in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, add the intermediate result to packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmadd_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using zeromask k (elements are zeroed out when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fmadd_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, accumulate to the lower complex number in c, and store the result in the lower elements of dst using zeromask k (elements are zeroed out when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and add the intermediate result to the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fmaddsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively add and subtract packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract packed elements in c from the intermediate result. Store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fmsubadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, alternatively subtract and add packed elements in c to/from the intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fmul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fmul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fmul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_fnmadd_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract the intermediate result from packed elements in c, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmadd_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fnmadd_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fnmsub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, subtract packed elements in c from the negated intermediate result, and store the results in dst using zeromask k (the element is zeroed out when the corresponding mask bit is not set).
_mm_maskz_fnmsub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_fnmsub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, and subtract the intermediate result from the lower element in c. Store the result in the lower element of dst using zeromask k (the element is zeroed out when the mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_getexp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Convert the exponent of each packed half-precision (16-bit) floating-point element in a to a half-precision (16-bit) floating-point number representing the integer exponent, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates floor(log2(x)) for each element.
_mm_maskz_getexp_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_maskz_getexp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Convert the exponent of the lower half-precision (16-bit) floating-point element in b to a half-precision (16-bit) floating-point number representing the integer exponent, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates floor(log2(x)) for the lower element.
_mm_maskz_getmant_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Normalize the mantissas of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_maskz_getmant_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter
_mm_maskz_getmant_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Normalize the mantissas of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. This intrinsic essentially calculates ±(2^k)*|x.significand|, where k depends on the interval range defined by norm and the sign depends on sign and the source sign.
_mm_maskz_load_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Load a half-precision (16-bit) floating-point element from memory into the lower element of a new vector using zeromask k (the element is zeroed out when mask bit 0 is not set), and zero the upper elements.
_mm_maskz_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_maskz_max_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_maskz_max_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_maskz_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_maskz_min_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_maskz_min_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_maskz_move_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Move the lower half-precision (16-bit) floating-point element from b to the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst using zeromask k (the element is zeroed out when corresponding mask bit is not set). Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_mul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_mul_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_maskz_mul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_maskz_mul_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set).
_mm_maskz_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_maskz_rcp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_maskz_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_reduce_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_reduce_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_roundscale_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_roundscale_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set). The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_maskz_rsqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_maskz_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_scalef_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_scalef_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sqrt_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_maskz_sqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst using zeromask k (the element is zeroed out when mask bit 0 is not set), and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_maskz_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst using zeromask k (elements are zeroed out when the corresponding mask bit is not set).
_mm_maskz_sub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set). Rounding is done according to the rounding parameter, which can be one of:
_mm_maskz_sub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst using zeromask k (the element is zeroed out when mask bit 0 is not set).
_mm_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed maximum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_max_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_max_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the maximum value in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) maximum value when inputs are NaN or signed-zero values.
_mm_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare packed half-precision (16-bit) floating-point elements in a and b, and store packed minimum values in dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_min_round_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Exceptions can be suppressed by passing _MM_FROUND_NO_EXC in the sae parameter. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_min_sh⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compare the lower half-precision (16-bit) floating-point elements in a and b, store the minimum value in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Does not follow the IEEE Standard for Floating-Point Arithmetic (IEEE 754) minimum value when inputs are NaN or signed-zero values.
_mm_move_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Move the lower half-precision (16-bit) floating-point element from b to the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_mul_pch⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed complex numbers in a and b, and store the results in dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Multiply packed half-precision (16-bit) floating-point elements in a and b, and store the results in dst.
_mm_mul_round_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mul_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_mul_sch⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower complex numbers in a and b, and store the result in the lower elements of dst, and copy the upper 6 packed elements from a to the upper elements of dst. Each complex number is composed of two adjacent half-precision (16-bit) floating-point elements, which defines the complex number complex = vec.fp16[0] + i * vec.fp16[1].
_mm_mul_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Multiply the lower half-precision (16-bit) floating-point elements in a and b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_permutex2var_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Shuffle half-precision (16-bit) floating-point elements in a and b using the corresponding selector and index in idx, and store the results in dst.
_mm_permutexvar_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Shuffle half-precision (16-bit) floating-point elements in a using the corresponding index in idx, and store the results in dst.
_mm_rcp_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal of packed 16-bit floating-point elements in a and stores the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_rcp_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_reduce_add_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by addition. Returns the sum of all elements in a.
_mm_reduce_max_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by maximum. Returns the maximum of all elements in a.
_mm_reduce_min_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by minimum. Returns the minimum of all elements in a.
_mm_reduce_mul_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Reduce the packed half-precision (16-bit) floating-point elements in a by multiplication. Returns the product of all elements in a.
_mm_reduce_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Extract the reduced argument of packed half-precision (16-bit) floating-point elements in a by the number of bits specified by imm8, and store the results in dst.
_mm_reduce_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_reduce_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Extract the reduced argument of the lower half-precision (16-bit) floating-point element in b by the number of bits specified by imm8, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_roundscale_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Round packed half-precision (16-bit) floating-point elements in a to the number of fraction bits specified by imm8, and store the results in dst.
_mm_roundscale_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_roundscale_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Round the lower half-precision (16-bit) floating-point element in b to the number of fraction bits specified by imm8, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_rsqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the approximate reciprocal square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_rsqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the approximate reciprocal square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. The maximum relative error for this approximation is less than 1.5*2^-12.
_mm_scalef_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Scale the packed half-precision (16-bit) floating-point elements in a using values from b, and store the results in dst.
_mm_scalef_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_scalef_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Scale the packed single-precision (32-bit) floating-point elements in a using values from b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_set1_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Broadcast the half-precision (16-bit) floating-point value a to all elements of dst.
_mm_set_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values.
_mm_set_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Copy half-precision (16-bit) floating-point elements from a to the lower element of dst and zero the upper 7 elements.
_mm_setr_ph⚠Experimental(x86 or x86-64) and avx512fp16
    Set packed half-precision (16-bit) floating-point elements in dst with the supplied values in reverse order.
_mm_setzero_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Return vector of type __m128h with all elements set to zero.
_mm_sqrt_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Compute the square root of packed half-precision (16-bit) floating-point elements in a, and store the results in dst.
_mm_sqrt_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_sqrt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compute the square root of the lower half-precision (16-bit) floating-point element in b, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_store_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Store 128-bits (composed of 8 packed half-precision (16-bit) floating-point elements) from a into memory. The address must be aligned to 16 bytes or a general-protection exception may be generated.
_mm_store_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Store the lower half-precision (16-bit) floating-point element from a into memory.
_mm_storeu_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Store 128-bits (composed of 8 packed half-precision (16-bit) floating-point elements) from a into memory. The address does not need to be aligned to any particular boundary.
_mm_sub_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Subtract packed half-precision (16-bit) floating-point elements in b from a, and store the results in dst.
_mm_sub_round_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst. Rounding is done according to the rounding parameter, which can be one of:
_mm_sub_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Subtract the lower half-precision (16-bit) floating-point elements in b from a, store the result in the lower element of dst, and copy the upper 7 packed elements from a to the upper elements of dst.
_mm_ucomieq_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for equality, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_ucomige_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for greater-than-or-equal, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_ucomigt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for greater-than, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_ucomile_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for less-than-or-equal, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_ucomilt_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for less-than, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_ucomineq_sh⚠Experimental(x86 or x86-64) and avx512fp16
    Compare the lower half-precision (16-bit) floating-point elements in a and b for not-equal, and return the boolean result (0 or 1). This instruction will not signal an exception for QNaNs.
_mm_undefined_ph⚠Experimental(x86 or x86-64) and avx512fp16,avx512vl
    Return vector of type __m128h with indetermination elements. Despite using the word “undefined” (following Intel’s naming scheme), this non-deterministically picks some valid value and is not equivalent to mem::MaybeUninit. In practice, this is typically equivalent to mem::zeroed.
_tile_cmmimfp16ps⚠Experimentalamx-complex
    Perform matrix multiplication of two tiles containing complex elements and accumulate the results into a packed single precision tile. Each dword element in input tiles a and b is interpreted as a complex number with FP16 real part and FP16 imaginary part. Calculates the imaginary part of the result. For each possible combination of (row of a, column of b), it performs a set of multiplication and accumulations on all corresponding complex numbers (one from a and one from b). The imaginary part of the a element is multiplied with the real part of the corresponding b element, and the real part of the a element is multiplied with the imaginary part of the corresponding b elements. The two accumulated results are added, and then accumulated into the corresponding row and column of dst.
_tile_cmmrlfp16ps⚠Experimentalamx-complex
    Perform matrix multiplication of two tiles containing complex elements and accumulate the results into a packed single precision tile. Each dword element in input tiles a and b is interpreted as a complex number with FP16 real part and FP16 imaginary part. Calculates the real part of the result. For each possible combination of (row of a, column of b), it performs a set of multiplication and accumulations on all corresponding complex numbers (one from a and one from b). The real part of the a element is multiplied with the real part of the corresponding b element, and the negated imaginary part of the a element is multiplied with the imaginary part of the corresponding b elements. The two accumulated results are added, and then accumulated into the corresponding row and column of dst.
_tile_dpbf16ps⚠Experimentalamx-bf16
    Compute dot-product of BF16 (16-bit) floating-point pairs in tiles a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in dst, and store the 32-bit result back to tile dst.
_tile_dpbssd⚠Experimentalamx-int8
    Compute dot-product of bytes in tiles with a source/destination accumulator. Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate 32-bit results. Sum these 4 results with the corresponding 32-bit integer in dst, and store the 32-bit result back to tile dst.
_tile_dpbsud⚠Experimentalamx-int8
    Compute dot-product of bytes in tiles with a source/destination accumulator. Multiply groups of 4 adjacent pairs of signed 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate 32-bit results. Sum these 4 results with the corresponding 32-bit integer in dst, and store the 32-bit result back to tile dst.
_tile_dpbusd⚠Experimentalamx-int8
    Compute dot-product of bytes in tiles with a source/destination accumulator. Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding signed 8-bit integers in b, producing 4 intermediate 32-bit results. Sum these 4 results with the corresponding 32-bit integer in dst, and store the 32-bit result back to tile dst.
_tile_dpbuud⚠Experimentalamx-int8
    Compute dot-product of bytes in tiles with a source/destination accumulator. Multiply groups of 4 adjacent pairs of unsigned 8-bit integers in a with corresponding unsigned 8-bit integers in b, producing 4 intermediate 32-bit results. Sum these 4 results with the corresponding 32-bit integer in dst, and store the 32-bit result back to tile dst.
_tile_dpfp16ps⚠Experimentalamx-fp16
    Compute dot-product of FP16 (16-bit) floating-point pairs in tiles a and b, accumulating the intermediate single-precision (32-bit) floating-point elements with elements in dst, and store the 32-bit result back to tile dst.
_tile_loadconfig⚠Experimentalamx-tile
    Load tile configuration from a 64-byte memory location specified by mem_addr. The tile configuration format is specified below, and includes the tile type pallette, the number of bytes per row, and the number of rows. If the specified pallette_id is zero, that signifies the init state for both the tile config and the tile data, and the tiles are zeroed. Any invalid configurations will result in #GP fault.
_tile_loadd⚠Experimentalamx-tile
    Load tile rows from memory specifieid by base address and stride into destination tile dst using the tile configuration previously configured via _tile_loadconfig.
_tile_release⚠Experimentalamx-tile
    Release the tile configuration to return to the init state, which releases all storage it currently holds.
_tile_storeconfig⚠Experimentalamx-tile
    Stores the current tile configuration to a 64-byte memory location specified by mem_addr. The tile configuration format is specified below, and includes the tile type pallette, the number of bytes per row, and the number of rows. If tiles are not configured, all zeroes will be stored to memory.
_tile_stored⚠Experimentalamx-tile
    Store the tile specified by src to memory specifieid by base address and stride using the tile configuration previously configured via _tile_loadconfig.
_tile_stream_loadd⚠Experimentalamx-tile
    Load tile rows from memory specifieid by base address and stride into destination tile dst using the tile configuration previously configured via _tile_loadconfig. This intrinsic provides a hint to the implementation that the data will likely not be reused in the near future and the data caching can be optimized accordingly.
_tile_zero⚠Experimentalamx-tile
    Zero the tile specified by tdest.
_xabort⚠Experimental(x86 or x86-64) and rtm
    Forces a restricted transactional memory (RTM) region to abort.
_xabort_codeExperimentalx86 or x86-64
    Retrieves the parameter passed to _xabort when _xbegin’s status has the _XABORT_EXPLICIT flag set.
_xbegin⚠Experimental(x86 or x86-64) and rtm
    Specifies the start of a restricted transactional memory (RTM) code region and returns a value indicating status.
_xend⚠Experimental(x86 or x86-64) and rtm
    Specifies the end of a restricted transactional memory (RTM) code region.
_xtest⚠Experimental(x86 or x86-64) and rtm
    Queries whether the processor is executing in a transactional region identified by restricted transactional memory (RTM) or hardware lock elision (HLE).

Type Aliases

_MM_CMPINT_ENUMx86 or x86-64
    The _MM_CMPINT_ENUM type used to specify comparison operations in AVX-512 intrinsics.
_MM_MANTISSA_NORM_ENUMx86 or x86-64
    The MM_MANTISSA_NORM_ENUM type used to specify mantissa normalized operations in AVX-512 intrinsics.
_MM_MANTISSA_SIGN_ENUMx86 or x86-64
    The MM_MANTISSA_SIGN_ENUM type used to specify mantissa signed operations in AVX-512 intrinsics.
_MM_PERM_ENUMx86 or x86-64
    The MM_PERM_ENUM type used to specify shuffle operations in AVX-512 intrinsics.
__mmask8x86 or x86-64
    The __mmask8 type used in AVX-512 intrinsics, a 8-bit integer
__mmask16x86 or x86-64
    The __mmask16 type used in AVX-512 intrinsics, a 16-bit integer
__mmask32x86 or x86-64
    The __mmask32 type used in AVX-512 intrinsics, a 32-bit integer
__mmask64x86 or x86-64
    The __mmask64 type used in AVX-512 intrinsics, a 64-bit integer
